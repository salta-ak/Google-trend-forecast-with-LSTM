
 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.694444  0.416667  0.333333
2021-07-25  0.555556  0.569444  0.513889  ...  0.944444  0.694444  0.416667
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.944444  0.694444
2021-08-08  0.555556  0.458333  0.555556  ...  0.305556  0.208333  0.944444
2021-08-15  0.444444  0.555556  0.458333  ...  0.541667  0.305556  0.208333

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn (SimpleRNN)       (None, 4)                 68        
_________________________________________________________________
dense (Dense)                (None, 1)                 5         
=================================================================
Total params: 73
Trainable params: 73
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0117
Epoch 2/100
198/198 - 0s - loss: 0.0101
Epoch 3/100
198/198 - 0s - loss: 0.0095
Epoch 4/100
198/198 - 0s - loss: 0.0090
Epoch 5/100
198/198 - 0s - loss: 0.0085
Epoch 6/100
198/198 - 0s - loss: 0.0084
Epoch 7/100
198/198 - 0s - loss: 0.0080
Epoch 8/100
198/198 - 0s - loss: 0.0077
Epoch 9/100
198/198 - 0s - loss: 0.0074
Epoch 10/100
198/198 - 0s - loss: 0.0073
Epoch 11/100
198/198 - 0s - loss: 0.0072
Epoch 12/100
198/198 - 0s - loss: 0.0071
Epoch 13/100
198/198 - 0s - loss: 0.0067
Epoch 14/100
198/198 - 0s - loss: 0.0066
Epoch 15/100
198/198 - 0s - loss: 0.0068
Epoch 16/100
198/198 - 0s - loss: 0.0066
Epoch 17/100
198/198 - 0s - loss: 0.0064
Epoch 18/100
198/198 - 0s - loss: 0.0065
Epoch 19/100
198/198 - 0s - loss: 0.0063
Epoch 20/100
198/198 - 0s - loss: 0.0064
Epoch 21/100
198/198 - 0s - loss: 0.0063
Epoch 22/100
198/198 - 0s - loss: 0.0063
Epoch 23/100
198/198 - 0s - loss: 0.0062
Epoch 24/100
198/198 - 0s - loss: 0.0063
Epoch 25/100
198/198 - 0s - loss: 0.0063
Epoch 26/100
198/198 - 0s - loss: 0.0060
Epoch 27/100
198/198 - 0s - loss: 0.0062
Epoch 28/100
198/198 - 0s - loss: 0.0062
Epoch 29/100
198/198 - 0s - loss: 0.0060
Epoch 30/100
198/198 - 0s - loss: 0.0059
Epoch 31/100
198/198 - 0s - loss: 0.0059
Epoch 32/100
198/198 - 0s - loss: 0.0059
Epoch 33/100
198/198 - 0s - loss: 0.0059
Epoch 34/100
198/198 - 0s - loss: 0.0060
Epoch 35/100
198/198 - 0s - loss: 0.0057
Epoch 36/100
198/198 - 0s - loss: 0.0058
Epoch 37/100
198/198 - 0s - loss: 0.0058
Epoch 38/100
198/198 - 0s - loss: 0.0057
Epoch 39/100
198/198 - 0s - loss: 0.0058
Epoch 40/100
198/198 - 0s - loss: 0.0057
Epoch 41/100
198/198 - 0s - loss: 0.0058
Epoch 42/100
198/198 - 0s - loss: 0.0058
Epoch 43/100
198/198 - 0s - loss: 0.0058
Epoch 44/100
198/198 - 0s - loss: 0.0059
Epoch 45/100
198/198 - 0s - loss: 0.0060
Epoch 46/100
198/198 - 0s - loss: 0.0057
Epoch 47/100
198/198 - 0s - loss: 0.0057
Epoch 48/100
198/198 - 0s - loss: 0.0062
Epoch 49/100
198/198 - 0s - loss: 0.0057
Epoch 50/100
198/198 - 0s - loss: 0.0056
Epoch 51/100
198/198 - 0s - loss: 0.0057
Epoch 52/100
198/198 - 0s - loss: 0.0058
Epoch 53/100
198/198 - 0s - loss: 0.0058
Epoch 54/100
198/198 - 0s - loss: 0.0056
Epoch 55/100
198/198 - 0s - loss: 0.0057
Epoch 56/100
198/198 - 0s - loss: 0.0056
Epoch 57/100
198/198 - 0s - loss: 0.0055
Epoch 58/100
198/198 - 0s - loss: 0.0055
Epoch 59/100
198/198 - 0s - loss: 0.0058
Epoch 60/100
198/198 - 0s - loss: 0.0055
Epoch 61/100
198/198 - 0s - loss: 0.0055
Epoch 62/100
198/198 - 0s - loss: 0.0056
Epoch 63/100
198/198 - 0s - loss: 0.0058
Epoch 64/100
198/198 - 0s - loss: 0.0056
Epoch 65/100
198/198 - 0s - loss: 0.0055
Epoch 66/100
198/198 - 0s - loss: 0.0056
Epoch 67/100
198/198 - 0s - loss: 0.0056
Epoch 68/100
198/198 - 0s - loss: 0.0055
Epoch 69/100
198/198 - 0s - loss: 0.0057
Epoch 70/100
198/198 - 0s - loss: 0.0055
Epoch 71/100
198/198 - 0s - loss: 0.0057
Epoch 72/100
198/198 - 0s - loss: 0.0055
Epoch 73/100
198/198 - 0s - loss: 0.0055
Epoch 74/100
198/198 - 0s - loss: 0.0055
Epoch 75/100
198/198 - 0s - loss: 0.0054
Epoch 76/100
198/198 - 0s - loss: 0.0056
Epoch 77/100
198/198 - 0s - loss: 0.0055
Epoch 78/100
198/198 - 0s - loss: 0.0053
Epoch 79/100
198/198 - 0s - loss: 0.0057
Epoch 80/100
198/198 - 0s - loss: 0.0056
Epoch 81/100
198/198 - 0s - loss: 0.0053
Epoch 82/100
198/198 - 0s - loss: 0.0055
Epoch 83/100
198/198 - 0s - loss: 0.0056
Epoch 84/100
198/198 - 0s - loss: 0.0055
Epoch 85/100
198/198 - 0s - loss: 0.0056
Epoch 86/100
198/198 - 0s - loss: 0.0054
Epoch 87/100
198/198 - 0s - loss: 0.0055
Epoch 88/100
198/198 - 0s - loss: 0.0054
Epoch 89/100
198/198 - 0s - loss: 0.0055
Epoch 90/100
198/198 - 0s - loss: 0.0055
Epoch 91/100
198/198 - 0s - loss: 0.0055
Epoch 92/100
198/198 - 0s - loss: 0.0056
Epoch 93/100
198/198 - 0s - loss: 0.0055
Epoch 94/100
198/198 - 0s - loss: 0.0055
Epoch 95/100
198/198 - 0s - loss: 0.0055
Epoch 96/100
198/198 - 0s - loss: 0.0056
Epoch 97/100
198/198 - 0s - loss: 0.0054
Epoch 98/100
198/198 - 0s - loss: 0.0055
Epoch 99/100
198/198 - 0s - loss: 0.0055
Epoch 100/100
198/198 - 0s - loss: 0.0056

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.075
Train RMSE: 0.158
key_word: bitcoin
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.694444  0.416667  0.333333
2021-07-25  0.555556  0.569444  0.513889  ...  0.944444  0.694444  0.416667
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.944444  0.694444
2021-08-08  0.555556  0.458333  0.555556  ...  0.305556  0.208333  0.944444
2021-08-15  0.444444  0.555556  0.458333  ...  0.541667  0.305556  0.208333

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 8)                 168       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 9         
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0116
Epoch 2/100
198/198 - 0s - loss: 0.0101
Epoch 3/100
198/198 - 0s - loss: 0.0094
Epoch 4/100
198/198 - 0s - loss: 0.0087
Epoch 5/100
198/198 - 0s - loss: 0.0087
Epoch 6/100
198/198 - 0s - loss: 0.0078
Epoch 7/100
198/198 - 0s - loss: 0.0079
Epoch 8/100
198/198 - 0s - loss: 0.0077
Epoch 9/100
198/198 - 0s - loss: 0.0076
Epoch 10/100
198/198 - 0s - loss: 0.0074
Epoch 11/100
198/198 - 0s - loss: 0.0071
Epoch 12/100
198/198 - 0s - loss: 0.0075
Epoch 13/100
198/198 - 0s - loss: 0.0072
Epoch 14/100
198/198 - 0s - loss: 0.0068
Epoch 15/100
198/198 - 0s - loss: 0.0069
Epoch 16/100
198/198 - 0s - loss: 0.0069
Epoch 17/100
198/198 - 0s - loss: 0.0064
Epoch 18/100
198/198 - 0s - loss: 0.0071
Epoch 19/100
198/198 - 0s - loss: 0.0064
Epoch 20/100
198/198 - 0s - loss: 0.0063
Epoch 21/100
198/198 - 0s - loss: 0.0064
Epoch 22/100
198/198 - 0s - loss: 0.0065
Epoch 23/100
198/198 - 0s - loss: 0.0061
Epoch 24/100
198/198 - 0s - loss: 0.0063
Epoch 25/100
198/198 - 0s - loss: 0.0063
Epoch 26/100
198/198 - 0s - loss: 0.0060
Epoch 27/100
198/198 - 0s - loss: 0.0062
Epoch 28/100
198/198 - 0s - loss: 0.0062
Epoch 29/100
198/198 - 0s - loss: 0.0059
Epoch 30/100
198/198 - 0s - loss: 0.0062
Epoch 31/100
198/198 - 0s - loss: 0.0059
Epoch 32/100
198/198 - 0s - loss: 0.0060
Epoch 33/100
198/198 - 0s - loss: 0.0062
Epoch 34/100
198/198 - 0s - loss: 0.0058
Epoch 35/100
198/198 - 0s - loss: 0.0061
Epoch 36/100
198/198 - 0s - loss: 0.0058
Epoch 37/100
198/198 - 0s - loss: 0.0060
Epoch 38/100
198/198 - 0s - loss: 0.0058
Epoch 39/100
198/198 - 0s - loss: 0.0059
Epoch 40/100
198/198 - 0s - loss: 0.0059
Epoch 41/100
198/198 - 0s - loss: 0.0058
Epoch 42/100
198/198 - 0s - loss: 0.0058
Epoch 43/100
198/198 - 0s - loss: 0.0060
Epoch 44/100
198/198 - 0s - loss: 0.0059
Epoch 45/100
198/198 - 0s - loss: 0.0059
Epoch 46/100
198/198 - 0s - loss: 0.0059
Epoch 47/100
198/198 - 0s - loss: 0.0058
Epoch 48/100
198/198 - 0s - loss: 0.0058
Epoch 49/100
198/198 - 0s - loss: 0.0056
Epoch 50/100
198/198 - 0s - loss: 0.0057
Epoch 51/100
198/198 - 0s - loss: 0.0060
Epoch 52/100
198/198 - 0s - loss: 0.0056
Epoch 53/100
198/198 - 0s - loss: 0.0059
Epoch 54/100
198/198 - 0s - loss: 0.0058
Epoch 55/100
198/198 - 0s - loss: 0.0058
Epoch 56/100
198/198 - 0s - loss: 0.0059
Epoch 57/100
198/198 - 0s - loss: 0.0057
Epoch 58/100
198/198 - 0s - loss: 0.0059
Epoch 59/100
198/198 - 0s - loss: 0.0057
Epoch 60/100
198/198 - 0s - loss: 0.0058
Epoch 61/100
198/198 - 0s - loss: 0.0056
Epoch 62/100
198/198 - 0s - loss: 0.0055
Epoch 63/100
198/198 - 0s - loss: 0.0056
Epoch 64/100
198/198 - 0s - loss: 0.0058
Epoch 65/100
198/198 - 0s - loss: 0.0057
Epoch 66/100
198/198 - 0s - loss: 0.0060
Epoch 67/100
198/198 - 0s - loss: 0.0055
Epoch 68/100
198/198 - 0s - loss: 0.0056
Epoch 69/100
198/198 - 0s - loss: 0.0054
Epoch 70/100
198/198 - 0s - loss: 0.0057
Epoch 71/100
198/198 - 0s - loss: 0.0057
Epoch 72/100
198/198 - 0s - loss: 0.0056
Epoch 73/100
198/198 - 0s - loss: 0.0054
Epoch 74/100
198/198 - 0s - loss: 0.0057
Epoch 75/100
198/198 - 0s - loss: 0.0056
Epoch 76/100
198/198 - 0s - loss: 0.0054
Epoch 77/100
198/198 - 0s - loss: 0.0055
Epoch 78/100
198/198 - 0s - loss: 0.0055
Epoch 79/100
198/198 - 0s - loss: 0.0056
Epoch 80/100
198/198 - 0s - loss: 0.0059
Epoch 81/100
198/198 - 0s - loss: 0.0054
Epoch 82/100
198/198 - 0s - loss: 0.0056
Epoch 83/100
198/198 - 0s - loss: 0.0055
Epoch 84/100
198/198 - 0s - loss: 0.0055
Epoch 85/100
198/198 - 0s - loss: 0.0059
Epoch 86/100
198/198 - 0s - loss: 0.0055
Epoch 87/100
198/198 - 0s - loss: 0.0055
Epoch 88/100
198/198 - 0s - loss: 0.0058
Epoch 89/100
198/198 - 0s - loss: 0.0053
Epoch 90/100
198/198 - 0s - loss: 0.0056
Epoch 91/100
198/198 - 0s - loss: 0.0055
Epoch 92/100
198/198 - 0s - loss: 0.0056
Epoch 93/100
198/198 - 0s - loss: 0.0056
Epoch 94/100
198/198 - 0s - loss: 0.0055
Epoch 95/100
198/198 - 0s - loss: 0.0059
Epoch 96/100
198/198 - 0s - loss: 0.0054
Epoch 97/100
198/198 - 0s - loss: 0.0056
Epoch 98/100
198/198 - 0s - loss: 0.0054
Epoch 99/100
198/198 - 0s - loss: 0.0053
Epoch 100/100
198/198 - 0s - loss: 0.0053

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.071
Train RMSE: 0.157
key_word: bitcoin
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.694444  0.416667  0.333333
2021-07-25  0.555556  0.569444  0.513889  ...  0.944444  0.694444  0.416667
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.944444  0.694444
2021-08-08  0.555556  0.458333  0.555556  ...  0.305556  0.208333  0.944444
2021-08-15  0.444444  0.555556  0.458333  ...  0.541667  0.305556  0.208333

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_2 (SimpleRNN)     (None, 16)                464       
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 17        
=================================================================
Total params: 481
Trainable params: 481
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0088
Epoch 2/100
198/198 - 0s - loss: 0.0076
Epoch 3/100
198/198 - 0s - loss: 0.0070
Epoch 4/100
198/198 - 0s - loss: 0.0073
Epoch 5/100
198/198 - 0s - loss: 0.0068
Epoch 6/100
198/198 - 0s - loss: 0.0067
Epoch 7/100
198/198 - 0s - loss: 0.0066
Epoch 8/100
198/198 - 0s - loss: 0.0067
Epoch 9/100
198/198 - 0s - loss: 0.0065
Epoch 10/100
198/198 - 0s - loss: 0.0064
Epoch 11/100
198/198 - 0s - loss: 0.0064
Epoch 12/100
198/198 - 0s - loss: 0.0062
Epoch 13/100
198/198 - 0s - loss: 0.0063
Epoch 14/100
198/198 - 0s - loss: 0.0058
Epoch 15/100
198/198 - 0s - loss: 0.0059
Epoch 16/100
198/198 - 0s - loss: 0.0061
Epoch 17/100
198/198 - 0s - loss: 0.0058
Epoch 18/100
198/198 - 0s - loss: 0.0061
Epoch 19/100
198/198 - 0s - loss: 0.0061
Epoch 20/100
198/198 - 0s - loss: 0.0061
Epoch 21/100
198/198 - 0s - loss: 0.0059
Epoch 22/100
198/198 - 0s - loss: 0.0061
Epoch 23/100
198/198 - 0s - loss: 0.0058
Epoch 24/100
198/198 - 0s - loss: 0.0061
Epoch 25/100
198/198 - 0s - loss: 0.0058
Epoch 26/100
198/198 - 0s - loss: 0.0056
Epoch 27/100
198/198 - 0s - loss: 0.0060
Epoch 28/100
198/198 - 0s - loss: 0.0059
Epoch 29/100
198/198 - 0s - loss: 0.0059
Epoch 30/100
198/198 - 0s - loss: 0.0057
Epoch 31/100
198/198 - 0s - loss: 0.0060
Epoch 32/100
198/198 - 0s - loss: 0.0060
Epoch 33/100
198/198 - 0s - loss: 0.0059
Epoch 34/100
198/198 - 0s - loss: 0.0053
Epoch 35/100
198/198 - 0s - loss: 0.0060
Epoch 36/100
198/198 - 0s - loss: 0.0057
Epoch 37/100
198/198 - 0s - loss: 0.0057
Epoch 38/100
198/198 - 0s - loss: 0.0058
Epoch 39/100
198/198 - 0s - loss: 0.0058
Epoch 40/100
198/198 - 0s - loss: 0.0058
Epoch 41/100
198/198 - 0s - loss: 0.0058
Epoch 42/100
198/198 - 0s - loss: 0.0060
Epoch 43/100
198/198 - 0s - loss: 0.0059
Epoch 44/100
198/198 - 0s - loss: 0.0058
Epoch 45/100
198/198 - 0s - loss: 0.0057
Epoch 46/100
198/198 - 0s - loss: 0.0058
Epoch 47/100
198/198 - 0s - loss: 0.0061
Epoch 48/100
198/198 - 0s - loss: 0.0058
Epoch 49/100
198/198 - 0s - loss: 0.0055
Epoch 50/100
198/198 - 0s - loss: 0.0060
Epoch 51/100
198/198 - 0s - loss: 0.0057
Epoch 52/100
198/198 - 0s - loss: 0.0056
Epoch 53/100
198/198 - 0s - loss: 0.0057
Epoch 54/100
198/198 - 0s - loss: 0.0058
Epoch 55/100
198/198 - 0s - loss: 0.0056
Epoch 56/100
198/198 - 0s - loss: 0.0057
Epoch 57/100
198/198 - 0s - loss: 0.0056
Epoch 58/100
198/198 - 0s - loss: 0.0056
Epoch 59/100
198/198 - 0s - loss: 0.0057
Epoch 60/100
198/198 - 0s - loss: 0.0061
Epoch 61/100
198/198 - 0s - loss: 0.0058
Epoch 62/100
198/198 - 0s - loss: 0.0055
Epoch 63/100
198/198 - 0s - loss: 0.0054
Epoch 64/100
198/198 - 0s - loss: 0.0059
Epoch 65/100
198/198 - 0s - loss: 0.0060
Epoch 66/100
198/198 - 0s - loss: 0.0056
Epoch 67/100
198/198 - 0s - loss: 0.0056
Epoch 68/100
198/198 - 0s - loss: 0.0055
Epoch 69/100
198/198 - 0s - loss: 0.0058
Epoch 70/100
198/198 - 0s - loss: 0.0055
Epoch 71/100
198/198 - 0s - loss: 0.0059
Epoch 72/100
198/198 - 0s - loss: 0.0059
Epoch 73/100
198/198 - 0s - loss: 0.0054
Epoch 74/100
198/198 - 0s - loss: 0.0057
Epoch 75/100
198/198 - 0s - loss: 0.0055
Epoch 76/100
198/198 - 0s - loss: 0.0056
Epoch 77/100
198/198 - 0s - loss: 0.0053
Epoch 78/100
198/198 - 0s - loss: 0.0056
Epoch 79/100
198/198 - 0s - loss: 0.0058
Epoch 80/100
198/198 - 0s - loss: 0.0056
Epoch 81/100
198/198 - 0s - loss: 0.0055
Epoch 82/100
198/198 - 0s - loss: 0.0057
Epoch 83/100
198/198 - 0s - loss: 0.0057
Epoch 84/100
198/198 - 0s - loss: 0.0056
Epoch 85/100
198/198 - 0s - loss: 0.0055
Epoch 86/100
198/198 - 0s - loss: 0.0054
Epoch 87/100
198/198 - 0s - loss: 0.0057
Epoch 88/100
198/198 - 0s - loss: 0.0055
Epoch 89/100
198/198 - 0s - loss: 0.0056
Epoch 90/100
198/198 - 0s - loss: 0.0055
Epoch 91/100
198/198 - 0s - loss: 0.0056
Epoch 92/100
198/198 - 0s - loss: 0.0054
Epoch 93/100
198/198 - 0s - loss: 0.0056
Epoch 94/100
198/198 - 0s - loss: 0.0056
Epoch 95/100
198/198 - 0s - loss: 0.0054
Epoch 96/100
198/198 - 0s - loss: 0.0056
Epoch 97/100
198/198 - 0s - loss: 0.0055
Epoch 98/100
198/198 - 0s - loss: 0.0056
Epoch 99/100
198/198 - 0s - loss: 0.0054
Epoch 100/100
198/198 - 0s - loss: 0.0053

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.073
Train RMSE: 0.159
key_word: bitcoin
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.694444  0.416667  0.333333
2021-07-25  0.555556  0.569444  0.513889  ...  0.944444  0.694444  0.416667
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.944444  0.694444
2021-08-08  0.555556  0.458333  0.555556  ...  0.305556  0.208333  0.944444
2021-08-15  0.444444  0.555556  0.458333  ...  0.541667  0.305556  0.208333

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_3 (SimpleRNN)     (None, 32)                1440      
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,473
Trainable params: 1,473
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0111
Epoch 2/100
198/198 - 0s - loss: 0.0092
Epoch 3/100
198/198 - 0s - loss: 0.0085
Epoch 4/100
198/198 - 0s - loss: 0.0088
Epoch 5/100
198/198 - 0s - loss: 0.0079
Epoch 6/100
198/198 - 0s - loss: 0.0077
Epoch 7/100
198/198 - 0s - loss: 0.0073
Epoch 8/100
198/198 - 0s - loss: 0.0071
Epoch 9/100
198/198 - 0s - loss: 0.0067
Epoch 10/100
198/198 - 0s - loss: 0.0068
Epoch 11/100
198/198 - 0s - loss: 0.0072
Epoch 12/100
198/198 - 0s - loss: 0.0071
Epoch 13/100
198/198 - 0s - loss: 0.0067
Epoch 14/100
198/198 - 0s - loss: 0.0064
Epoch 15/100
198/198 - 0s - loss: 0.0074
Epoch 16/100
198/198 - 0s - loss: 0.0075
Epoch 17/100
198/198 - 0s - loss: 0.0068
Epoch 18/100
198/198 - 0s - loss: 0.0068
Epoch 19/100
198/198 - 0s - loss: 0.0067
Epoch 20/100
198/198 - 0s - loss: 0.0068
Epoch 21/100
198/198 - 0s - loss: 0.0063
Epoch 22/100
198/198 - 0s - loss: 0.0064
Epoch 23/100
198/198 - 0s - loss: 0.0065
Epoch 24/100
198/198 - 0s - loss: 0.0063
Epoch 25/100
198/198 - 0s - loss: 0.0064
Epoch 26/100
198/198 - 0s - loss: 0.0064
Epoch 27/100
198/198 - 0s - loss: 0.0064
Epoch 28/100
198/198 - 0s - loss: 0.0064
Epoch 29/100
198/198 - 0s - loss: 0.0061
Epoch 30/100
198/198 - 0s - loss: 0.0061
Epoch 31/100
198/198 - 0s - loss: 0.0067
Epoch 32/100
198/198 - 0s - loss: 0.0061
Epoch 33/100
198/198 - 0s - loss: 0.0063
Epoch 34/100
198/198 - 0s - loss: 0.0059
Epoch 35/100
198/198 - 0s - loss: 0.0069
Epoch 36/100
198/198 - 0s - loss: 0.0059
Epoch 37/100
198/198 - 0s - loss: 0.0063
Epoch 38/100
198/198 - 0s - loss: 0.0065
Epoch 39/100
198/198 - 0s - loss: 0.0056
Epoch 40/100
198/198 - 0s - loss: 0.0061
Epoch 41/100
198/198 - 0s - loss: 0.0062
Epoch 42/100
198/198 - 0s - loss: 0.0063
Epoch 43/100
198/198 - 0s - loss: 0.0063
Epoch 44/100
198/198 - 0s - loss: 0.0060
Epoch 45/100
198/198 - 0s - loss: 0.0058
Epoch 46/100
198/198 - 0s - loss: 0.0060
Epoch 47/100
198/198 - 0s - loss: 0.0055
Epoch 48/100
198/198 - 0s - loss: 0.0064
Epoch 49/100
198/198 - 0s - loss: 0.0059
Epoch 50/100
198/198 - 0s - loss: 0.0060
Epoch 51/100
198/198 - 0s - loss: 0.0062
Epoch 52/100
198/198 - 0s - loss: 0.0067
Epoch 53/100
198/198 - 0s - loss: 0.0058
Epoch 54/100
198/198 - 0s - loss: 0.0062
Epoch 55/100
198/198 - 0s - loss: 0.0060
Epoch 56/100
198/198 - 0s - loss: 0.0055
Epoch 57/100
198/198 - 0s - loss: 0.0058
Epoch 58/100
198/198 - 0s - loss: 0.0059
Epoch 59/100
198/198 - 0s - loss: 0.0064
Epoch 60/100
198/198 - 0s - loss: 0.0061
Epoch 61/100
198/198 - 0s - loss: 0.0059
Epoch 62/100
198/198 - 0s - loss: 0.0059
Epoch 63/100
198/198 - 0s - loss: 0.0055
Epoch 64/100
198/198 - 0s - loss: 0.0058
Epoch 65/100
198/198 - 0s - loss: 0.0053
Epoch 66/100
198/198 - 0s - loss: 0.0059
Epoch 67/100
198/198 - 0s - loss: 0.0062
Epoch 68/100
198/198 - 0s - loss: 0.0059
Epoch 69/100
198/198 - 0s - loss: 0.0060
Epoch 70/100
198/198 - 0s - loss: 0.0062
Epoch 71/100
198/198 - 0s - loss: 0.0057
Epoch 72/100
198/198 - 0s - loss: 0.0060
Epoch 73/100
198/198 - 0s - loss: 0.0058
Epoch 74/100
198/198 - 0s - loss: 0.0060
Epoch 75/100
198/198 - 0s - loss: 0.0062
Epoch 76/100
198/198 - 0s - loss: 0.0061
Epoch 77/100
198/198 - 0s - loss: 0.0056
Epoch 78/100
198/198 - 0s - loss: 0.0058
Epoch 79/100
198/198 - 0s - loss: 0.0056
Epoch 80/100
198/198 - 0s - loss: 0.0059
Epoch 81/100
198/198 - 0s - loss: 0.0058
Epoch 82/100
198/198 - 0s - loss: 0.0054
Epoch 83/100
198/198 - 0s - loss: 0.0057
Epoch 84/100
198/198 - 0s - loss: 0.0061
Epoch 85/100
198/198 - 0s - loss: 0.0056
Epoch 86/100
198/198 - 0s - loss: 0.0056
Epoch 87/100
198/198 - 0s - loss: 0.0060
Epoch 88/100
198/198 - 0s - loss: 0.0058
Epoch 89/100
198/198 - 0s - loss: 0.0059
Epoch 90/100
198/198 - 0s - loss: 0.0056
Epoch 91/100
198/198 - 0s - loss: 0.0056
Epoch 92/100
198/198 - 0s - loss: 0.0058
Epoch 93/100
198/198 - 0s - loss: 0.0061
Epoch 94/100
198/198 - 0s - loss: 0.0054
Epoch 95/100
198/198 - 0s - loss: 0.0056
Epoch 96/100
198/198 - 0s - loss: 0.0059
Epoch 97/100
198/198 - 0s - loss: 0.0056
Epoch 98/100
198/198 - 0s - loss: 0.0055
Epoch 99/100
198/198 - 0s - loss: 0.0058
Epoch 100/100
198/198 - 0s - loss: 0.0055

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.073
Train RMSE: 0.156
key_word: bitcoin
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.694444  0.416667  0.333333
2021-07-25  0.555556  0.569444  0.513889  ...  0.944444  0.694444  0.416667
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.944444  0.694444
2021-08-08  0.555556  0.458333  0.555556  ...  0.305556  0.208333  0.944444
2021-08-15  0.444444  0.555556  0.458333  ...  0.541667  0.305556  0.208333

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_4 (SimpleRNN)     (None, 60)                4380      
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 61        
=================================================================
Total params: 4,441
Trainable params: 4,441
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0135
Epoch 2/100
198/198 - 0s - loss: 0.0114
Epoch 3/100
198/198 - 0s - loss: 0.0094
Epoch 4/100
198/198 - 0s - loss: 0.0097
Epoch 5/100
198/198 - 0s - loss: 0.0081
Epoch 6/100
198/198 - 0s - loss: 0.0085
Epoch 7/100
198/198 - 0s - loss: 0.0079
Epoch 8/100
198/198 - 0s - loss: 0.0068
Epoch 9/100
198/198 - 0s - loss: 0.0082
Epoch 10/100
198/198 - 0s - loss: 0.0068
Epoch 11/100
198/198 - 0s - loss: 0.0080
Epoch 12/100
198/198 - 0s - loss: 0.0080
Epoch 13/100
198/198 - 0s - loss: 0.0068
Epoch 14/100
198/198 - 0s - loss: 0.0079
Epoch 15/100
198/198 - 0s - loss: 0.0067
Epoch 16/100
198/198 - 0s - loss: 0.0074
Epoch 17/100
198/198 - 0s - loss: 0.0072
Epoch 18/100
198/198 - 0s - loss: 0.0075
Epoch 19/100
198/198 - 0s - loss: 0.0075
Epoch 20/100
198/198 - 0s - loss: 0.0071
Epoch 21/100
198/198 - 0s - loss: 0.0071
Epoch 22/100
198/198 - 0s - loss: 0.0067
Epoch 23/100
198/198 - 0s - loss: 0.0079
Epoch 24/100
198/198 - 0s - loss: 0.0069
Epoch 25/100
198/198 - 0s - loss: 0.0073
Epoch 26/100
198/198 - 0s - loss: 0.0067
Epoch 27/100
198/198 - 0s - loss: 0.0061
Epoch 28/100
198/198 - 0s - loss: 0.0072
Epoch 29/100
198/198 - 0s - loss: 0.0074
Epoch 30/100
198/198 - 0s - loss: 0.0066
Epoch 31/100
198/198 - 0s - loss: 0.0065
Epoch 32/100
198/198 - 0s - loss: 0.0066
Epoch 33/100
198/198 - 0s - loss: 0.0070
Epoch 34/100
198/198 - 0s - loss: 0.0069
Epoch 35/100
198/198 - 0s - loss: 0.0063
Epoch 36/100
198/198 - 0s - loss: 0.0067
Epoch 37/100
198/198 - 0s - loss: 0.0062
Epoch 38/100
198/198 - 0s - loss: 0.0065
Epoch 39/100
198/198 - 0s - loss: 0.0066
Epoch 40/100
198/198 - 0s - loss: 0.0076
Epoch 41/100
198/198 - 0s - loss: 0.0062
Epoch 42/100
198/198 - 0s - loss: 0.0062
Epoch 43/100
198/198 - 0s - loss: 0.0064
Epoch 44/100
198/198 - 0s - loss: 0.0062
Epoch 45/100
198/198 - 0s - loss: 0.0064
Epoch 46/100
198/198 - 0s - loss: 0.0064
Epoch 47/100
198/198 - 0s - loss: 0.0068
Epoch 48/100
198/198 - 0s - loss: 0.0060
Epoch 49/100
198/198 - 0s - loss: 0.0064
Epoch 50/100
198/198 - 0s - loss: 0.0060
Epoch 51/100
198/198 - 0s - loss: 0.0061
Epoch 52/100
198/198 - 0s - loss: 0.0066
Epoch 53/100
198/198 - 0s - loss: 0.0064
Epoch 54/100
198/198 - 0s - loss: 0.0066
Epoch 55/100
198/198 - 0s - loss: 0.0064
Epoch 56/100
198/198 - 0s - loss: 0.0062
Epoch 57/100
198/198 - 0s - loss: 0.0063
Epoch 58/100
198/198 - 0s - loss: 0.0065
Epoch 59/100
198/198 - 0s - loss: 0.0060
Epoch 60/100
198/198 - 0s - loss: 0.0065
Epoch 61/100
198/198 - 0s - loss: 0.0065
Epoch 62/100
198/198 - 0s - loss: 0.0065
Epoch 63/100
198/198 - 0s - loss: 0.0060
Epoch 64/100
198/198 - 0s - loss: 0.0063
Epoch 65/100
198/198 - 0s - loss: 0.0062
Epoch 66/100
198/198 - 0s - loss: 0.0060
Epoch 67/100
198/198 - 0s - loss: 0.0061
Epoch 68/100
198/198 - 0s - loss: 0.0063
Epoch 69/100
198/198 - 0s - loss: 0.0057
Epoch 70/100
198/198 - 0s - loss: 0.0060
Epoch 71/100
198/198 - 0s - loss: 0.0059
Epoch 72/100
198/198 - 0s - loss: 0.0059
Epoch 73/100
198/198 - 0s - loss: 0.0061
Epoch 74/100
198/198 - 0s - loss: 0.0065
Epoch 75/100
198/198 - 0s - loss: 0.0061
Epoch 76/100
198/198 - 0s - loss: 0.0057
Epoch 77/100
198/198 - 0s - loss: 0.0064
Epoch 78/100
198/198 - 0s - loss: 0.0062
Epoch 79/100
198/198 - 0s - loss: 0.0063
Epoch 80/100
198/198 - 0s - loss: 0.0057
Epoch 81/100
198/198 - 0s - loss: 0.0062
Epoch 82/100
198/198 - 0s - loss: 0.0057
Epoch 83/100
198/198 - 0s - loss: 0.0061
Epoch 84/100
198/198 - 0s - loss: 0.0054
Epoch 85/100
198/198 - 0s - loss: 0.0058
Epoch 86/100
198/198 - 0s - loss: 0.0057
Epoch 87/100
198/198 - 0s - loss: 0.0063
Epoch 88/100
198/198 - 0s - loss: 0.0056
Epoch 89/100
198/198 - 0s - loss: 0.0058
Epoch 90/100
198/198 - 0s - loss: 0.0057
Epoch 91/100
198/198 - 0s - loss: 0.0058
Epoch 92/100
198/198 - 0s - loss: 0.0058
Epoch 93/100
198/198 - 0s - loss: 0.0056
Epoch 94/100
198/198 - 0s - loss: 0.0056
Epoch 95/100
198/198 - 0s - loss: 0.0057
Epoch 96/100
198/198 - 0s - loss: 0.0058
Epoch 97/100
198/198 - 0s - loss: 0.0060
Epoch 98/100
198/198 - 0s - loss: 0.0056
Epoch 99/100
198/198 - 0s - loss: 0.0059
Epoch 100/100
198/198 - 0s - loss: 0.0057

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.074
Train RMSE: 0.159
key_word: bitcoin
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.486111  0.847222  0.458333
2021-07-25  0.555556  0.569444  0.513889  ...  0.597222  0.486111  0.847222
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.597222  0.486111
2021-08-08  0.555556  0.458333  0.555556  ...  0.541667  0.208333  0.597222
2021-08-15  0.444444  0.555556  0.458333  ...  0.486111  0.541667  0.208333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_5 (SimpleRNN)     (None, 4)                 116       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 5         
=================================================================
Total params: 121
Trainable params: 121
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0230
Epoch 2/100
188/188 - 0s - loss: 0.0185
Epoch 3/100
188/188 - 0s - loss: 0.0194
Epoch 4/100
188/188 - 0s - loss: 0.0173
Epoch 5/100
188/188 - 0s - loss: 0.0141
Epoch 6/100
188/188 - 0s - loss: 0.0138
Epoch 7/100
188/188 - 0s - loss: 0.0123
Epoch 8/100
188/188 - 0s - loss: 0.0116
Epoch 9/100
188/188 - 0s - loss: 0.0114
Epoch 10/100
188/188 - 0s - loss: 0.0101
Epoch 11/100
188/188 - 0s - loss: 0.0096
Epoch 12/100
188/188 - 0s - loss: 0.0100
Epoch 13/100
188/188 - 0s - loss: 0.0085
Epoch 14/100
188/188 - 0s - loss: 0.0084
Epoch 15/100
188/188 - 0s - loss: 0.0084
Epoch 16/100
188/188 - 0s - loss: 0.0087
Epoch 17/100
188/188 - 0s - loss: 0.0084
Epoch 18/100
188/188 - 0s - loss: 0.0074
Epoch 19/100
188/188 - 0s - loss: 0.0073
Epoch 20/100
188/188 - 0s - loss: 0.0067
Epoch 21/100
188/188 - 0s - loss: 0.0076
Epoch 22/100
188/188 - 0s - loss: 0.0071
Epoch 23/100
188/188 - 0s - loss: 0.0066
Epoch 24/100
188/188 - 0s - loss: 0.0068
Epoch 25/100
188/188 - 0s - loss: 0.0066
Epoch 26/100
188/188 - 0s - loss: 0.0062
Epoch 27/100
188/188 - 0s - loss: 0.0063
Epoch 28/100
188/188 - 0s - loss: 0.0062
Epoch 29/100
188/188 - 0s - loss: 0.0063
Epoch 30/100
188/188 - 0s - loss: 0.0061
Epoch 31/100
188/188 - 0s - loss: 0.0060
Epoch 32/100
188/188 - 0s - loss: 0.0061
Epoch 33/100
188/188 - 0s - loss: 0.0061
Epoch 34/100
188/188 - 0s - loss: 0.0064
Epoch 35/100
188/188 - 0s - loss: 0.0057
Epoch 36/100
188/188 - 0s - loss: 0.0060
Epoch 37/100
188/188 - 0s - loss: 0.0060
Epoch 38/100
188/188 - 0s - loss: 0.0059
Epoch 39/100
188/188 - 0s - loss: 0.0061
Epoch 40/100
188/188 - 0s - loss: 0.0060
Epoch 41/100
188/188 - 0s - loss: 0.0055
Epoch 42/100
188/188 - 0s - loss: 0.0060
Epoch 43/100
188/188 - 0s - loss: 0.0061
Epoch 44/100
188/188 - 0s - loss: 0.0056
Epoch 45/100
188/188 - 0s - loss: 0.0059
Epoch 46/100
188/188 - 0s - loss: 0.0061
Epoch 47/100
188/188 - 0s - loss: 0.0055
Epoch 48/100
188/188 - 0s - loss: 0.0054
Epoch 49/100
188/188 - 0s - loss: 0.0061
Epoch 50/100
188/188 - 0s - loss: 0.0057
Epoch 51/100
188/188 - 0s - loss: 0.0059
Epoch 52/100
188/188 - 0s - loss: 0.0058
Epoch 53/100
188/188 - 0s - loss: 0.0052
Epoch 54/100
188/188 - 0s - loss: 0.0055
Epoch 55/100
188/188 - 0s - loss: 0.0057
Epoch 56/100
188/188 - 0s - loss: 0.0055
Epoch 57/100
188/188 - 0s - loss: 0.0055
Epoch 58/100
188/188 - 0s - loss: 0.0056
Epoch 59/100
188/188 - 0s - loss: 0.0057
Epoch 60/100
188/188 - 0s - loss: 0.0057
Epoch 61/100
188/188 - 0s - loss: 0.0054
Epoch 62/100
188/188 - 0s - loss: 0.0057
Epoch 63/100
188/188 - 0s - loss: 0.0053
Epoch 64/100
188/188 - 0s - loss: 0.0054
Epoch 65/100
188/188 - 0s - loss: 0.0053
Epoch 66/100
188/188 - 0s - loss: 0.0061
Epoch 67/100
188/188 - 0s - loss: 0.0056
Epoch 68/100
188/188 - 0s - loss: 0.0057
Epoch 69/100
188/188 - 0s - loss: 0.0052
Epoch 70/100
188/188 - 0s - loss: 0.0055
Epoch 71/100
188/188 - 0s - loss: 0.0053
Epoch 72/100
188/188 - 0s - loss: 0.0056
Epoch 73/100
188/188 - 0s - loss: 0.0053
Epoch 74/100
188/188 - 0s - loss: 0.0053
Epoch 75/100
188/188 - 0s - loss: 0.0053
Epoch 76/100
188/188 - 0s - loss: 0.0054
Epoch 77/100
188/188 - 0s - loss: 0.0052
Epoch 78/100
188/188 - 0s - loss: 0.0052
Epoch 79/100
188/188 - 0s - loss: 0.0053
Epoch 80/100
188/188 - 0s - loss: 0.0054
Epoch 81/100
188/188 - 0s - loss: 0.0057
Epoch 82/100
188/188 - 0s - loss: 0.0053
Epoch 83/100
188/188 - 0s - loss: 0.0054
Epoch 84/100
188/188 - 0s - loss: 0.0052
Epoch 85/100
188/188 - 0s - loss: 0.0053
Epoch 86/100
188/188 - 0s - loss: 0.0054
Epoch 87/100
188/188 - 0s - loss: 0.0054
Epoch 88/100
188/188 - 0s - loss: 0.0051
Epoch 89/100
188/188 - 0s - loss: 0.0052
Epoch 90/100
188/188 - 0s - loss: 0.0053
Epoch 91/100
188/188 - 0s - loss: 0.0055
Epoch 92/100
188/188 - 0s - loss: 0.0053
Epoch 93/100
188/188 - 0s - loss: 0.0051
Epoch 94/100
188/188 - 0s - loss: 0.0053
Epoch 95/100
188/188 - 0s - loss: 0.0053
Epoch 96/100
188/188 - 0s - loss: 0.0054
Epoch 97/100
188/188 - 0s - loss: 0.0050
Epoch 98/100
188/188 - 0s - loss: 0.0053
Epoch 99/100
188/188 - 0s - loss: 0.0053
Epoch 100/100
188/188 - 0s - loss: 0.0052

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.068
Train RMSE: 0.162
key_word: bitcoin
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.486111  0.847222  0.458333
2021-07-25  0.555556  0.569444  0.513889  ...  0.597222  0.486111  0.847222
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.597222  0.486111
2021-08-08  0.555556  0.458333  0.555556  ...  0.541667  0.208333  0.597222
2021-08-15  0.444444  0.555556  0.458333  ...  0.486111  0.541667  0.208333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_6 (SimpleRNN)     (None, 8)                 264       
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 9         
=================================================================
Total params: 273
Trainable params: 273
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0133
Epoch 2/100
188/188 - 0s - loss: 0.0121
Epoch 3/100
188/188 - 0s - loss: 0.0098
Epoch 4/100
188/188 - 0s - loss: 0.0101
Epoch 5/100
188/188 - 0s - loss: 0.0093
Epoch 6/100
188/188 - 0s - loss: 0.0082
Epoch 7/100
188/188 - 0s - loss: 0.0086
Epoch 8/100
188/188 - 0s - loss: 0.0077
Epoch 9/100
188/188 - 0s - loss: 0.0077
Epoch 10/100
188/188 - 0s - loss: 0.0073
Epoch 11/100
188/188 - 0s - loss: 0.0071
Epoch 12/100
188/188 - 0s - loss: 0.0068
Epoch 13/100
188/188 - 0s - loss: 0.0070
Epoch 14/100
188/188 - 0s - loss: 0.0070
Epoch 15/100
188/188 - 0s - loss: 0.0069
Epoch 16/100
188/188 - 0s - loss: 0.0073
Epoch 17/100
188/188 - 0s - loss: 0.0063
Epoch 18/100
188/188 - 0s - loss: 0.0064
Epoch 19/100
188/188 - 0s - loss: 0.0063
Epoch 20/100
188/188 - 0s - loss: 0.0067
Epoch 21/100
188/188 - 0s - loss: 0.0064
Epoch 22/100
188/188 - 0s - loss: 0.0062
Epoch 23/100
188/188 - 0s - loss: 0.0062
Epoch 24/100
188/188 - 0s - loss: 0.0063
Epoch 25/100
188/188 - 0s - loss: 0.0065
Epoch 26/100
188/188 - 0s - loss: 0.0063
Epoch 27/100
188/188 - 0s - loss: 0.0063
Epoch 28/100
188/188 - 0s - loss: 0.0061
Epoch 29/100
188/188 - 0s - loss: 0.0061
Epoch 30/100
188/188 - 0s - loss: 0.0059
Epoch 31/100
188/188 - 0s - loss: 0.0060
Epoch 32/100
188/188 - 0s - loss: 0.0061
Epoch 33/100
188/188 - 0s - loss: 0.0060
Epoch 34/100
188/188 - 0s - loss: 0.0061
Epoch 35/100
188/188 - 0s - loss: 0.0059
Epoch 36/100
188/188 - 0s - loss: 0.0060
Epoch 37/100
188/188 - 0s - loss: 0.0061
Epoch 38/100
188/188 - 0s - loss: 0.0059
Epoch 39/100
188/188 - 0s - loss: 0.0060
Epoch 40/100
188/188 - 0s - loss: 0.0063
Epoch 41/100
188/188 - 0s - loss: 0.0060
Epoch 42/100
188/188 - 0s - loss: 0.0057
Epoch 43/100
188/188 - 0s - loss: 0.0059
Epoch 44/100
188/188 - 0s - loss: 0.0062
Epoch 45/100
188/188 - 0s - loss: 0.0058
Epoch 46/100
188/188 - 0s - loss: 0.0059
Epoch 47/100
188/188 - 0s - loss: 0.0059
Epoch 48/100
188/188 - 0s - loss: 0.0060
Epoch 49/100
188/188 - 0s - loss: 0.0058
Epoch 50/100
188/188 - 0s - loss: 0.0059
Epoch 51/100
188/188 - 0s - loss: 0.0059
Epoch 52/100
188/188 - 0s - loss: 0.0059
Epoch 53/100
188/188 - 0s - loss: 0.0058
Epoch 54/100
188/188 - 0s - loss: 0.0057
Epoch 55/100
188/188 - 0s - loss: 0.0059
Epoch 56/100
188/188 - 0s - loss: 0.0060
Epoch 57/100
188/188 - 0s - loss: 0.0058
Epoch 58/100
188/188 - 0s - loss: 0.0058
Epoch 59/100
188/188 - 0s - loss: 0.0057
Epoch 60/100
188/188 - 0s - loss: 0.0057
Epoch 61/100
188/188 - 0s - loss: 0.0058
Epoch 62/100
188/188 - 0s - loss: 0.0062
Epoch 63/100
188/188 - 0s - loss: 0.0058
Epoch 64/100
188/188 - 0s - loss: 0.0059
Epoch 65/100
188/188 - 0s - loss: 0.0060
Epoch 66/100
188/188 - 0s - loss: 0.0057
Epoch 67/100
188/188 - 0s - loss: 0.0059
Epoch 68/100
188/188 - 0s - loss: 0.0059
Epoch 69/100
188/188 - 0s - loss: 0.0059
Epoch 70/100
188/188 - 0s - loss: 0.0056
Epoch 71/100
188/188 - 0s - loss: 0.0055
Epoch 72/100
188/188 - 0s - loss: 0.0056
Epoch 73/100
188/188 - 0s - loss: 0.0059
Epoch 74/100
188/188 - 0s - loss: 0.0057
Epoch 75/100
188/188 - 0s - loss: 0.0056
Epoch 76/100
188/188 - 0s - loss: 0.0060
Epoch 77/100
188/188 - 0s - loss: 0.0059
Epoch 78/100
188/188 - 0s - loss: 0.0057
Epoch 79/100
188/188 - 0s - loss: 0.0061
Epoch 80/100
188/188 - 0s - loss: 0.0056
Epoch 81/100
188/188 - 0s - loss: 0.0056
Epoch 82/100
188/188 - 0s - loss: 0.0060
Epoch 83/100
188/188 - 0s - loss: 0.0058
Epoch 84/100
188/188 - 0s - loss: 0.0058
Epoch 85/100
188/188 - 0s - loss: 0.0058
Epoch 86/100
188/188 - 0s - loss: 0.0059
Epoch 87/100
188/188 - 0s - loss: 0.0056
Epoch 88/100
188/188 - 0s - loss: 0.0058
Epoch 89/100
188/188 - 0s - loss: 0.0057
Epoch 90/100
188/188 - 0s - loss: 0.0061
Epoch 91/100
188/188 - 0s - loss: 0.0056
Epoch 92/100
188/188 - 0s - loss: 0.0058
Epoch 93/100
188/188 - 0s - loss: 0.0058
Epoch 94/100
188/188 - 0s - loss: 0.0060
Epoch 95/100
188/188 - 0s - loss: 0.0060
Epoch 96/100
188/188 - 0s - loss: 0.0056
Epoch 97/100
188/188 - 0s - loss: 0.0055
Epoch 98/100
188/188 - 0s - loss: 0.0056
Epoch 99/100
188/188 - 0s - loss: 0.0057
Epoch 100/100
188/188 - 0s - loss: 0.0053

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.082
Train RMSE: 0.155
key_word: bitcoin
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.486111  0.847222  0.458333
2021-07-25  0.555556  0.569444  0.513889  ...  0.597222  0.486111  0.847222
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.597222  0.486111
2021-08-08  0.555556  0.458333  0.555556  ...  0.541667  0.208333  0.597222
2021-08-15  0.444444  0.555556  0.458333  ...  0.486111  0.541667  0.208333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_7 (SimpleRNN)     (None, 16)                656       
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 17        
=================================================================
Total params: 673
Trainable params: 673
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0665
Epoch 2/100
188/188 - 0s - loss: 0.0173
Epoch 3/100
188/188 - 0s - loss: 0.0149
Epoch 4/100
188/188 - 0s - loss: 0.0153
Epoch 5/100
188/188 - 0s - loss: 0.0120
Epoch 6/100
188/188 - 0s - loss: 0.0128
Epoch 7/100
188/188 - 0s - loss: 0.0111
Epoch 8/100
188/188 - 0s - loss: 0.0105
Epoch 9/100
188/188 - 0s - loss: 0.0094
Epoch 10/100
188/188 - 0s - loss: 0.0090
Epoch 11/100
188/188 - 0s - loss: 0.0087
Epoch 12/100
188/188 - 0s - loss: 0.0085
Epoch 13/100
188/188 - 0s - loss: 0.0085
Epoch 14/100
188/188 - 0s - loss: 0.0078
Epoch 15/100
188/188 - 0s - loss: 0.0075
Epoch 16/100
188/188 - 0s - loss: 0.0072
Epoch 17/100
188/188 - 0s - loss: 0.0070
Epoch 18/100
188/188 - 0s - loss: 0.0069
Epoch 19/100
188/188 - 0s - loss: 0.0076
Epoch 20/100
188/188 - 0s - loss: 0.0073
Epoch 21/100
188/188 - 0s - loss: 0.0069
Epoch 22/100
188/188 - 0s - loss: 0.0066
Epoch 23/100
188/188 - 0s - loss: 0.0067
Epoch 24/100
188/188 - 0s - loss: 0.0069
Epoch 25/100
188/188 - 0s - loss: 0.0061
Epoch 26/100
188/188 - 0s - loss: 0.0064
Epoch 27/100
188/188 - 0s - loss: 0.0073
Epoch 28/100
188/188 - 0s - loss: 0.0065
Epoch 29/100
188/188 - 0s - loss: 0.0068
Epoch 30/100
188/188 - 0s - loss: 0.0067
Epoch 31/100
188/188 - 0s - loss: 0.0063
Epoch 32/100
188/188 - 0s - loss: 0.0068
Epoch 33/100
188/188 - 0s - loss: 0.0064
Epoch 34/100
188/188 - 0s - loss: 0.0061
Epoch 35/100
188/188 - 0s - loss: 0.0067
Epoch 36/100
188/188 - 0s - loss: 0.0065
Epoch 37/100
188/188 - 0s - loss: 0.0055
Epoch 38/100
188/188 - 0s - loss: 0.0061
Epoch 39/100
188/188 - 0s - loss: 0.0062
Epoch 40/100
188/188 - 0s - loss: 0.0065
Epoch 41/100
188/188 - 0s - loss: 0.0062
Epoch 42/100
188/188 - 0s - loss: 0.0060
Epoch 43/100
188/188 - 0s - loss: 0.0061
Epoch 44/100
188/188 - 0s - loss: 0.0065
Epoch 45/100
188/188 - 0s - loss: 0.0059
Epoch 46/100
188/188 - 0s - loss: 0.0061
Epoch 47/100
188/188 - 0s - loss: 0.0067
Epoch 48/100
188/188 - 0s - loss: 0.0058
Epoch 49/100
188/188 - 0s - loss: 0.0057
Epoch 50/100
188/188 - 0s - loss: 0.0063
Epoch 51/100
188/188 - 0s - loss: 0.0061
Epoch 52/100
188/188 - 0s - loss: 0.0063
Epoch 53/100
188/188 - 0s - loss: 0.0060
Epoch 54/100
188/188 - 0s - loss: 0.0065
Epoch 55/100
188/188 - 0s - loss: 0.0065
Epoch 56/100
188/188 - 0s - loss: 0.0058
Epoch 57/100
188/188 - 0s - loss: 0.0055
Epoch 58/100
188/188 - 0s - loss: 0.0062
Epoch 59/100
188/188 - 0s - loss: 0.0057
Epoch 60/100
188/188 - 0s - loss: 0.0058
Epoch 61/100
188/188 - 0s - loss: 0.0056
Epoch 62/100
188/188 - 0s - loss: 0.0056
Epoch 63/100
188/188 - 0s - loss: 0.0059
Epoch 64/100
188/188 - 0s - loss: 0.0071
Epoch 65/100
188/188 - 0s - loss: 0.0059
Epoch 66/100
188/188 - 0s - loss: 0.0060
Epoch 67/100
188/188 - 0s - loss: 0.0056
Epoch 68/100
188/188 - 0s - loss: 0.0057
Epoch 69/100
188/188 - 0s - loss: 0.0059
Epoch 70/100
188/188 - 0s - loss: 0.0054
Epoch 71/100
188/188 - 0s - loss: 0.0061
Epoch 72/100
188/188 - 0s - loss: 0.0065
Epoch 73/100
188/188 - 0s - loss: 0.0063
Epoch 74/100
188/188 - 0s - loss: 0.0063
Epoch 75/100
188/188 - 0s - loss: 0.0057
Epoch 76/100
188/188 - 0s - loss: 0.0058
Epoch 77/100
188/188 - 0s - loss: 0.0059
Epoch 78/100
188/188 - 0s - loss: 0.0060
Epoch 79/100
188/188 - 0s - loss: 0.0057
Epoch 80/100
188/188 - 0s - loss: 0.0061
Epoch 81/100
188/188 - 0s - loss: 0.0055
Epoch 82/100
188/188 - 0s - loss: 0.0058
Epoch 83/100
188/188 - 0s - loss: 0.0056
Epoch 84/100
188/188 - 0s - loss: 0.0061
Epoch 85/100
188/188 - 0s - loss: 0.0063
Epoch 86/100
188/188 - 0s - loss: 0.0058
Epoch 87/100
188/188 - 0s - loss: 0.0055
Epoch 88/100
188/188 - 0s - loss: 0.0056
Epoch 89/100
188/188 - 0s - loss: 0.0056
Epoch 90/100
188/188 - 0s - loss: 0.0057
Epoch 91/100
188/188 - 0s - loss: 0.0056
Epoch 92/100
188/188 - 0s - loss: 0.0057
Epoch 93/100
188/188 - 0s - loss: 0.0056
Epoch 94/100
188/188 - 0s - loss: 0.0057
Epoch 95/100
188/188 - 0s - loss: 0.0056
Epoch 96/100
188/188 - 0s - loss: 0.0060
Epoch 97/100
188/188 - 0s - loss: 0.0056
Epoch 98/100
188/188 - 0s - loss: 0.0054
Epoch 99/100
188/188 - 0s - loss: 0.0058
Epoch 100/100
188/188 - 0s - loss: 0.0056

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.082
Train RMSE: 0.162
key_word: bitcoin
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.486111  0.847222  0.458333
2021-07-25  0.555556  0.569444  0.513889  ...  0.597222  0.486111  0.847222
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.597222  0.486111
2021-08-08  0.555556  0.458333  0.555556  ...  0.541667  0.208333  0.597222
2021-08-15  0.444444  0.555556  0.458333  ...  0.486111  0.541667  0.208333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_8 (SimpleRNN)     (None, 32)                1824      
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 33        
=================================================================
Total params: 1,857
Trainable params: 1,857
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0215
Epoch 2/100
188/188 - 0s - loss: 0.0163
Epoch 3/100
188/188 - 0s - loss: 0.0137
Epoch 4/100
188/188 - 0s - loss: 0.0111
Epoch 5/100
188/188 - 0s - loss: 0.0114
Epoch 6/100
188/188 - 0s - loss: 0.0098
Epoch 7/100
188/188 - 0s - loss: 0.0086
Epoch 8/100
188/188 - 0s - loss: 0.0083
Epoch 9/100
188/188 - 0s - loss: 0.0091
Epoch 10/100
188/188 - 0s - loss: 0.0077
Epoch 11/100
188/188 - 0s - loss: 0.0082
Epoch 12/100
188/188 - 0s - loss: 0.0074
Epoch 13/100
188/188 - 0s - loss: 0.0086
Epoch 14/100
188/188 - 0s - loss: 0.0077
Epoch 15/100
188/188 - 0s - loss: 0.0078
Epoch 16/100
188/188 - 0s - loss: 0.0072
Epoch 17/100
188/188 - 0s - loss: 0.0077
Epoch 18/100
188/188 - 0s - loss: 0.0080
Epoch 19/100
188/188 - 0s - loss: 0.0076
Epoch 20/100
188/188 - 0s - loss: 0.0068
Epoch 21/100
188/188 - 0s - loss: 0.0078
Epoch 22/100
188/188 - 0s - loss: 0.0067
Epoch 23/100
188/188 - 0s - loss: 0.0097
Epoch 24/100
188/188 - 0s - loss: 0.0080
Epoch 25/100
188/188 - 0s - loss: 0.0071
Epoch 26/100
188/188 - 0s - loss: 0.0064
Epoch 27/100
188/188 - 0s - loss: 0.0076
Epoch 28/100
188/188 - 0s - loss: 0.0067
Epoch 29/100
188/188 - 0s - loss: 0.0071
Epoch 30/100
188/188 - 0s - loss: 0.0066
Epoch 31/100
188/188 - 0s - loss: 0.0076
Epoch 32/100
188/188 - 0s - loss: 0.0069
Epoch 33/100
188/188 - 0s - loss: 0.0081
Epoch 34/100
188/188 - 0s - loss: 0.0067
Epoch 35/100
188/188 - 0s - loss: 0.0076
Epoch 36/100
188/188 - 0s - loss: 0.0073
Epoch 37/100
188/188 - 0s - loss: 0.0066
Epoch 38/100
188/188 - 0s - loss: 0.0072
Epoch 39/100
188/188 - 0s - loss: 0.0064
Epoch 40/100
188/188 - 0s - loss: 0.0063
Epoch 41/100
188/188 - 0s - loss: 0.0062
Epoch 42/100
188/188 - 0s - loss: 0.0071
Epoch 43/100
188/188 - 0s - loss: 0.0070
Epoch 44/100
188/188 - 0s - loss: 0.0069
Epoch 45/100
188/188 - 0s - loss: 0.0062
Epoch 46/100
188/188 - 0s - loss: 0.0075
Epoch 47/100
188/188 - 0s - loss: 0.0067
Epoch 48/100
188/188 - 0s - loss: 0.0060
Epoch 49/100
188/188 - 0s - loss: 0.0073
Epoch 50/100
188/188 - 0s - loss: 0.0061
Epoch 51/100
188/188 - 0s - loss: 0.0072
Epoch 52/100
188/188 - 0s - loss: 0.0069
Epoch 53/100
188/188 - 0s - loss: 0.0067
Epoch 54/100
188/188 - 0s - loss: 0.0063
Epoch 55/100
188/188 - 0s - loss: 0.0063
Epoch 56/100
188/188 - 0s - loss: 0.0057
Epoch 57/100
188/188 - 0s - loss: 0.0063
Epoch 58/100
188/188 - 0s - loss: 0.0071
Epoch 59/100
188/188 - 0s - loss: 0.0062
Epoch 60/100
188/188 - 0s - loss: 0.0065
Epoch 61/100
188/188 - 0s - loss: 0.0064
Epoch 62/100
188/188 - 0s - loss: 0.0060
Epoch 63/100
188/188 - 0s - loss: 0.0062
Epoch 64/100
188/188 - 0s - loss: 0.0064
Epoch 65/100
188/188 - 0s - loss: 0.0060
Epoch 66/100
188/188 - 0s - loss: 0.0064
Epoch 67/100
188/188 - 0s - loss: 0.0067
Epoch 68/100
188/188 - 0s - loss: 0.0066
Epoch 69/100
188/188 - 0s - loss: 0.0068
Epoch 70/100
188/188 - 0s - loss: 0.0069
Epoch 71/100
188/188 - 0s - loss: 0.0060
Epoch 72/100
188/188 - 0s - loss: 0.0064
Epoch 73/100
188/188 - 0s - loss: 0.0057
Epoch 74/100
188/188 - 0s - loss: 0.0076
Epoch 75/100
188/188 - 0s - loss: 0.0060
Epoch 76/100
188/188 - 0s - loss: 0.0056
Epoch 77/100
188/188 - 0s - loss: 0.0061
Epoch 78/100
188/188 - 0s - loss: 0.0073
Epoch 79/100
188/188 - 0s - loss: 0.0057
Epoch 80/100
188/188 - 0s - loss: 0.0053
Epoch 81/100
188/188 - 0s - loss: 0.0061
Epoch 82/100
188/188 - 0s - loss: 0.0062
Epoch 83/100
188/188 - 0s - loss: 0.0065
Epoch 84/100
188/188 - 0s - loss: 0.0062
Epoch 85/100
188/188 - 0s - loss: 0.0060
Epoch 86/100
188/188 - 0s - loss: 0.0059
Epoch 87/100
188/188 - 0s - loss: 0.0061
Epoch 88/100
188/188 - 0s - loss: 0.0061
Epoch 89/100
188/188 - 0s - loss: 0.0060
Epoch 90/100
188/188 - 0s - loss: 0.0056
Epoch 91/100
188/188 - 0s - loss: 0.0064
Epoch 92/100
188/188 - 0s - loss: 0.0062
Epoch 93/100
188/188 - 0s - loss: 0.0061
Epoch 94/100
188/188 - 0s - loss: 0.0055
Epoch 95/100
188/188 - 0s - loss: 0.0060
Epoch 96/100
188/188 - 0s - loss: 0.0057
Epoch 97/100
188/188 - 0s - loss: 0.0062
Epoch 98/100
188/188 - 0s - loss: 0.0060
Epoch 99/100
188/188 - 0s - loss: 0.0059
Epoch 100/100
188/188 - 0s - loss: 0.0059

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.109
Train RMSE: 0.183
key_word: bitcoin
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.569444  0.513889  0.444444  ...  0.486111  0.847222  0.458333
2021-07-25  0.555556  0.569444  0.513889  ...  0.597222  0.486111  0.847222
2021-08-01  0.458333  0.555556  0.569444  ...  0.208333  0.597222  0.486111
2021-08-08  0.555556  0.458333  0.555556  ...  0.541667  0.208333  0.597222
2021-08-15  0.444444  0.555556  0.458333  ...  0.486111  0.541667  0.208333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_9 (SimpleRNN)     (None, 60)                5100      
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 61        
=================================================================
Total params: 5,161
Trainable params: 5,161
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0251
Epoch 2/100
188/188 - 0s - loss: 0.0148
Epoch 3/100
188/188 - 0s - loss: 0.0115
Epoch 4/100
188/188 - 0s - loss: 0.0108
Epoch 5/100
188/188 - 0s - loss: 0.0117
Epoch 6/100
188/188 - 0s - loss: 0.0105
Epoch 7/100
188/188 - 0s - loss: 0.0073
Epoch 8/100
188/188 - 0s - loss: 0.0084
Epoch 9/100
188/188 - 0s - loss: 0.0085
Epoch 10/100
188/188 - 0s - loss: 0.0086
Epoch 11/100
188/188 - 0s - loss: 0.0088
Epoch 12/100
188/188 - 0s - loss: 0.0091
Epoch 13/100
188/188 - 0s - loss: 0.0082
Epoch 14/100
188/188 - 0s - loss: 0.0087
Epoch 15/100
188/188 - 0s - loss: 0.0078
Epoch 16/100
188/188 - 0s - loss: 0.0078
Epoch 17/100
188/188 - 0s - loss: 0.0077
Epoch 18/100
188/188 - 0s - loss: 0.0083
Epoch 19/100
188/188 - 0s - loss: 0.0073
Epoch 20/100
188/188 - 0s - loss: 0.0077
Epoch 21/100
188/188 - 0s - loss: 0.0073
Epoch 22/100
188/188 - 0s - loss: 0.0073
Epoch 23/100
188/188 - 0s - loss: 0.0074
Epoch 24/100
188/188 - 0s - loss: 0.0072
Epoch 25/100
188/188 - 0s - loss: 0.0082
Epoch 26/100
188/188 - 0s - loss: 0.0074
Epoch 27/100
188/188 - 0s - loss: 0.0078
Epoch 28/100
188/188 - 0s - loss: 0.0081
Epoch 29/100
188/188 - 0s - loss: 0.0075
Epoch 30/100
188/188 - 0s - loss: 0.0074
Epoch 31/100
188/188 - 0s - loss: 0.0087
Epoch 32/100
188/188 - 0s - loss: 0.0075
Epoch 33/100
188/188 - 0s - loss: 0.0070
Epoch 34/100
188/188 - 0s - loss: 0.0077
Epoch 35/100
188/188 - 0s - loss: 0.0070
Epoch 36/100
188/188 - 0s - loss: 0.0073
Epoch 37/100
188/188 - 0s - loss: 0.0060
Epoch 38/100
188/188 - 0s - loss: 0.0069
Epoch 39/100
188/188 - 0s - loss: 0.0066
Epoch 40/100
188/188 - 0s - loss: 0.0076
Epoch 41/100
188/188 - 0s - loss: 0.0069
Epoch 42/100
188/188 - 0s - loss: 0.0065
Epoch 43/100
188/188 - 0s - loss: 0.0069
Epoch 44/100
188/188 - 0s - loss: 0.0070
Epoch 45/100
188/188 - 0s - loss: 0.0070
Epoch 46/100
188/188 - 0s - loss: 0.0070
Epoch 47/100
188/188 - 0s - loss: 0.0077
Epoch 48/100
188/188 - 0s - loss: 0.0065
Epoch 49/100
188/188 - 0s - loss: 0.0073
Epoch 50/100
188/188 - 0s - loss: 0.0071
Epoch 51/100
188/188 - 0s - loss: 0.0068
Epoch 52/100
188/188 - 0s - loss: 0.0067
Epoch 53/100
188/188 - 0s - loss: 0.0070
Epoch 54/100
188/188 - 0s - loss: 0.0065
Epoch 55/100
188/188 - 0s - loss: 0.0063
Epoch 56/100
188/188 - 0s - loss: 0.0068
Epoch 57/100
188/188 - 0s - loss: 0.0070
Epoch 58/100
188/188 - 0s - loss: 0.0068
Epoch 59/100
188/188 - 0s - loss: 0.0059
Epoch 60/100
188/188 - 0s - loss: 0.0061
Epoch 61/100
188/188 - 0s - loss: 0.0063
Epoch 62/100
188/188 - 0s - loss: 0.0067
Epoch 63/100
188/188 - 0s - loss: 0.0062
Epoch 64/100
188/188 - 0s - loss: 0.0060
Epoch 65/100
188/188 - 0s - loss: 0.0066
Epoch 66/100
188/188 - 0s - loss: 0.0073
Epoch 67/100
188/188 - 0s - loss: 0.0063
Epoch 68/100
188/188 - 0s - loss: 0.0062
Epoch 69/100
188/188 - 0s - loss: 0.0063
Epoch 70/100
188/188 - 0s - loss: 0.0068
Epoch 71/100
188/188 - 0s - loss: 0.0061
Epoch 72/100
188/188 - 0s - loss: 0.0061
Epoch 73/100
188/188 - 0s - loss: 0.0065
Epoch 74/100
188/188 - 0s - loss: 0.0063
Epoch 75/100
188/188 - 0s - loss: 0.0060
Epoch 76/100
188/188 - 0s - loss: 0.0067
Epoch 77/100
188/188 - 0s - loss: 0.0059
Epoch 78/100
188/188 - 0s - loss: 0.0063
Epoch 79/100
188/188 - 0s - loss: 0.0057
Epoch 80/100
188/188 - 0s - loss: 0.0072
Epoch 81/100
188/188 - 0s - loss: 0.0061
Epoch 82/100
188/188 - 0s - loss: 0.0062
Epoch 83/100
188/188 - 0s - loss: 0.0063
Epoch 84/100
188/188 - 0s - loss: 0.0064
Epoch 85/100
188/188 - 0s - loss: 0.0063
Epoch 86/100
188/188 - 0s - loss: 0.0060
Epoch 87/100
188/188 - 0s - loss: 0.0062
Epoch 88/100
188/188 - 0s - loss: 0.0062
Epoch 89/100
188/188 - 0s - loss: 0.0062
Epoch 90/100
188/188 - 0s - loss: 0.0065
Epoch 91/100
188/188 - 0s - loss: 0.0060
Epoch 92/100
188/188 - 0s - loss: 0.0062
Epoch 93/100
188/188 - 0s - loss: 0.0064
Epoch 94/100
188/188 - 0s - loss: 0.0065
Epoch 95/100
188/188 - 0s - loss: 0.0059
Epoch 96/100
188/188 - 0s - loss: 0.0059
Epoch 97/100
188/188 - 0s - loss: 0.0061
Epoch 98/100
188/188 - 0s - loss: 0.0062
Epoch 99/100
188/188 - 0s - loss: 0.0063
Epoch 100/100
188/188 - 0s - loss: 0.0062

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.073
Train RMSE: 0.156
key_word: bitcoin
window size: 24
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.628319  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.407080  0.628319  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.513274  0.407080  0.628319
2021-08-08  0.424779  0.628319  0.522124  ...  0.513274  0.513274  0.407080
2021-08-15  0.495575  0.424779  0.628319  ...  0.513274  0.513274  0.513274

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_10 (SimpleRNN)    (None, 4)                 68        
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 5         
=================================================================
Total params: 73
Trainable params: 73
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.2591
Epoch 2/100
198/198 - 0s - loss: 0.0056
Epoch 3/100
198/198 - 0s - loss: 0.0056
Epoch 4/100
198/198 - 0s - loss: 0.0055
Epoch 5/100
198/198 - 0s - loss: 0.0054
Epoch 6/100
198/198 - 0s - loss: 0.0054
Epoch 7/100
198/198 - 0s - loss: 0.0051
Epoch 8/100
198/198 - 0s - loss: 0.0050
Epoch 9/100
198/198 - 0s - loss: 0.0052
Epoch 10/100
198/198 - 0s - loss: 0.0049
Epoch 11/100
198/198 - 0s - loss: 0.0048
Epoch 12/100
198/198 - 0s - loss: 0.0049
Epoch 13/100
198/198 - 0s - loss: 0.0047
Epoch 14/100
198/198 - 0s - loss: 0.0046
Epoch 15/100
198/198 - 0s - loss: 0.0045
Epoch 16/100
198/198 - 0s - loss: 0.0045
Epoch 17/100
198/198 - 0s - loss: 0.0044
Epoch 18/100
198/198 - 0s - loss: 0.0043
Epoch 19/100
198/198 - 0s - loss: 0.0042
Epoch 20/100
198/198 - 0s - loss: 0.0043
Epoch 21/100
198/198 - 0s - loss: 0.0042
Epoch 22/100
198/198 - 0s - loss: 0.0039
Epoch 23/100
198/198 - 0s - loss: 0.0038
Epoch 24/100
198/198 - 0s - loss: 0.0039
Epoch 25/100
198/198 - 0s - loss: 0.0040
Epoch 26/100
198/198 - 0s - loss: 0.0039
Epoch 27/100
198/198 - 0s - loss: 0.0040
Epoch 28/100
198/198 - 0s - loss: 0.0038
Epoch 29/100
198/198 - 0s - loss: 0.0037
Epoch 30/100
198/198 - 0s - loss: 0.0036
Epoch 31/100
198/198 - 0s - loss: 0.0036
Epoch 32/100
198/198 - 0s - loss: 0.0035
Epoch 33/100
198/198 - 0s - loss: 0.0037
Epoch 34/100
198/198 - 0s - loss: 0.0035
Epoch 35/100
198/198 - 0s - loss: 0.0037
Epoch 36/100
198/198 - 0s - loss: 0.0035
Epoch 37/100
198/198 - 0s - loss: 0.0035
Epoch 38/100
198/198 - 0s - loss: 0.0035
Epoch 39/100
198/198 - 0s - loss: 0.0035
Epoch 40/100
198/198 - 0s - loss: 0.0036
Epoch 41/100
198/198 - 0s - loss: 0.0035
Epoch 42/100
198/198 - 0s - loss: 0.0034
Epoch 43/100
198/198 - 0s - loss: 0.0034
Epoch 44/100
198/198 - 0s - loss: 0.0034
Epoch 45/100
198/198 - 0s - loss: 0.0034
Epoch 46/100
198/198 - 0s - loss: 0.0035
Epoch 47/100
198/198 - 0s - loss: 0.0033
Epoch 48/100
198/198 - 0s - loss: 0.0033
Epoch 49/100
198/198 - 0s - loss: 0.0035
Epoch 50/100
198/198 - 0s - loss: 0.0034
Epoch 51/100
198/198 - 0s - loss: 0.0033
Epoch 52/100
198/198 - 0s - loss: 0.0035
Epoch 53/100
198/198 - 0s - loss: 0.0033
Epoch 54/100
198/198 - 0s - loss: 0.0034
Epoch 55/100
198/198 - 0s - loss: 0.0034
Epoch 56/100
198/198 - 0s - loss: 0.0034
Epoch 57/100
198/198 - 0s - loss: 0.0034
Epoch 58/100
198/198 - 0s - loss: 0.0033
Epoch 59/100
198/198 - 0s - loss: 0.0034
Epoch 60/100
198/198 - 0s - loss: 0.0034
Epoch 61/100
198/198 - 0s - loss: 0.0032
Epoch 62/100
198/198 - 0s - loss: 0.0034
Epoch 63/100
198/198 - 0s - loss: 0.0032
Epoch 64/100
198/198 - 0s - loss: 0.0033
Epoch 65/100
198/198 - 0s - loss: 0.0035
Epoch 66/100
198/198 - 0s - loss: 0.0034
Epoch 67/100
198/198 - 0s - loss: 0.0034
Epoch 68/100
198/198 - 0s - loss: 0.0034
Epoch 69/100
198/198 - 0s - loss: 0.0034
Epoch 70/100
198/198 - 0s - loss: 0.0033
Epoch 71/100
198/198 - 0s - loss: 0.0032
Epoch 72/100
198/198 - 0s - loss: 0.0036
Epoch 73/100
198/198 - 0s - loss: 0.0032
Epoch 74/100
198/198 - 0s - loss: 0.0032
Epoch 75/100
198/198 - 0s - loss: 0.0033
Epoch 76/100
198/198 - 0s - loss: 0.0032
Epoch 77/100
198/198 - 0s - loss: 0.0031
Epoch 78/100
198/198 - 0s - loss: 0.0033
Epoch 79/100
198/198 - 0s - loss: 0.0031
Epoch 80/100
198/198 - 0s - loss: 0.0032
Epoch 81/100
198/198 - 0s - loss: 0.0032
Epoch 82/100
198/198 - 0s - loss: 0.0033
Epoch 83/100
198/198 - 0s - loss: 0.0034
Epoch 84/100
198/198 - 0s - loss: 0.0032
Epoch 85/100
198/198 - 0s - loss: 0.0032
Epoch 86/100
198/198 - 0s - loss: 0.0033
Epoch 87/100
198/198 - 0s - loss: 0.0032
Epoch 88/100
198/198 - 0s - loss: 0.0032
Epoch 89/100
198/198 - 0s - loss: 0.0035
Epoch 90/100
198/198 - 0s - loss: 0.0033
Epoch 91/100
198/198 - 0s - loss: 0.0031
Epoch 92/100
198/198 - 0s - loss: 0.0032
Epoch 93/100
198/198 - 0s - loss: 0.0030
Epoch 94/100
198/198 - 0s - loss: 0.0034
Epoch 95/100
198/198 - 0s - loss: 0.0031
Epoch 96/100
198/198 - 0s - loss: 0.0031
Epoch 97/100
198/198 - 0s - loss: 0.0032
Epoch 98/100
198/198 - 0s - loss: 0.0031
Epoch 99/100
198/198 - 0s - loss: 0.0032
Epoch 100/100
198/198 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.055
Train RMSE: 0.097
key_word: COVID-19
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.628319  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.407080  0.628319  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.513274  0.407080  0.628319
2021-08-08  0.424779  0.628319  0.522124  ...  0.513274  0.513274  0.407080
2021-08-15  0.495575  0.424779  0.628319  ...  0.513274  0.513274  0.513274

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_11 (SimpleRNN)    (None, 8)                 168       
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 9         
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0311
Epoch 2/100
198/198 - 0s - loss: 0.0081
Epoch 3/100
198/198 - 0s - loss: 0.0082
Epoch 4/100
198/198 - 0s - loss: 0.0071
Epoch 5/100
198/198 - 0s - loss: 0.0070
Epoch 6/100
198/198 - 0s - loss: 0.0065
Epoch 7/100
198/198 - 0s - loss: 0.0061
Epoch 8/100
198/198 - 0s - loss: 0.0056
Epoch 9/100
198/198 - 0s - loss: 0.0058
Epoch 10/100
198/198 - 0s - loss: 0.0052
Epoch 11/100
198/198 - 0s - loss: 0.0050
Epoch 12/100
198/198 - 0s - loss: 0.0049
Epoch 13/100
198/198 - 0s - loss: 0.0047
Epoch 14/100
198/198 - 0s - loss: 0.0047
Epoch 15/100
198/198 - 0s - loss: 0.0043
Epoch 16/100
198/198 - 0s - loss: 0.0047
Epoch 17/100
198/198 - 0s - loss: 0.0040
Epoch 18/100
198/198 - 0s - loss: 0.0046
Epoch 19/100
198/198 - 0s - loss: 0.0043
Epoch 20/100
198/198 - 0s - loss: 0.0041
Epoch 21/100
198/198 - 0s - loss: 0.0038
Epoch 22/100
198/198 - 0s - loss: 0.0037
Epoch 23/100
198/198 - 0s - loss: 0.0039
Epoch 24/100
198/198 - 0s - loss: 0.0041
Epoch 25/100
198/198 - 0s - loss: 0.0038
Epoch 26/100
198/198 - 0s - loss: 0.0041
Epoch 27/100
198/198 - 0s - loss: 0.0039
Epoch 28/100
198/198 - 0s - loss: 0.0039
Epoch 29/100
198/198 - 0s - loss: 0.0038
Epoch 30/100
198/198 - 0s - loss: 0.0038
Epoch 31/100
198/198 - 0s - loss: 0.0041
Epoch 32/100
198/198 - 0s - loss: 0.0040
Epoch 33/100
198/198 - 0s - loss: 0.0037
Epoch 34/100
198/198 - 0s - loss: 0.0037
Epoch 35/100
198/198 - 0s - loss: 0.0038
Epoch 36/100
198/198 - 0s - loss: 0.0039
Epoch 37/100
198/198 - 0s - loss: 0.0035
Epoch 38/100
198/198 - 0s - loss: 0.0037
Epoch 39/100
198/198 - 0s - loss: 0.0036
Epoch 40/100
198/198 - 0s - loss: 0.0037
Epoch 41/100
198/198 - 0s - loss: 0.0038
Epoch 42/100
198/198 - 0s - loss: 0.0037
Epoch 43/100
198/198 - 0s - loss: 0.0038
Epoch 44/100
198/198 - 0s - loss: 0.0036
Epoch 45/100
198/198 - 0s - loss: 0.0036
Epoch 46/100
198/198 - 0s - loss: 0.0036
Epoch 47/100
198/198 - 0s - loss: 0.0035
Epoch 48/100
198/198 - 0s - loss: 0.0034
Epoch 49/100
198/198 - 0s - loss: 0.0036
Epoch 50/100
198/198 - 0s - loss: 0.0034
Epoch 51/100
198/198 - 0s - loss: 0.0036
Epoch 52/100
198/198 - 0s - loss: 0.0036
Epoch 53/100
198/198 - 0s - loss: 0.0035
Epoch 54/100
198/198 - 0s - loss: 0.0034
Epoch 55/100
198/198 - 0s - loss: 0.0034
Epoch 56/100
198/198 - 0s - loss: 0.0035
Epoch 57/100
198/198 - 0s - loss: 0.0035
Epoch 58/100
198/198 - 0s - loss: 0.0035
Epoch 59/100
198/198 - 0s - loss: 0.0035
Epoch 60/100
198/198 - 0s - loss: 0.0038
Epoch 61/100
198/198 - 0s - loss: 0.0035
Epoch 62/100
198/198 - 0s - loss: 0.0036
Epoch 63/100
198/198 - 0s - loss: 0.0036
Epoch 64/100
198/198 - 0s - loss: 0.0034
Epoch 65/100
198/198 - 0s - loss: 0.0033
Epoch 66/100
198/198 - 0s - loss: 0.0035
Epoch 67/100
198/198 - 0s - loss: 0.0036
Epoch 68/100
198/198 - 0s - loss: 0.0035
Epoch 69/100
198/198 - 0s - loss: 0.0034
Epoch 70/100
198/198 - 0s - loss: 0.0034
Epoch 71/100
198/198 - 0s - loss: 0.0035
Epoch 72/100
198/198 - 0s - loss: 0.0035
Epoch 73/100
198/198 - 0s - loss: 0.0035
Epoch 74/100
198/198 - 0s - loss: 0.0034
Epoch 75/100
198/198 - 0s - loss: 0.0038
Epoch 76/100
198/198 - 0s - loss: 0.0033
Epoch 77/100
198/198 - 0s - loss: 0.0037
Epoch 78/100
198/198 - 0s - loss: 0.0034
Epoch 79/100
198/198 - 0s - loss: 0.0036
Epoch 80/100
198/198 - 0s - loss: 0.0035
Epoch 81/100
198/198 - 0s - loss: 0.0034
Epoch 82/100
198/198 - 0s - loss: 0.0035
Epoch 83/100
198/198 - 0s - loss: 0.0036
Epoch 84/100
198/198 - 0s - loss: 0.0034
Epoch 85/100
198/198 - 0s - loss: 0.0033
Epoch 86/100
198/198 - 0s - loss: 0.0035
Epoch 87/100
198/198 - 0s - loss: 0.0036
Epoch 88/100
198/198 - 0s - loss: 0.0034
Epoch 89/100
198/198 - 0s - loss: 0.0036
Epoch 90/100
198/198 - 0s - loss: 0.0034
Epoch 91/100
198/198 - 0s - loss: 0.0033
Epoch 92/100
198/198 - 0s - loss: 0.0033
Epoch 93/100
198/198 - 0s - loss: 0.0038
Epoch 94/100
198/198 - 0s - loss: 0.0033
Epoch 95/100
198/198 - 0s - loss: 0.0032
Epoch 96/100
198/198 - 0s - loss: 0.0036
Epoch 97/100
198/198 - 0s - loss: 0.0036
Epoch 98/100
198/198 - 0s - loss: 0.0032
Epoch 99/100
198/198 - 0s - loss: 0.0034
Epoch 100/100
198/198 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.102
key_word: COVID-19
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.628319  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.407080  0.628319  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.513274  0.407080  0.628319
2021-08-08  0.424779  0.628319  0.522124  ...  0.513274  0.513274  0.407080
2021-08-15  0.495575  0.424779  0.628319  ...  0.513274  0.513274  0.513274

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_12 (SimpleRNN)    (None, 16)                464       
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 17        
=================================================================
Total params: 481
Trainable params: 481
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.1333
Epoch 2/100
198/198 - 0s - loss: 0.0038
Epoch 3/100
198/198 - 0s - loss: 0.0038
Epoch 4/100
198/198 - 0s - loss: 0.0039
Epoch 5/100
198/198 - 0s - loss: 0.0038
Epoch 6/100
198/198 - 0s - loss: 0.0038
Epoch 7/100
198/198 - 0s - loss: 0.0039
Epoch 8/100
198/198 - 0s - loss: 0.0040
Epoch 9/100
198/198 - 0s - loss: 0.0038
Epoch 10/100
198/198 - 0s - loss: 0.0036
Epoch 11/100
198/198 - 0s - loss: 0.0039
Epoch 12/100
198/198 - 0s - loss: 0.0040
Epoch 13/100
198/198 - 0s - loss: 0.0039
Epoch 14/100
198/198 - 0s - loss: 0.0039
Epoch 15/100
198/198 - 0s - loss: 0.0039
Epoch 16/100
198/198 - 0s - loss: 0.0040
Epoch 17/100
198/198 - 0s - loss: 0.0039
Epoch 18/100
198/198 - 0s - loss: 0.0038
Epoch 19/100
198/198 - 0s - loss: 0.0036
Epoch 20/100
198/198 - 0s - loss: 0.0038
Epoch 21/100
198/198 - 0s - loss: 0.0043
Epoch 22/100
198/198 - 0s - loss: 0.0037
Epoch 23/100
198/198 - 0s - loss: 0.0042
Epoch 24/100
198/198 - 0s - loss: 0.0038
Epoch 25/100
198/198 - 0s - loss: 0.0042
Epoch 26/100
198/198 - 0s - loss: 0.0040
Epoch 27/100
198/198 - 0s - loss: 0.0040
Epoch 28/100
198/198 - 0s - loss: 0.0034
Epoch 29/100
198/198 - 0s - loss: 0.0044
Epoch 30/100
198/198 - 0s - loss: 0.0038
Epoch 31/100
198/198 - 0s - loss: 0.0039
Epoch 32/100
198/198 - 0s - loss: 0.0039
Epoch 33/100
198/198 - 0s - loss: 0.0038
Epoch 34/100
198/198 - 0s - loss: 0.0040
Epoch 35/100
198/198 - 0s - loss: 0.0038
Epoch 36/100
198/198 - 0s - loss: 0.0038
Epoch 37/100
198/198 - 0s - loss: 0.0037
Epoch 38/100
198/198 - 0s - loss: 0.0035
Epoch 39/100
198/198 - 0s - loss: 0.0036
Epoch 40/100
198/198 - 0s - loss: 0.0039
Epoch 41/100
198/198 - 0s - loss: 0.0036
Epoch 42/100
198/198 - 0s - loss: 0.0036
Epoch 43/100
198/198 - 0s - loss: 0.0036
Epoch 44/100
198/198 - 0s - loss: 0.0038
Epoch 45/100
198/198 - 0s - loss: 0.0037
Epoch 46/100
198/198 - 0s - loss: 0.0037
Epoch 47/100
198/198 - 0s - loss: 0.0038
Epoch 48/100
198/198 - 0s - loss: 0.0037
Epoch 49/100
198/198 - 0s - loss: 0.0036
Epoch 50/100
198/198 - 0s - loss: 0.0040
Epoch 51/100
198/198 - 0s - loss: 0.0037
Epoch 52/100
198/198 - 0s - loss: 0.0039
Epoch 53/100
198/198 - 0s - loss: 0.0039
Epoch 54/100
198/198 - 0s - loss: 0.0034
Epoch 55/100
198/198 - 0s - loss: 0.0035
Epoch 56/100
198/198 - 0s - loss: 0.0036
Epoch 57/100
198/198 - 0s - loss: 0.0039
Epoch 58/100
198/198 - 0s - loss: 0.0033
Epoch 59/100
198/198 - 0s - loss: 0.0037
Epoch 60/100
198/198 - 0s - loss: 0.0036
Epoch 61/100
198/198 - 0s - loss: 0.0038
Epoch 62/100
198/198 - 0s - loss: 0.0036
Epoch 63/100
198/198 - 0s - loss: 0.0037
Epoch 64/100
198/198 - 0s - loss: 0.0035
Epoch 65/100
198/198 - 0s - loss: 0.0035
Epoch 66/100
198/198 - 0s - loss: 0.0033
Epoch 67/100
198/198 - 0s - loss: 0.0037
Epoch 68/100
198/198 - 0s - loss: 0.0036
Epoch 69/100
198/198 - 0s - loss: 0.0036
Epoch 70/100
198/198 - 0s - loss: 0.0034
Epoch 71/100
198/198 - 0s - loss: 0.0037
Epoch 72/100
198/198 - 0s - loss: 0.0036
Epoch 73/100
198/198 - 0s - loss: 0.0035
Epoch 74/100
198/198 - 0s - loss: 0.0035
Epoch 75/100
198/198 - 0s - loss: 0.0035
Epoch 76/100
198/198 - 0s - loss: 0.0034
Epoch 77/100
198/198 - 0s - loss: 0.0036
Epoch 78/100
198/198 - 0s - loss: 0.0038
Epoch 79/100
198/198 - 0s - loss: 0.0036
Epoch 80/100
198/198 - 0s - loss: 0.0034
Epoch 81/100
198/198 - 0s - loss: 0.0035
Epoch 82/100
198/198 - 0s - loss: 0.0035
Epoch 83/100
198/198 - 0s - loss: 0.0034
Epoch 84/100
198/198 - 0s - loss: 0.0034
Epoch 85/100
198/198 - 0s - loss: 0.0035
Epoch 86/100
198/198 - 0s - loss: 0.0035
Epoch 87/100
198/198 - 0s - loss: 0.0037
Epoch 88/100
198/198 - 0s - loss: 0.0034
Epoch 89/100
198/198 - 0s - loss: 0.0035
Epoch 90/100
198/198 - 0s - loss: 0.0035
Epoch 91/100
198/198 - 0s - loss: 0.0034
Epoch 92/100
198/198 - 0s - loss: 0.0034
Epoch 93/100
198/198 - 0s - loss: 0.0034
Epoch 94/100
198/198 - 0s - loss: 0.0035
Epoch 95/100
198/198 - 0s - loss: 0.0037
Epoch 96/100
198/198 - 0s - loss: 0.0036
Epoch 97/100
198/198 - 0s - loss: 0.0037
Epoch 98/100
198/198 - 0s - loss: 0.0034
Epoch 99/100
198/198 - 0s - loss: 0.0033
Epoch 100/100
198/198 - 0s - loss: 0.0035

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.054
Train RMSE: 0.086
key_word: COVID-19
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.628319  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.407080  0.628319  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.513274  0.407080  0.628319
2021-08-08  0.424779  0.628319  0.522124  ...  0.513274  0.513274  0.407080
2021-08-15  0.495575  0.424779  0.628319  ...  0.513274  0.513274  0.513274

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_13 (SimpleRNN)    (None, 32)                1440      
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 33        
=================================================================
Total params: 1,473
Trainable params: 1,473
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0055
Epoch 2/100
198/198 - 0s - loss: 0.0052
Epoch 3/100
198/198 - 0s - loss: 0.0048
Epoch 4/100
198/198 - 0s - loss: 0.0048
Epoch 5/100
198/198 - 0s - loss: 0.0044
Epoch 6/100
198/198 - 0s - loss: 0.0060
Epoch 7/100
198/198 - 0s - loss: 0.0043
Epoch 8/100
198/198 - 0s - loss: 0.0047
Epoch 9/100
198/198 - 0s - loss: 0.0040
Epoch 10/100
198/198 - 0s - loss: 0.0048
Epoch 11/100
198/198 - 0s - loss: 0.0049
Epoch 12/100
198/198 - 0s - loss: 0.0041
Epoch 13/100
198/198 - 0s - loss: 0.0042
Epoch 14/100
198/198 - 0s - loss: 0.0039
Epoch 15/100
198/198 - 0s - loss: 0.0044
Epoch 16/100
198/198 - 0s - loss: 0.0049
Epoch 17/100
198/198 - 0s - loss: 0.0041
Epoch 18/100
198/198 - 0s - loss: 0.0041
Epoch 19/100
198/198 - 0s - loss: 0.0040
Epoch 20/100
198/198 - 0s - loss: 0.0044
Epoch 21/100
198/198 - 0s - loss: 0.0042
Epoch 22/100
198/198 - 0s - loss: 0.0050
Epoch 23/100
198/198 - 0s - loss: 0.0042
Epoch 24/100
198/198 - 0s - loss: 0.0038
Epoch 25/100
198/198 - 0s - loss: 0.0038
Epoch 26/100
198/198 - 0s - loss: 0.0043
Epoch 27/100
198/198 - 0s - loss: 0.0040
Epoch 28/100
198/198 - 0s - loss: 0.0040
Epoch 29/100
198/198 - 0s - loss: 0.0044
Epoch 30/100
198/198 - 0s - loss: 0.0038
Epoch 31/100
198/198 - 0s - loss: 0.0051
Epoch 32/100
198/198 - 0s - loss: 0.0034
Epoch 33/100
198/198 - 0s - loss: 0.0039
Epoch 34/100
198/198 - 0s - loss: 0.0043
Epoch 35/100
198/198 - 0s - loss: 0.0039
Epoch 36/100
198/198 - 0s - loss: 0.0038
Epoch 37/100
198/198 - 0s - loss: 0.0038
Epoch 38/100
198/198 - 0s - loss: 0.0039
Epoch 39/100
198/198 - 0s - loss: 0.0041
Epoch 40/100
198/198 - 0s - loss: 0.0035
Epoch 41/100
198/198 - 0s - loss: 0.0039
Epoch 42/100
198/198 - 0s - loss: 0.0036
Epoch 43/100
198/198 - 0s - loss: 0.0045
Epoch 44/100
198/198 - 0s - loss: 0.0038
Epoch 45/100
198/198 - 0s - loss: 0.0041
Epoch 46/100
198/198 - 0s - loss: 0.0040
Epoch 47/100
198/198 - 0s - loss: 0.0040
Epoch 48/100
198/198 - 0s - loss: 0.0036
Epoch 49/100
198/198 - 0s - loss: 0.0037
Epoch 50/100
198/198 - 0s - loss: 0.0037
Epoch 51/100
198/198 - 0s - loss: 0.0037
Epoch 52/100
198/198 - 0s - loss: 0.0043
Epoch 53/100
198/198 - 0s - loss: 0.0034
Epoch 54/100
198/198 - 0s - loss: 0.0035
Epoch 55/100
198/198 - 0s - loss: 0.0039
Epoch 56/100
198/198 - 0s - loss: 0.0035
Epoch 57/100
198/198 - 0s - loss: 0.0036
Epoch 58/100
198/198 - 0s - loss: 0.0041
Epoch 59/100
198/198 - 0s - loss: 0.0036
Epoch 60/100
198/198 - 0s - loss: 0.0040
Epoch 61/100
198/198 - 0s - loss: 0.0039
Epoch 62/100
198/198 - 0s - loss: 0.0037
Epoch 63/100
198/198 - 0s - loss: 0.0036
Epoch 64/100
198/198 - 0s - loss: 0.0034
Epoch 65/100
198/198 - 0s - loss: 0.0040
Epoch 66/100
198/198 - 0s - loss: 0.0037
Epoch 67/100
198/198 - 0s - loss: 0.0035
Epoch 68/100
198/198 - 0s - loss: 0.0034
Epoch 69/100
198/198 - 0s - loss: 0.0036
Epoch 70/100
198/198 - 0s - loss: 0.0035
Epoch 71/100
198/198 - 0s - loss: 0.0033
Epoch 72/100
198/198 - 0s - loss: 0.0037
Epoch 73/100
198/198 - 0s - loss: 0.0038
Epoch 74/100
198/198 - 0s - loss: 0.0034
Epoch 75/100
198/198 - 0s - loss: 0.0037
Epoch 76/100
198/198 - 0s - loss: 0.0035
Epoch 77/100
198/198 - 0s - loss: 0.0036
Epoch 78/100
198/198 - 0s - loss: 0.0036
Epoch 79/100
198/198 - 0s - loss: 0.0037
Epoch 80/100
198/198 - 0s - loss: 0.0036
Epoch 81/100
198/198 - 0s - loss: 0.0034
Epoch 82/100
198/198 - 0s - loss: 0.0036
Epoch 83/100
198/198 - 0s - loss: 0.0034
Epoch 84/100
198/198 - 0s - loss: 0.0037
Epoch 85/100
198/198 - 0s - loss: 0.0036
Epoch 86/100
198/198 - 0s - loss: 0.0037
Epoch 87/100
198/198 - 0s - loss: 0.0036
Epoch 88/100
198/198 - 0s - loss: 0.0036
Epoch 89/100
198/198 - 0s - loss: 0.0036
Epoch 90/100
198/198 - 0s - loss: 0.0036
Epoch 91/100
198/198 - 0s - loss: 0.0035
Epoch 92/100
198/198 - 0s - loss: 0.0036
Epoch 93/100
198/198 - 0s - loss: 0.0034
Epoch 94/100
198/198 - 0s - loss: 0.0035
Epoch 95/100
198/198 - 0s - loss: 0.0033
Epoch 96/100
198/198 - 0s - loss: 0.0033
Epoch 97/100
198/198 - 0s - loss: 0.0034
Epoch 98/100
198/198 - 0s - loss: 0.0037
Epoch 99/100
198/198 - 0s - loss: 0.0036
Epoch 100/100
198/198 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.057
Train RMSE: 0.085
key_word: COVID-19
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.628319  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.407080  0.628319  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.513274  0.407080  0.628319
2021-08-08  0.424779  0.628319  0.522124  ...  0.513274  0.513274  0.407080
2021-08-15  0.495575  0.424779  0.628319  ...  0.513274  0.513274  0.513274

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_14 (SimpleRNN)    (None, 60)                4380      
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 61        
=================================================================
Total params: 4,441
Trainable params: 4,441
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0228
Epoch 2/100
198/198 - 0s - loss: 0.0077
Epoch 3/100
198/198 - 0s - loss: 0.0064
Epoch 4/100
198/198 - 0s - loss: 0.0064
Epoch 5/100
198/198 - 0s - loss: 0.0059
Epoch 6/100
198/198 - 0s - loss: 0.0067
Epoch 7/100
198/198 - 0s - loss: 0.0051
Epoch 8/100
198/198 - 0s - loss: 0.0063
Epoch 9/100
198/198 - 0s - loss: 0.0052
Epoch 10/100
198/198 - 0s - loss: 0.0049
Epoch 11/100
198/198 - 0s - loss: 0.0046
Epoch 12/100
198/198 - 0s - loss: 0.0057
Epoch 13/100
198/198 - 0s - loss: 0.0047
Epoch 14/100
198/198 - 0s - loss: 0.0052
Epoch 15/100
198/198 - 0s - loss: 0.0048
Epoch 16/100
198/198 - 0s - loss: 0.0045
Epoch 17/100
198/198 - 0s - loss: 0.0044
Epoch 18/100
198/198 - 0s - loss: 0.0045
Epoch 19/100
198/198 - 0s - loss: 0.0045
Epoch 20/100
198/198 - 0s - loss: 0.0057
Epoch 21/100
198/198 - 0s - loss: 0.0039
Epoch 22/100
198/198 - 0s - loss: 0.0040
Epoch 23/100
198/198 - 0s - loss: 0.0050
Epoch 24/100
198/198 - 0s - loss: 0.0047
Epoch 25/100
198/198 - 0s - loss: 0.0047
Epoch 26/100
198/198 - 0s - loss: 0.0042
Epoch 27/100
198/198 - 0s - loss: 0.0044
Epoch 28/100
198/198 - 0s - loss: 0.0045
Epoch 29/100
198/198 - 0s - loss: 0.0041
Epoch 30/100
198/198 - 0s - loss: 0.0046
Epoch 31/100
198/198 - 0s - loss: 0.0039
Epoch 32/100
198/198 - 0s - loss: 0.0044
Epoch 33/100
198/198 - 0s - loss: 0.0038
Epoch 34/100
198/198 - 0s - loss: 0.0042
Epoch 35/100
198/198 - 0s - loss: 0.0041
Epoch 36/100
198/198 - 0s - loss: 0.0039
Epoch 37/100
198/198 - 0s - loss: 0.0038
Epoch 38/100
198/198 - 0s - loss: 0.0039
Epoch 39/100
198/198 - 0s - loss: 0.0041
Epoch 40/100
198/198 - 0s - loss: 0.0048
Epoch 41/100
198/198 - 0s - loss: 0.0041
Epoch 42/100
198/198 - 0s - loss: 0.0037
Epoch 43/100
198/198 - 0s - loss: 0.0040
Epoch 44/100
198/198 - 0s - loss: 0.0040
Epoch 45/100
198/198 - 0s - loss: 0.0041
Epoch 46/100
198/198 - 0s - loss: 0.0038
Epoch 47/100
198/198 - 0s - loss: 0.0039
Epoch 48/100
198/198 - 0s - loss: 0.0041
Epoch 49/100
198/198 - 0s - loss: 0.0041
Epoch 50/100
198/198 - 0s - loss: 0.0040
Epoch 51/100
198/198 - 0s - loss: 0.0035
Epoch 52/100
198/198 - 0s - loss: 0.0036
Epoch 53/100
198/198 - 0s - loss: 0.0040
Epoch 54/100
198/198 - 0s - loss: 0.0035
Epoch 55/100
198/198 - 0s - loss: 0.0037
Epoch 56/100
198/198 - 0s - loss: 0.0036
Epoch 57/100
198/198 - 0s - loss: 0.0037
Epoch 58/100
198/198 - 0s - loss: 0.0035
Epoch 59/100
198/198 - 0s - loss: 0.0036
Epoch 60/100
198/198 - 0s - loss: 0.0036
Epoch 61/100
198/198 - 0s - loss: 0.0036
Epoch 62/100
198/198 - 0s - loss: 0.0036
Epoch 63/100
198/198 - 0s - loss: 0.0039
Epoch 64/100
198/198 - 0s - loss: 0.0037
Epoch 65/100
198/198 - 0s - loss: 0.0037
Epoch 66/100
198/198 - 0s - loss: 0.0036
Epoch 67/100
198/198 - 0s - loss: 0.0036
Epoch 68/100
198/198 - 0s - loss: 0.0036
Epoch 69/100
198/198 - 0s - loss: 0.0038
Epoch 70/100
198/198 - 0s - loss: 0.0034
Epoch 71/100
198/198 - 0s - loss: 0.0036
Epoch 72/100
198/198 - 0s - loss: 0.0035
Epoch 73/100
198/198 - 0s - loss: 0.0036
Epoch 74/100
198/198 - 0s - loss: 0.0037
Epoch 75/100
198/198 - 0s - loss: 0.0035
Epoch 76/100
198/198 - 0s - loss: 0.0037
Epoch 77/100
198/198 - 0s - loss: 0.0036
Epoch 78/100
198/198 - 0s - loss: 0.0038
Epoch 79/100
198/198 - 0s - loss: 0.0034
Epoch 80/100
198/198 - 0s - loss: 0.0038
Epoch 81/100
198/198 - 0s - loss: 0.0038
Epoch 82/100
198/198 - 0s - loss: 0.0037
Epoch 83/100
198/198 - 0s - loss: 0.0036
Epoch 84/100
198/198 - 0s - loss: 0.0038
Epoch 85/100
198/198 - 0s - loss: 0.0036
Epoch 86/100
198/198 - 0s - loss: 0.0033
Epoch 87/100
198/198 - 0s - loss: 0.0038
Epoch 88/100
198/198 - 0s - loss: 0.0035
Epoch 89/100
198/198 - 0s - loss: 0.0037
Epoch 90/100
198/198 - 0s - loss: 0.0036
Epoch 91/100
198/198 - 0s - loss: 0.0036
Epoch 92/100
198/198 - 0s - loss: 0.0035
Epoch 93/100
198/198 - 0s - loss: 0.0034
Epoch 94/100
198/198 - 0s - loss: 0.0034
Epoch 95/100
198/198 - 0s - loss: 0.0034
Epoch 96/100
198/198 - 0s - loss: 0.0036
Epoch 97/100
198/198 - 0s - loss: 0.0036
Epoch 98/100
198/198 - 0s - loss: 0.0036
Epoch 99/100
198/198 - 0s - loss: 0.0033
Epoch 100/100
198/198 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.059
Train RMSE: 0.088
key_word: COVID-19
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.522124  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.530973  0.522124  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.522124  0.530973  0.522124
2021-08-08  0.424779  0.628319  0.522124  ...  0.530973  0.522124  0.530973
2021-08-15  0.495575  0.424779  0.628319  ...  0.522124  0.530973  0.522124

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_15 (SimpleRNN)    (None, 4)                 116       
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 5         
=================================================================
Total params: 121
Trainable params: 121
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0136
Epoch 2/100
188/188 - 0s - loss: 0.0043
Epoch 3/100
188/188 - 0s - loss: 0.0047
Epoch 4/100
188/188 - 0s - loss: 0.0045
Epoch 5/100
188/188 - 0s - loss: 0.0044
Epoch 6/100
188/188 - 0s - loss: 0.0045
Epoch 7/100
188/188 - 0s - loss: 0.0043
Epoch 8/100
188/188 - 0s - loss: 0.0042
Epoch 9/100
188/188 - 0s - loss: 0.0041
Epoch 10/100
188/188 - 0s - loss: 0.0041
Epoch 11/100
188/188 - 0s - loss: 0.0041
Epoch 12/100
188/188 - 0s - loss: 0.0041
Epoch 13/100
188/188 - 0s - loss: 0.0039
Epoch 14/100
188/188 - 0s - loss: 0.0040
Epoch 15/100
188/188 - 0s - loss: 0.0041
Epoch 16/100
188/188 - 0s - loss: 0.0041
Epoch 17/100
188/188 - 0s - loss: 0.0039
Epoch 18/100
188/188 - 0s - loss: 0.0040
Epoch 19/100
188/188 - 0s - loss: 0.0038
Epoch 20/100
188/188 - 0s - loss: 0.0038
Epoch 21/100
188/188 - 0s - loss: 0.0039
Epoch 22/100
188/188 - 0s - loss: 0.0038
Epoch 23/100
188/188 - 0s - loss: 0.0037
Epoch 24/100
188/188 - 0s - loss: 0.0039
Epoch 25/100
188/188 - 0s - loss: 0.0038
Epoch 26/100
188/188 - 0s - loss: 0.0038
Epoch 27/100
188/188 - 0s - loss: 0.0037
Epoch 28/100
188/188 - 0s - loss: 0.0038
Epoch 29/100
188/188 - 0s - loss: 0.0037
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0037
Epoch 32/100
188/188 - 0s - loss: 0.0037
Epoch 33/100
188/188 - 0s - loss: 0.0036
Epoch 34/100
188/188 - 0s - loss: 0.0037
Epoch 35/100
188/188 - 0s - loss: 0.0036
Epoch 36/100
188/188 - 0s - loss: 0.0035
Epoch 37/100
188/188 - 0s - loss: 0.0039
Epoch 38/100
188/188 - 0s - loss: 0.0037
Epoch 39/100
188/188 - 0s - loss: 0.0036
Epoch 40/100
188/188 - 0s - loss: 0.0036
Epoch 41/100
188/188 - 0s - loss: 0.0037
Epoch 42/100
188/188 - 0s - loss: 0.0035
Epoch 43/100
188/188 - 0s - loss: 0.0037
Epoch 44/100
188/188 - 0s - loss: 0.0037
Epoch 45/100
188/188 - 0s - loss: 0.0036
Epoch 46/100
188/188 - 0s - loss: 0.0035
Epoch 47/100
188/188 - 0s - loss: 0.0035
Epoch 48/100
188/188 - 0s - loss: 0.0035
Epoch 49/100
188/188 - 0s - loss: 0.0036
Epoch 50/100
188/188 - 0s - loss: 0.0035
Epoch 51/100
188/188 - 0s - loss: 0.0038
Epoch 52/100
188/188 - 0s - loss: 0.0036
Epoch 53/100
188/188 - 0s - loss: 0.0034
Epoch 54/100
188/188 - 0s - loss: 0.0034
Epoch 55/100
188/188 - 0s - loss: 0.0034
Epoch 56/100
188/188 - 0s - loss: 0.0037
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0035
Epoch 59/100
188/188 - 0s - loss: 0.0035
Epoch 60/100
188/188 - 0s - loss: 0.0035
Epoch 61/100
188/188 - 0s - loss: 0.0034
Epoch 62/100
188/188 - 0s - loss: 0.0036
Epoch 63/100
188/188 - 0s - loss: 0.0034
Epoch 64/100
188/188 - 0s - loss: 0.0036
Epoch 65/100
188/188 - 0s - loss: 0.0036
Epoch 66/100
188/188 - 0s - loss: 0.0036
Epoch 67/100
188/188 - 0s - loss: 0.0033
Epoch 68/100
188/188 - 0s - loss: 0.0034
Epoch 69/100
188/188 - 0s - loss: 0.0035
Epoch 70/100
188/188 - 0s - loss: 0.0035
Epoch 71/100
188/188 - 0s - loss: 0.0035
Epoch 72/100
188/188 - 0s - loss: 0.0034
Epoch 73/100
188/188 - 0s - loss: 0.0034
Epoch 74/100
188/188 - 0s - loss: 0.0034
Epoch 75/100
188/188 - 0s - loss: 0.0033
Epoch 76/100
188/188 - 0s - loss: 0.0034
Epoch 77/100
188/188 - 0s - loss: 0.0033
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0034
Epoch 80/100
188/188 - 0s - loss: 0.0032
Epoch 81/100
188/188 - 0s - loss: 0.0033
Epoch 82/100
188/188 - 0s - loss: 0.0034
Epoch 83/100
188/188 - 0s - loss: 0.0033
Epoch 84/100
188/188 - 0s - loss: 0.0035
Epoch 85/100
188/188 - 0s - loss: 0.0034
Epoch 86/100
188/188 - 0s - loss: 0.0033
Epoch 87/100
188/188 - 0s - loss: 0.0033
Epoch 88/100
188/188 - 0s - loss: 0.0032
Epoch 89/100
188/188 - 0s - loss: 0.0034
Epoch 90/100
188/188 - 0s - loss: 0.0033
Epoch 91/100
188/188 - 0s - loss: 0.0031
Epoch 92/100
188/188 - 0s - loss: 0.0032
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0034
Epoch 95/100
188/188 - 0s - loss: 0.0033
Epoch 96/100
188/188 - 0s - loss: 0.0031
Epoch 97/100
188/188 - 0s - loss: 0.0033
Epoch 98/100
188/188 - 0s - loss: 0.0032
Epoch 99/100
188/188 - 0s - loss: 0.0031
Epoch 100/100
188/188 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.055
Train RMSE: 0.101
key_word: COVID-19
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.522124  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.530973  0.522124  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.522124  0.530973  0.522124
2021-08-08  0.424779  0.628319  0.522124  ...  0.530973  0.522124  0.530973
2021-08-15  0.495575  0.424779  0.628319  ...  0.522124  0.530973  0.522124

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_16 (SimpleRNN)    (None, 8)                 264       
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 9         
=================================================================
Total params: 273
Trainable params: 273
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0047
Epoch 2/100
188/188 - 0s - loss: 0.0047
Epoch 3/100
188/188 - 0s - loss: 0.0040
Epoch 4/100
188/188 - 0s - loss: 0.0050
Epoch 5/100
188/188 - 0s - loss: 0.0043
Epoch 6/100
188/188 - 0s - loss: 0.0045
Epoch 7/100
188/188 - 0s - loss: 0.0040
Epoch 8/100
188/188 - 0s - loss: 0.0039
Epoch 9/100
188/188 - 0s - loss: 0.0041
Epoch 10/100
188/188 - 0s - loss: 0.0038
Epoch 11/100
188/188 - 0s - loss: 0.0035
Epoch 12/100
188/188 - 0s - loss: 0.0040
Epoch 13/100
188/188 - 0s - loss: 0.0037
Epoch 14/100
188/188 - 0s - loss: 0.0036
Epoch 15/100
188/188 - 0s - loss: 0.0037
Epoch 16/100
188/188 - 0s - loss: 0.0038
Epoch 17/100
188/188 - 0s - loss: 0.0038
Epoch 18/100
188/188 - 0s - loss: 0.0038
Epoch 19/100
188/188 - 0s - loss: 0.0038
Epoch 20/100
188/188 - 0s - loss: 0.0037
Epoch 21/100
188/188 - 0s - loss: 0.0037
Epoch 22/100
188/188 - 0s - loss: 0.0037
Epoch 23/100
188/188 - 0s - loss: 0.0037
Epoch 24/100
188/188 - 0s - loss: 0.0033
Epoch 25/100
188/188 - 0s - loss: 0.0038
Epoch 26/100
188/188 - 0s - loss: 0.0035
Epoch 27/100
188/188 - 0s - loss: 0.0035
Epoch 28/100
188/188 - 0s - loss: 0.0035
Epoch 29/100
188/188 - 0s - loss: 0.0035
Epoch 30/100
188/188 - 0s - loss: 0.0035
Epoch 31/100
188/188 - 0s - loss: 0.0033
Epoch 32/100
188/188 - 0s - loss: 0.0034
Epoch 33/100
188/188 - 0s - loss: 0.0034
Epoch 34/100
188/188 - 0s - loss: 0.0033
Epoch 35/100
188/188 - 0s - loss: 0.0033
Epoch 36/100
188/188 - 0s - loss: 0.0034
Epoch 37/100
188/188 - 0s - loss: 0.0034
Epoch 38/100
188/188 - 0s - loss: 0.0034
Epoch 39/100
188/188 - 0s - loss: 0.0035
Epoch 40/100
188/188 - 0s - loss: 0.0032
Epoch 41/100
188/188 - 0s - loss: 0.0033
Epoch 42/100
188/188 - 0s - loss: 0.0035
Epoch 43/100
188/188 - 0s - loss: 0.0031
Epoch 44/100
188/188 - 0s - loss: 0.0031
Epoch 45/100
188/188 - 0s - loss: 0.0036
Epoch 46/100
188/188 - 0s - loss: 0.0032
Epoch 47/100
188/188 - 0s - loss: 0.0034
Epoch 48/100
188/188 - 0s - loss: 0.0033
Epoch 49/100
188/188 - 0s - loss: 0.0035
Epoch 50/100
188/188 - 0s - loss: 0.0035
Epoch 51/100
188/188 - 0s - loss: 0.0032
Epoch 52/100
188/188 - 0s - loss: 0.0035
Epoch 53/100
188/188 - 0s - loss: 0.0032
Epoch 54/100
188/188 - 0s - loss: 0.0033
Epoch 55/100
188/188 - 0s - loss: 0.0033
Epoch 56/100
188/188 - 0s - loss: 0.0032
Epoch 57/100
188/188 - 0s - loss: 0.0031
Epoch 58/100
188/188 - 0s - loss: 0.0032
Epoch 59/100
188/188 - 0s - loss: 0.0030
Epoch 60/100
188/188 - 0s - loss: 0.0031
Epoch 61/100
188/188 - 0s - loss: 0.0033
Epoch 62/100
188/188 - 0s - loss: 0.0032
Epoch 63/100
188/188 - 0s - loss: 0.0033
Epoch 64/100
188/188 - 0s - loss: 0.0032
Epoch 65/100
188/188 - 0s - loss: 0.0030
Epoch 66/100
188/188 - 0s - loss: 0.0032
Epoch 67/100
188/188 - 0s - loss: 0.0031
Epoch 68/100
188/188 - 0s - loss: 0.0031
Epoch 69/100
188/188 - 0s - loss: 0.0033
Epoch 70/100
188/188 - 0s - loss: 0.0030
Epoch 71/100
188/188 - 0s - loss: 0.0031
Epoch 72/100
188/188 - 0s - loss: 0.0029
Epoch 73/100
188/188 - 0s - loss: 0.0031
Epoch 74/100
188/188 - 0s - loss: 0.0030
Epoch 75/100
188/188 - 0s - loss: 0.0032
Epoch 76/100
188/188 - 0s - loss: 0.0031
Epoch 77/100
188/188 - 0s - loss: 0.0029
Epoch 78/100
188/188 - 0s - loss: 0.0032
Epoch 79/100
188/188 - 0s - loss: 0.0031
Epoch 80/100
188/188 - 0s - loss: 0.0031
Epoch 81/100
188/188 - 0s - loss: 0.0030
Epoch 82/100
188/188 - 0s - loss: 0.0031
Epoch 83/100
188/188 - 0s - loss: 0.0030
Epoch 84/100
188/188 - 0s - loss: 0.0029
Epoch 85/100
188/188 - 0s - loss: 0.0030
Epoch 86/100
188/188 - 0s - loss: 0.0031
Epoch 87/100
188/188 - 0s - loss: 0.0030
Epoch 88/100
188/188 - 0s - loss: 0.0030
Epoch 89/100
188/188 - 0s - loss: 0.0030
Epoch 90/100
188/188 - 0s - loss: 0.0030
Epoch 91/100
188/188 - 0s - loss: 0.0030
Epoch 92/100
188/188 - 0s - loss: 0.0029
Epoch 93/100
188/188 - 0s - loss: 0.0029
Epoch 94/100
188/188 - 0s - loss: 0.0028
Epoch 95/100
188/188 - 0s - loss: 0.0028
Epoch 96/100
188/188 - 0s - loss: 0.0032
Epoch 97/100
188/188 - 0s - loss: 0.0028
Epoch 98/100
188/188 - 0s - loss: 0.0029
Epoch 99/100
188/188 - 0s - loss: 0.0028
Epoch 100/100
188/188 - 0s - loss: 0.0029

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.051
Train RMSE: 0.116
key_word: COVID-19
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.522124  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.530973  0.522124  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.522124  0.530973  0.522124
2021-08-08  0.424779  0.628319  0.522124  ...  0.530973  0.522124  0.530973
2021-08-15  0.495575  0.424779  0.628319  ...  0.522124  0.530973  0.522124

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_17 (SimpleRNN)    (None, 16)                656       
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 17        
=================================================================
Total params: 673
Trainable params: 673
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0129
Epoch 2/100
188/188 - 0s - loss: 0.0056
Epoch 3/100
188/188 - 0s - loss: 0.0060
Epoch 4/100
188/188 - 0s - loss: 0.0055
Epoch 5/100
188/188 - 0s - loss: 0.0054
Epoch 6/100
188/188 - 0s - loss: 0.0047
Epoch 7/100
188/188 - 0s - loss: 0.0045
Epoch 8/100
188/188 - 0s - loss: 0.0044
Epoch 9/100
188/188 - 0s - loss: 0.0047
Epoch 10/100
188/188 - 0s - loss: 0.0042
Epoch 11/100
188/188 - 0s - loss: 0.0045
Epoch 12/100
188/188 - 0s - loss: 0.0041
Epoch 13/100
188/188 - 0s - loss: 0.0049
Epoch 14/100
188/188 - 0s - loss: 0.0046
Epoch 15/100
188/188 - 0s - loss: 0.0041
Epoch 16/100
188/188 - 0s - loss: 0.0036
Epoch 17/100
188/188 - 0s - loss: 0.0039
Epoch 18/100
188/188 - 0s - loss: 0.0042
Epoch 19/100
188/188 - 0s - loss: 0.0041
Epoch 20/100
188/188 - 0s - loss: 0.0035
Epoch 21/100
188/188 - 0s - loss: 0.0035
Epoch 22/100
188/188 - 0s - loss: 0.0037
Epoch 23/100
188/188 - 0s - loss: 0.0042
Epoch 24/100
188/188 - 0s - loss: 0.0034
Epoch 25/100
188/188 - 0s - loss: 0.0035
Epoch 26/100
188/188 - 0s - loss: 0.0036
Epoch 27/100
188/188 - 0s - loss: 0.0030
Epoch 28/100
188/188 - 0s - loss: 0.0035
Epoch 29/100
188/188 - 0s - loss: 0.0035
Epoch 30/100
188/188 - 0s - loss: 0.0031
Epoch 31/100
188/188 - 0s - loss: 0.0031
Epoch 32/100
188/188 - 0s - loss: 0.0037
Epoch 33/100
188/188 - 0s - loss: 0.0035
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0031
Epoch 36/100
188/188 - 0s - loss: 0.0038
Epoch 37/100
188/188 - 0s - loss: 0.0033
Epoch 38/100
188/188 - 0s - loss: 0.0031
Epoch 39/100
188/188 - 0s - loss: 0.0032
Epoch 40/100
188/188 - 0s - loss: 0.0033
Epoch 41/100
188/188 - 0s - loss: 0.0030
Epoch 42/100
188/188 - 0s - loss: 0.0034
Epoch 43/100
188/188 - 0s - loss: 0.0032
Epoch 44/100
188/188 - 0s - loss: 0.0038
Epoch 45/100
188/188 - 0s - loss: 0.0031
Epoch 46/100
188/188 - 0s - loss: 0.0032
Epoch 47/100
188/188 - 0s - loss: 0.0031
Epoch 48/100
188/188 - 0s - loss: 0.0029
Epoch 49/100
188/188 - 0s - loss: 0.0034
Epoch 50/100
188/188 - 0s - loss: 0.0033
Epoch 51/100
188/188 - 0s - loss: 0.0030
Epoch 52/100
188/188 - 0s - loss: 0.0029
Epoch 53/100
188/188 - 0s - loss: 0.0032
Epoch 54/100
188/188 - 0s - loss: 0.0033
Epoch 55/100
188/188 - 0s - loss: 0.0031
Epoch 56/100
188/188 - 0s - loss: 0.0030
Epoch 57/100
188/188 - 0s - loss: 0.0031
Epoch 58/100
188/188 - 0s - loss: 0.0032
Epoch 59/100
188/188 - 0s - loss: 0.0031
Epoch 60/100
188/188 - 0s - loss: 0.0032
Epoch 61/100
188/188 - 0s - loss: 0.0031
Epoch 62/100
188/188 - 0s - loss: 0.0030
Epoch 63/100
188/188 - 0s - loss: 0.0028
Epoch 64/100
188/188 - 0s - loss: 0.0030
Epoch 65/100
188/188 - 0s - loss: 0.0027
Epoch 66/100
188/188 - 0s - loss: 0.0030
Epoch 67/100
188/188 - 0s - loss: 0.0031
Epoch 68/100
188/188 - 0s - loss: 0.0034
Epoch 69/100
188/188 - 0s - loss: 0.0030
Epoch 70/100
188/188 - 0s - loss: 0.0027
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0030
Epoch 73/100
188/188 - 0s - loss: 0.0028
Epoch 74/100
188/188 - 0s - loss: 0.0030
Epoch 75/100
188/188 - 0s - loss: 0.0028
Epoch 76/100
188/188 - 0s - loss: 0.0030
Epoch 77/100
188/188 - 0s - loss: 0.0030
Epoch 78/100
188/188 - 0s - loss: 0.0030
Epoch 79/100
188/188 - 0s - loss: 0.0027
Epoch 80/100
188/188 - 0s - loss: 0.0027
Epoch 81/100
188/188 - 0s - loss: 0.0031
Epoch 82/100
188/188 - 0s - loss: 0.0029
Epoch 83/100
188/188 - 0s - loss: 0.0029
Epoch 84/100
188/188 - 0s - loss: 0.0037
Epoch 85/100
188/188 - 0s - loss: 0.0028
Epoch 86/100
188/188 - 0s - loss: 0.0026
Epoch 87/100
188/188 - 0s - loss: 0.0028
Epoch 88/100
188/188 - 0s - loss: 0.0028
Epoch 89/100
188/188 - 0s - loss: 0.0027
Epoch 90/100
188/188 - 0s - loss: 0.0028
Epoch 91/100
188/188 - 0s - loss: 0.0027
Epoch 92/100
188/188 - 0s - loss: 0.0029
Epoch 93/100
188/188 - 0s - loss: 0.0024
Epoch 94/100
188/188 - 0s - loss: 0.0028
Epoch 95/100
188/188 - 0s - loss: 0.0030
Epoch 96/100
188/188 - 0s - loss: 0.0028
Epoch 97/100
188/188 - 0s - loss: 0.0027
Epoch 98/100
188/188 - 0s - loss: 0.0030
Epoch 99/100
188/188 - 0s - loss: 0.0031
Epoch 100/100
188/188 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.047
Train RMSE: 0.119
key_word: COVID-19
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.522124  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.530973  0.522124  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.522124  0.530973  0.522124
2021-08-08  0.424779  0.628319  0.522124  ...  0.530973  0.522124  0.530973
2021-08-15  0.495575  0.424779  0.628319  ...  0.522124  0.530973  0.522124

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_18 (SimpleRNN)    (None, 32)                1824      
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 33        
=================================================================
Total params: 1,857
Trainable params: 1,857
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0744
Epoch 2/100
188/188 - 0s - loss: 0.0061
Epoch 3/100
188/188 - 0s - loss: 0.0061
Epoch 4/100
188/188 - 0s - loss: 0.0066
Epoch 5/100
188/188 - 0s - loss: 0.0064
Epoch 6/100
188/188 - 0s - loss: 0.0062
Epoch 7/100
188/188 - 0s - loss: 0.0059
Epoch 8/100
188/188 - 0s - loss: 0.0049
Epoch 9/100
188/188 - 0s - loss: 0.0056
Epoch 10/100
188/188 - 0s - loss: 0.0055
Epoch 11/100
188/188 - 0s - loss: 0.0050
Epoch 12/100
188/188 - 0s - loss: 0.0053
Epoch 13/100
188/188 - 0s - loss: 0.0045
Epoch 14/100
188/188 - 0s - loss: 0.0053
Epoch 15/100
188/188 - 0s - loss: 0.0044
Epoch 16/100
188/188 - 0s - loss: 0.0050
Epoch 17/100
188/188 - 0s - loss: 0.0044
Epoch 18/100
188/188 - 0s - loss: 0.0041
Epoch 19/100
188/188 - 0s - loss: 0.0047
Epoch 20/100
188/188 - 0s - loss: 0.0044
Epoch 21/100
188/188 - 0s - loss: 0.0041
Epoch 22/100
188/188 - 0s - loss: 0.0045
Epoch 23/100
188/188 - 0s - loss: 0.0045
Epoch 24/100
188/188 - 0s - loss: 0.0041
Epoch 25/100
188/188 - 0s - loss: 0.0041
Epoch 26/100
188/188 - 0s - loss: 0.0041
Epoch 27/100
188/188 - 0s - loss: 0.0044
Epoch 28/100
188/188 - 0s - loss: 0.0041
Epoch 29/100
188/188 - 0s - loss: 0.0042
Epoch 30/100
188/188 - 0s - loss: 0.0040
Epoch 31/100
188/188 - 0s - loss: 0.0037
Epoch 32/100
188/188 - 0s - loss: 0.0037
Epoch 33/100
188/188 - 0s - loss: 0.0043
Epoch 34/100
188/188 - 0s - loss: 0.0037
Epoch 35/100
188/188 - 0s - loss: 0.0035
Epoch 36/100
188/188 - 0s - loss: 0.0038
Epoch 37/100
188/188 - 0s - loss: 0.0045
Epoch 38/100
188/188 - 0s - loss: 0.0037
Epoch 39/100
188/188 - 0s - loss: 0.0038
Epoch 40/100
188/188 - 0s - loss: 0.0039
Epoch 41/100
188/188 - 0s - loss: 0.0036
Epoch 42/100
188/188 - 0s - loss: 0.0039
Epoch 43/100
188/188 - 0s - loss: 0.0036
Epoch 44/100
188/188 - 0s - loss: 0.0039
Epoch 45/100
188/188 - 0s - loss: 0.0038
Epoch 46/100
188/188 - 0s - loss: 0.0038
Epoch 47/100
188/188 - 0s - loss: 0.0041
Epoch 48/100
188/188 - 0s - loss: 0.0040
Epoch 49/100
188/188 - 0s - loss: 0.0037
Epoch 50/100
188/188 - 0s - loss: 0.0036
Epoch 51/100
188/188 - 0s - loss: 0.0038
Epoch 52/100
188/188 - 0s - loss: 0.0032
Epoch 53/100
188/188 - 0s - loss: 0.0036
Epoch 54/100
188/188 - 0s - loss: 0.0032
Epoch 55/100
188/188 - 0s - loss: 0.0036
Epoch 56/100
188/188 - 0s - loss: 0.0038
Epoch 57/100
188/188 - 0s - loss: 0.0031
Epoch 58/100
188/188 - 0s - loss: 0.0034
Epoch 59/100
188/188 - 0s - loss: 0.0039
Epoch 60/100
188/188 - 0s - loss: 0.0034
Epoch 61/100
188/188 - 0s - loss: 0.0037
Epoch 62/100
188/188 - 0s - loss: 0.0034
Epoch 63/100
188/188 - 0s - loss: 0.0032
Epoch 64/100
188/188 - 0s - loss: 0.0031
Epoch 65/100
188/188 - 0s - loss: 0.0037
Epoch 66/100
188/188 - 0s - loss: 0.0033
Epoch 67/100
188/188 - 0s - loss: 0.0033
Epoch 68/100
188/188 - 0s - loss: 0.0032
Epoch 69/100
188/188 - 0s - loss: 0.0035
Epoch 70/100
188/188 - 0s - loss: 0.0038
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0036
Epoch 73/100
188/188 - 0s - loss: 0.0034
Epoch 74/100
188/188 - 0s - loss: 0.0034
Epoch 75/100
188/188 - 0s - loss: 0.0033
Epoch 76/100
188/188 - 0s - loss: 0.0032
Epoch 77/100
188/188 - 0s - loss: 0.0031
Epoch 78/100
188/188 - 0s - loss: 0.0032
Epoch 79/100
188/188 - 0s - loss: 0.0035
Epoch 80/100
188/188 - 0s - loss: 0.0031
Epoch 81/100
188/188 - 0s - loss: 0.0032
Epoch 82/100
188/188 - 0s - loss: 0.0034
Epoch 83/100
188/188 - 0s - loss: 0.0036
Epoch 84/100
188/188 - 0s - loss: 0.0032
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0032
Epoch 87/100
188/188 - 0s - loss: 0.0031
Epoch 88/100
188/188 - 0s - loss: 0.0033
Epoch 89/100
188/188 - 0s - loss: 0.0031
Epoch 90/100
188/188 - 0s - loss: 0.0031
Epoch 91/100
188/188 - 0s - loss: 0.0034
Epoch 92/100
188/188 - 0s - loss: 0.0030
Epoch 93/100
188/188 - 0s - loss: 0.0029
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0033
Epoch 96/100
188/188 - 0s - loss: 0.0033
Epoch 97/100
188/188 - 0s - loss: 0.0028
Epoch 98/100
188/188 - 0s - loss: 0.0032
Epoch 99/100
188/188 - 0s - loss: 0.0031
Epoch 100/100
188/188 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.050
Train RMSE: 0.106
key_word: COVID-19
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.522124  0.530973  0.530973  ...  0.522124  0.513274  0.522124
2021-07-25  0.522124  0.522124  0.530973  ...  0.530973  0.522124  0.513274
2021-08-01  0.628319  0.522124  0.522124  ...  0.522124  0.530973  0.522124
2021-08-08  0.424779  0.628319  0.522124  ...  0.530973  0.522124  0.530973
2021-08-15  0.495575  0.424779  0.628319  ...  0.522124  0.530973  0.522124

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_19 (SimpleRNN)    (None, 60)                5100      
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 61        
=================================================================
Total params: 5,161
Trainable params: 5,161
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0201
Epoch 2/100
188/188 - 0s - loss: 0.0073
Epoch 3/100
188/188 - 0s - loss: 0.0070
Epoch 4/100
188/188 - 0s - loss: 0.0067
Epoch 5/100
188/188 - 0s - loss: 0.0053
Epoch 6/100
188/188 - 0s - loss: 0.0062
Epoch 7/100
188/188 - 0s - loss: 0.0058
Epoch 8/100
188/188 - 0s - loss: 0.0060
Epoch 9/100
188/188 - 0s - loss: 0.0063
Epoch 10/100
188/188 - 0s - loss: 0.0057
Epoch 11/100
188/188 - 0s - loss: 0.0047
Epoch 12/100
188/188 - 0s - loss: 0.0044
Epoch 13/100
188/188 - 0s - loss: 0.0062
Epoch 14/100
188/188 - 0s - loss: 0.0051
Epoch 15/100
188/188 - 0s - loss: 0.0045
Epoch 16/100
188/188 - 0s - loss: 0.0048
Epoch 17/100
188/188 - 0s - loss: 0.0051
Epoch 18/100
188/188 - 0s - loss: 0.0048
Epoch 19/100
188/188 - 0s - loss: 0.0047
Epoch 20/100
188/188 - 0s - loss: 0.0044
Epoch 21/100
188/188 - 0s - loss: 0.0043
Epoch 22/100
188/188 - 0s - loss: 0.0038
Epoch 23/100
188/188 - 0s - loss: 0.0037
Epoch 24/100
188/188 - 0s - loss: 0.0045
Epoch 25/100
188/188 - 0s - loss: 0.0043
Epoch 26/100
188/188 - 0s - loss: 0.0039
Epoch 27/100
188/188 - 0s - loss: 0.0044
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0041
Epoch 30/100
188/188 - 0s - loss: 0.0043
Epoch 31/100
188/188 - 0s - loss: 0.0041
Epoch 32/100
188/188 - 0s - loss: 0.0041
Epoch 33/100
188/188 - 0s - loss: 0.0041
Epoch 34/100
188/188 - 0s - loss: 0.0045
Epoch 35/100
188/188 - 0s - loss: 0.0044
Epoch 36/100
188/188 - 0s - loss: 0.0042
Epoch 37/100
188/188 - 0s - loss: 0.0038
Epoch 38/100
188/188 - 0s - loss: 0.0039
Epoch 39/100
188/188 - 0s - loss: 0.0039
Epoch 40/100
188/188 - 0s - loss: 0.0041
Epoch 41/100
188/188 - 0s - loss: 0.0041
Epoch 42/100
188/188 - 0s - loss: 0.0035
Epoch 43/100
188/188 - 0s - loss: 0.0033
Epoch 44/100
188/188 - 0s - loss: 0.0050
Epoch 45/100
188/188 - 0s - loss: 0.0045
Epoch 46/100
188/188 - 0s - loss: 0.0034
Epoch 47/100
188/188 - 0s - loss: 0.0036
Epoch 48/100
188/188 - 0s - loss: 0.0037
Epoch 49/100
188/188 - 0s - loss: 0.0034
Epoch 50/100
188/188 - 0s - loss: 0.0036
Epoch 51/100
188/188 - 0s - loss: 0.0037
Epoch 52/100
188/188 - 0s - loss: 0.0035
Epoch 53/100
188/188 - 0s - loss: 0.0037
Epoch 54/100
188/188 - 0s - loss: 0.0040
Epoch 55/100
188/188 - 0s - loss: 0.0032
Epoch 56/100
188/188 - 0s - loss: 0.0036
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0036
Epoch 59/100
188/188 - 0s - loss: 0.0037
Epoch 60/100
188/188 - 0s - loss: 0.0034
Epoch 61/100
188/188 - 0s - loss: 0.0038
Epoch 62/100
188/188 - 0s - loss: 0.0036
Epoch 63/100
188/188 - 0s - loss: 0.0036
Epoch 64/100
188/188 - 0s - loss: 0.0037
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0036
Epoch 67/100
188/188 - 0s - loss: 0.0035
Epoch 68/100
188/188 - 0s - loss: 0.0034
Epoch 69/100
188/188 - 0s - loss: 0.0034
Epoch 70/100
188/188 - 0s - loss: 0.0041
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0034
Epoch 73/100
188/188 - 0s - loss: 0.0037
Epoch 74/100
188/188 - 0s - loss: 0.0036
Epoch 75/100
188/188 - 0s - loss: 0.0036
Epoch 76/100
188/188 - 0s - loss: 0.0034
Epoch 77/100
188/188 - 0s - loss: 0.0033
Epoch 78/100
188/188 - 0s - loss: 0.0032
Epoch 79/100
188/188 - 0s - loss: 0.0032
Epoch 80/100
188/188 - 0s - loss: 0.0036
Epoch 81/100
188/188 - 0s - loss: 0.0034
Epoch 82/100
188/188 - 0s - loss: 0.0034
Epoch 83/100
188/188 - 0s - loss: 0.0032
Epoch 84/100
188/188 - 0s - loss: 0.0038
Epoch 85/100
188/188 - 0s - loss: 0.0031
Epoch 86/100
188/188 - 0s - loss: 0.0033
Epoch 87/100
188/188 - 0s - loss: 0.0033
Epoch 88/100
188/188 - 0s - loss: 0.0033
Epoch 89/100
188/188 - 0s - loss: 0.0034
Epoch 90/100
188/188 - 0s - loss: 0.0033
Epoch 91/100
188/188 - 0s - loss: 0.0034
Epoch 92/100
188/188 - 0s - loss: 0.0036
Epoch 93/100
188/188 - 0s - loss: 0.0033
Epoch 94/100
188/188 - 0s - loss: 0.0029
Epoch 95/100
188/188 - 0s - loss: 0.0035
Epoch 96/100
188/188 - 0s - loss: 0.0036
Epoch 97/100
188/188 - 0s - loss: 0.0032
Epoch 98/100
188/188 - 0s - loss: 0.0038
Epoch 99/100
188/188 - 0s - loss: 0.0033
Epoch 100/100
188/188 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.137
Train RMSE: 0.160
key_word: COVID-19
window size: 24
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.470588  0.411765  0.352941
2021-07-25  0.411765  0.470588  0.470588  ...  0.352941  0.470588  0.411765
2021-08-01  0.352941  0.411765  0.470588  ...  0.411765  0.352941  0.470588
2021-08-08  0.411765  0.352941  0.411765  ...  0.411765  0.411765  0.352941
2021-08-15  0.000000  0.411765  0.352941  ...  0.411765  0.411765  0.411765

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_20 (SimpleRNN)    (None, 4)                 68        
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 5         
=================================================================
Total params: 73
Trainable params: 73
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.1089
Epoch 2/100
198/198 - 0s - loss: 0.0169
Epoch 3/100
198/198 - 0s - loss: 0.0162
Epoch 4/100
198/198 - 0s - loss: 0.0152
Epoch 5/100
198/198 - 0s - loss: 0.0143
Epoch 6/100
198/198 - 0s - loss: 0.0130
Epoch 7/100
198/198 - 0s - loss: 0.0120
Epoch 8/100
198/198 - 0s - loss: 0.0109
Epoch 9/100
198/198 - 0s - loss: 0.0103
Epoch 10/100
198/198 - 0s - loss: 0.0099
Epoch 11/100
198/198 - 0s - loss: 0.0089
Epoch 12/100
198/198 - 0s - loss: 0.0087
Epoch 13/100
198/198 - 0s - loss: 0.0082
Epoch 14/100
198/198 - 0s - loss: 0.0080
Epoch 15/100
198/198 - 0s - loss: 0.0073
Epoch 16/100
198/198 - 0s - loss: 0.0068
Epoch 17/100
198/198 - 0s - loss: 0.0065
Epoch 18/100
198/198 - 0s - loss: 0.0062
Epoch 19/100
198/198 - 0s - loss: 0.0062
Epoch 20/100
198/198 - 0s - loss: 0.0062
Epoch 21/100
198/198 - 0s - loss: 0.0060
Epoch 22/100
198/198 - 0s - loss: 0.0055
Epoch 23/100
198/198 - 0s - loss: 0.0055
Epoch 24/100
198/198 - 0s - loss: 0.0053
Epoch 25/100
198/198 - 0s - loss: 0.0053
Epoch 26/100
198/198 - 0s - loss: 0.0052
Epoch 27/100
198/198 - 0s - loss: 0.0051
Epoch 28/100
198/198 - 0s - loss: 0.0051
Epoch 29/100
198/198 - 0s - loss: 0.0050
Epoch 30/100
198/198 - 0s - loss: 0.0050
Epoch 31/100
198/198 - 0s - loss: 0.0050
Epoch 32/100
198/198 - 0s - loss: 0.0048
Epoch 33/100
198/198 - 0s - loss: 0.0051
Epoch 34/100
198/198 - 0s - loss: 0.0048
Epoch 35/100
198/198 - 0s - loss: 0.0047
Epoch 36/100
198/198 - 0s - loss: 0.0048
Epoch 37/100
198/198 - 0s - loss: 0.0045
Epoch 38/100
198/198 - 0s - loss: 0.0046
Epoch 39/100
198/198 - 0s - loss: 0.0044
Epoch 40/100
198/198 - 0s - loss: 0.0047
Epoch 41/100
198/198 - 0s - loss: 0.0048
Epoch 42/100
198/198 - 0s - loss: 0.0046
Epoch 43/100
198/198 - 0s - loss: 0.0048
Epoch 44/100
198/198 - 0s - loss: 0.0045
Epoch 45/100
198/198 - 0s - loss: 0.0047
Epoch 46/100
198/198 - 0s - loss: 0.0045
Epoch 47/100
198/198 - 0s - loss: 0.0046
Epoch 48/100
198/198 - 0s - loss: 0.0046
Epoch 49/100
198/198 - 0s - loss: 0.0044
Epoch 50/100
198/198 - 0s - loss: 0.0046
Epoch 51/100
198/198 - 0s - loss: 0.0043
Epoch 52/100
198/198 - 0s - loss: 0.0047
Epoch 53/100
198/198 - 0s - loss: 0.0043
Epoch 54/100
198/198 - 0s - loss: 0.0044
Epoch 55/100
198/198 - 0s - loss: 0.0043
Epoch 56/100
198/198 - 0s - loss: 0.0044
Epoch 57/100
198/198 - 0s - loss: 0.0045
Epoch 58/100
198/198 - 0s - loss: 0.0045
Epoch 59/100
198/198 - 0s - loss: 0.0046
Epoch 60/100
198/198 - 0s - loss: 0.0043
Epoch 61/100
198/198 - 0s - loss: 0.0043
Epoch 62/100
198/198 - 0s - loss: 0.0044
Epoch 63/100
198/198 - 0s - loss: 0.0045
Epoch 64/100
198/198 - 0s - loss: 0.0043
Epoch 65/100
198/198 - 0s - loss: 0.0044
Epoch 66/100
198/198 - 0s - loss: 0.0042
Epoch 67/100
198/198 - 0s - loss: 0.0043
Epoch 68/100
198/198 - 0s - loss: 0.0043
Epoch 69/100
198/198 - 0s - loss: 0.0042
Epoch 70/100
198/198 - 0s - loss: 0.0044
Epoch 71/100
198/198 - 0s - loss: 0.0041
Epoch 72/100
198/198 - 0s - loss: 0.0043
Epoch 73/100
198/198 - 0s - loss: 0.0043
Epoch 74/100
198/198 - 0s - loss: 0.0042
Epoch 75/100
198/198 - 0s - loss: 0.0044
Epoch 76/100
198/198 - 0s - loss: 0.0043
Epoch 77/100
198/198 - 0s - loss: 0.0045
Epoch 78/100
198/198 - 0s - loss: 0.0045
Epoch 79/100
198/198 - 0s - loss: 0.0044
Epoch 80/100
198/198 - 0s - loss: 0.0045
Epoch 81/100
198/198 - 0s - loss: 0.0043
Epoch 82/100
198/198 - 0s - loss: 0.0044
Epoch 83/100
198/198 - 0s - loss: 0.0044
Epoch 84/100
198/198 - 0s - loss: 0.0043
Epoch 85/100
198/198 - 0s - loss: 0.0042
Epoch 86/100
198/198 - 0s - loss: 0.0043
Epoch 87/100
198/198 - 0s - loss: 0.0045
Epoch 88/100
198/198 - 0s - loss: 0.0043
Epoch 89/100
198/198 - 0s - loss: 0.0043
Epoch 90/100
198/198 - 0s - loss: 0.0046
Epoch 91/100
198/198 - 0s - loss: 0.0043
Epoch 92/100
198/198 - 0s - loss: 0.0043
Epoch 93/100
198/198 - 0s - loss: 0.0042
Epoch 94/100
198/198 - 0s - loss: 0.0043
Epoch 95/100
198/198 - 0s - loss: 0.0043
Epoch 96/100
198/198 - 0s - loss: 0.0044
Epoch 97/100
198/198 - 0s - loss: 0.0043
Epoch 98/100
198/198 - 0s - loss: 0.0042
Epoch 99/100
198/198 - 0s - loss: 0.0043
Epoch 100/100
198/198 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.145
key_word: stock price
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.470588  0.411765  0.352941
2021-07-25  0.411765  0.470588  0.470588  ...  0.352941  0.470588  0.411765
2021-08-01  0.352941  0.411765  0.470588  ...  0.411765  0.352941  0.470588
2021-08-08  0.411765  0.352941  0.411765  ...  0.411765  0.411765  0.352941
2021-08-15  0.000000  0.411765  0.352941  ...  0.411765  0.411765  0.411765

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_21 (SimpleRNN)    (None, 8)                 168       
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 9         
=================================================================
Total params: 177
Trainable params: 177
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0120
Epoch 2/100
198/198 - 0s - loss: 0.0095
Epoch 3/100
198/198 - 0s - loss: 0.0080
Epoch 4/100
198/198 - 0s - loss: 0.0075
Epoch 5/100
198/198 - 0s - loss: 0.0067
Epoch 6/100
198/198 - 0s - loss: 0.0064
Epoch 7/100
198/198 - 0s - loss: 0.0057
Epoch 8/100
198/198 - 0s - loss: 0.0055
Epoch 9/100
198/198 - 0s - loss: 0.0054
Epoch 10/100
198/198 - 0s - loss: 0.0052
Epoch 11/100
198/198 - 0s - loss: 0.0053
Epoch 12/100
198/198 - 0s - loss: 0.0051
Epoch 13/100
198/198 - 0s - loss: 0.0047
Epoch 14/100
198/198 - 0s - loss: 0.0048
Epoch 15/100
198/198 - 0s - loss: 0.0049
Epoch 16/100
198/198 - 0s - loss: 0.0048
Epoch 17/100
198/198 - 0s - loss: 0.0049
Epoch 18/100
198/198 - 0s - loss: 0.0047
Epoch 19/100
198/198 - 0s - loss: 0.0045
Epoch 20/100
198/198 - 0s - loss: 0.0049
Epoch 21/100
198/198 - 0s - loss: 0.0048
Epoch 22/100
198/198 - 0s - loss: 0.0047
Epoch 23/100
198/198 - 0s - loss: 0.0043
Epoch 24/100
198/198 - 0s - loss: 0.0047
Epoch 25/100
198/198 - 0s - loss: 0.0048
Epoch 26/100
198/198 - 0s - loss: 0.0047
Epoch 27/100
198/198 - 0s - loss: 0.0048
Epoch 28/100
198/198 - 0s - loss: 0.0046
Epoch 29/100
198/198 - 0s - loss: 0.0045
Epoch 30/100
198/198 - 0s - loss: 0.0043
Epoch 31/100
198/198 - 0s - loss: 0.0045
Epoch 32/100
198/198 - 0s - loss: 0.0044
Epoch 33/100
198/198 - 0s - loss: 0.0044
Epoch 34/100
198/198 - 0s - loss: 0.0043
Epoch 35/100
198/198 - 0s - loss: 0.0044
Epoch 36/100
198/198 - 0s - loss: 0.0046
Epoch 37/100
198/198 - 0s - loss: 0.0044
Epoch 38/100
198/198 - 0s - loss: 0.0046
Epoch 39/100
198/198 - 0s - loss: 0.0045
Epoch 40/100
198/198 - 0s - loss: 0.0044
Epoch 41/100
198/198 - 0s - loss: 0.0042
Epoch 42/100
198/198 - 0s - loss: 0.0042
Epoch 43/100
198/198 - 0s - loss: 0.0045
Epoch 44/100
198/198 - 0s - loss: 0.0044
Epoch 45/100
198/198 - 0s - loss: 0.0046
Epoch 46/100
198/198 - 0s - loss: 0.0044
Epoch 47/100
198/198 - 0s - loss: 0.0043
Epoch 48/100
198/198 - 0s - loss: 0.0045
Epoch 49/100
198/198 - 0s - loss: 0.0045
Epoch 50/100
198/198 - 0s - loss: 0.0046
Epoch 51/100
198/198 - 0s - loss: 0.0044
Epoch 52/100
198/198 - 0s - loss: 0.0044
Epoch 53/100
198/198 - 0s - loss: 0.0043
Epoch 54/100
198/198 - 0s - loss: 0.0041
Epoch 55/100
198/198 - 0s - loss: 0.0045
Epoch 56/100
198/198 - 0s - loss: 0.0045
Epoch 57/100
198/198 - 0s - loss: 0.0043
Epoch 58/100
198/198 - 0s - loss: 0.0042
Epoch 59/100
198/198 - 0s - loss: 0.0044
Epoch 60/100
198/198 - 0s - loss: 0.0045
Epoch 61/100
198/198 - 0s - loss: 0.0044
Epoch 62/100
198/198 - 0s - loss: 0.0043
Epoch 63/100
198/198 - 0s - loss: 0.0045
Epoch 64/100
198/198 - 0s - loss: 0.0045
Epoch 65/100
198/198 - 0s - loss: 0.0043
Epoch 66/100
198/198 - 0s - loss: 0.0045
Epoch 67/100
198/198 - 0s - loss: 0.0042
Epoch 68/100
198/198 - 0s - loss: 0.0044
Epoch 69/100
198/198 - 0s - loss: 0.0047
Epoch 70/100
198/198 - 0s - loss: 0.0046
Epoch 71/100
198/198 - 0s - loss: 0.0043
Epoch 72/100
198/198 - 0s - loss: 0.0043
Epoch 73/100
198/198 - 0s - loss: 0.0044
Epoch 74/100
198/198 - 0s - loss: 0.0044
Epoch 75/100
198/198 - 0s - loss: 0.0041
Epoch 76/100
198/198 - 0s - loss: 0.0045
Epoch 77/100
198/198 - 0s - loss: 0.0044
Epoch 78/100
198/198 - 0s - loss: 0.0043
Epoch 79/100
198/198 - 0s - loss: 0.0043
Epoch 80/100
198/198 - 0s - loss: 0.0044
Epoch 81/100
198/198 - 0s - loss: 0.0044
Epoch 82/100
198/198 - 0s - loss: 0.0043
Epoch 83/100
198/198 - 0s - loss: 0.0042
Epoch 84/100
198/198 - 0s - loss: 0.0042
Epoch 85/100
198/198 - 0s - loss: 0.0042
Epoch 86/100
198/198 - 0s - loss: 0.0044
Epoch 87/100
198/198 - 0s - loss: 0.0044
Epoch 88/100
198/198 - 0s - loss: 0.0043
Epoch 89/100
198/198 - 0s - loss: 0.0043
Epoch 90/100
198/198 - 0s - loss: 0.0043
Epoch 91/100
198/198 - 0s - loss: 0.0042
Epoch 92/100
198/198 - 0s - loss: 0.0041
Epoch 93/100
198/198 - 0s - loss: 0.0040
Epoch 94/100
198/198 - 0s - loss: 0.0043
Epoch 95/100
198/198 - 0s - loss: 0.0042
Epoch 96/100
198/198 - 0s - loss: 0.0044
Epoch 97/100
198/198 - 0s - loss: 0.0041
Epoch 98/100
198/198 - 0s - loss: 0.0043
Epoch 99/100
198/198 - 0s - loss: 0.0043
Epoch 100/100
198/198 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.062
Train RMSE: 0.142
key_word: stock price
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.470588  0.411765  0.352941
2021-07-25  0.411765  0.470588  0.470588  ...  0.352941  0.470588  0.411765
2021-08-01  0.352941  0.411765  0.470588  ...  0.411765  0.352941  0.470588
2021-08-08  0.411765  0.352941  0.411765  ...  0.411765  0.411765  0.352941
2021-08-15  0.000000  0.411765  0.352941  ...  0.411765  0.411765  0.411765

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_22 (SimpleRNN)    (None, 16)                464       
_________________________________________________________________
dense_22 (Dense)             (None, 1)                 17        
=================================================================
Total params: 481
Trainable params: 481
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0128
Epoch 2/100
198/198 - 0s - loss: 0.0087
Epoch 3/100
198/198 - 0s - loss: 0.0078
Epoch 4/100
198/198 - 0s - loss: 0.0072
Epoch 5/100
198/198 - 0s - loss: 0.0066
Epoch 6/100
198/198 - 0s - loss: 0.0059
Epoch 7/100
198/198 - 0s - loss: 0.0057
Epoch 8/100
198/198 - 0s - loss: 0.0059
Epoch 9/100
198/198 - 0s - loss: 0.0056
Epoch 10/100
198/198 - 0s - loss: 0.0052
Epoch 11/100
198/198 - 0s - loss: 0.0048
Epoch 12/100
198/198 - 0s - loss: 0.0054
Epoch 13/100
198/198 - 0s - loss: 0.0050
Epoch 14/100
198/198 - 0s - loss: 0.0051
Epoch 15/100
198/198 - 0s - loss: 0.0052
Epoch 16/100
198/198 - 0s - loss: 0.0049
Epoch 17/100
198/198 - 0s - loss: 0.0053
Epoch 18/100
198/198 - 0s - loss: 0.0046
Epoch 19/100
198/198 - 0s - loss: 0.0050
Epoch 20/100
198/198 - 0s - loss: 0.0047
Epoch 21/100
198/198 - 0s - loss: 0.0047
Epoch 22/100
198/198 - 0s - loss: 0.0048
Epoch 23/100
198/198 - 0s - loss: 0.0054
Epoch 24/100
198/198 - 0s - loss: 0.0050
Epoch 25/100
198/198 - 0s - loss: 0.0052
Epoch 26/100
198/198 - 0s - loss: 0.0047
Epoch 27/100
198/198 - 0s - loss: 0.0048
Epoch 28/100
198/198 - 0s - loss: 0.0055
Epoch 29/100
198/198 - 0s - loss: 0.0047
Epoch 30/100
198/198 - 0s - loss: 0.0050
Epoch 31/100
198/198 - 0s - loss: 0.0046
Epoch 32/100
198/198 - 0s - loss: 0.0048
Epoch 33/100
198/198 - 0s - loss: 0.0051
Epoch 34/100
198/198 - 0s - loss: 0.0046
Epoch 35/100
198/198 - 0s - loss: 0.0054
Epoch 36/100
198/198 - 0s - loss: 0.0050
Epoch 37/100
198/198 - 0s - loss: 0.0045
Epoch 38/100
198/198 - 0s - loss: 0.0047
Epoch 39/100
198/198 - 0s - loss: 0.0049
Epoch 40/100
198/198 - 0s - loss: 0.0050
Epoch 41/100
198/198 - 0s - loss: 0.0049
Epoch 42/100
198/198 - 0s - loss: 0.0054
Epoch 43/100
198/198 - 0s - loss: 0.0045
Epoch 44/100
198/198 - 0s - loss: 0.0047
Epoch 45/100
198/198 - 0s - loss: 0.0046
Epoch 46/100
198/198 - 0s - loss: 0.0046
Epoch 47/100
198/198 - 0s - loss: 0.0046
Epoch 48/100
198/198 - 0s - loss: 0.0048
Epoch 49/100
198/198 - 0s - loss: 0.0044
Epoch 50/100
198/198 - 0s - loss: 0.0045
Epoch 51/100
198/198 - 0s - loss: 0.0044
Epoch 52/100
198/198 - 0s - loss: 0.0047
Epoch 53/100
198/198 - 0s - loss: 0.0049
Epoch 54/100
198/198 - 0s - loss: 0.0047
Epoch 55/100
198/198 - 0s - loss: 0.0044
Epoch 56/100
198/198 - 0s - loss: 0.0052
Epoch 57/100
198/198 - 0s - loss: 0.0048
Epoch 58/100
198/198 - 0s - loss: 0.0047
Epoch 59/100
198/198 - 0s - loss: 0.0047
Epoch 60/100
198/198 - 0s - loss: 0.0045
Epoch 61/100
198/198 - 0s - loss: 0.0045
Epoch 62/100
198/198 - 0s - loss: 0.0045
Epoch 63/100
198/198 - 0s - loss: 0.0052
Epoch 64/100
198/198 - 0s - loss: 0.0044
Epoch 65/100
198/198 - 0s - loss: 0.0046
Epoch 66/100
198/198 - 0s - loss: 0.0053
Epoch 67/100
198/198 - 0s - loss: 0.0048
Epoch 68/100
198/198 - 0s - loss: 0.0043
Epoch 69/100
198/198 - 0s - loss: 0.0044
Epoch 70/100
198/198 - 0s - loss: 0.0046
Epoch 71/100
198/198 - 0s - loss: 0.0045
Epoch 72/100
198/198 - 0s - loss: 0.0044
Epoch 73/100
198/198 - 0s - loss: 0.0043
Epoch 74/100
198/198 - 0s - loss: 0.0047
Epoch 75/100
198/198 - 0s - loss: 0.0042
Epoch 76/100
198/198 - 0s - loss: 0.0046
Epoch 77/100
198/198 - 0s - loss: 0.0045
Epoch 78/100
198/198 - 0s - loss: 0.0045
Epoch 79/100
198/198 - 0s - loss: 0.0048
Epoch 80/100
198/198 - 0s - loss: 0.0044
Epoch 81/100
198/198 - 0s - loss: 0.0045
Epoch 82/100
198/198 - 0s - loss: 0.0044
Epoch 83/100
198/198 - 0s - loss: 0.0042
Epoch 84/100
198/198 - 0s - loss: 0.0044
Epoch 85/100
198/198 - 0s - loss: 0.0046
Epoch 86/100
198/198 - 0s - loss: 0.0047
Epoch 87/100
198/198 - 0s - loss: 0.0042
Epoch 88/100
198/198 - 0s - loss: 0.0043
Epoch 89/100
198/198 - 0s - loss: 0.0044
Epoch 90/100
198/198 - 0s - loss: 0.0044
Epoch 91/100
198/198 - 0s - loss: 0.0043
Epoch 92/100
198/198 - 0s - loss: 0.0042
Epoch 93/100
198/198 - 0s - loss: 0.0047
Epoch 94/100
198/198 - 0s - loss: 0.0043
Epoch 95/100
198/198 - 0s - loss: 0.0043
Epoch 96/100
198/198 - 0s - loss: 0.0046
Epoch 97/100
198/198 - 0s - loss: 0.0048
Epoch 98/100
198/198 - 0s - loss: 0.0043
Epoch 99/100
198/198 - 0s - loss: 0.0040
Epoch 100/100
198/198 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.071
Train RMSE: 0.143
key_word: stock price
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.470588  0.411765  0.352941
2021-07-25  0.411765  0.470588  0.470588  ...  0.352941  0.470588  0.411765
2021-08-01  0.352941  0.411765  0.470588  ...  0.411765  0.352941  0.470588
2021-08-08  0.411765  0.352941  0.411765  ...  0.411765  0.411765  0.352941
2021-08-15  0.000000  0.411765  0.352941  ...  0.411765  0.411765  0.411765

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_23 (SimpleRNN)    (None, 32)                1440      
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 33        
=================================================================
Total params: 1,473
Trainable params: 1,473
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0147
Epoch 2/100
198/198 - 0s - loss: 0.0100
Epoch 3/100
198/198 - 0s - loss: 0.0077
Epoch 4/100
198/198 - 0s - loss: 0.0074
Epoch 5/100
198/198 - 0s - loss: 0.0068
Epoch 6/100
198/198 - 0s - loss: 0.0062
Epoch 7/100
198/198 - 0s - loss: 0.0058
Epoch 8/100
198/198 - 0s - loss: 0.0059
Epoch 9/100
198/198 - 0s - loss: 0.0053
Epoch 10/100
198/198 - 0s - loss: 0.0053
Epoch 11/100
198/198 - 0s - loss: 0.0050
Epoch 12/100
198/198 - 0s - loss: 0.0055
Epoch 13/100
198/198 - 0s - loss: 0.0049
Epoch 14/100
198/198 - 0s - loss: 0.0050
Epoch 15/100
198/198 - 0s - loss: 0.0051
Epoch 16/100
198/198 - 0s - loss: 0.0049
Epoch 17/100
198/198 - 0s - loss: 0.0056
Epoch 18/100
198/198 - 0s - loss: 0.0053
Epoch 19/100
198/198 - 0s - loss: 0.0050
Epoch 20/100
198/198 - 0s - loss: 0.0052
Epoch 21/100
198/198 - 0s - loss: 0.0064
Epoch 22/100
198/198 - 0s - loss: 0.0049
Epoch 23/100
198/198 - 0s - loss: 0.0051
Epoch 24/100
198/198 - 0s - loss: 0.0052
Epoch 25/100
198/198 - 0s - loss: 0.0051
Epoch 26/100
198/198 - 0s - loss: 0.0049
Epoch 27/100
198/198 - 0s - loss: 0.0050
Epoch 28/100
198/198 - 0s - loss: 0.0050
Epoch 29/100
198/198 - 0s - loss: 0.0052
Epoch 30/100
198/198 - 0s - loss: 0.0049
Epoch 31/100
198/198 - 0s - loss: 0.0052
Epoch 32/100
198/198 - 0s - loss: 0.0053
Epoch 33/100
198/198 - 0s - loss: 0.0053
Epoch 34/100
198/198 - 0s - loss: 0.0048
Epoch 35/100
198/198 - 0s - loss: 0.0048
Epoch 36/100
198/198 - 0s - loss: 0.0049
Epoch 37/100
198/198 - 0s - loss: 0.0049
Epoch 38/100
198/198 - 0s - loss: 0.0050
Epoch 39/100
198/198 - 0s - loss: 0.0048
Epoch 40/100
198/198 - 0s - loss: 0.0051
Epoch 41/100
198/198 - 0s - loss: 0.0046
Epoch 42/100
198/198 - 0s - loss: 0.0049
Epoch 43/100
198/198 - 0s - loss: 0.0049
Epoch 44/100
198/198 - 0s - loss: 0.0053
Epoch 45/100
198/198 - 0s - loss: 0.0049
Epoch 46/100
198/198 - 0s - loss: 0.0047
Epoch 47/100
198/198 - 0s - loss: 0.0046
Epoch 48/100
198/198 - 0s - loss: 0.0048
Epoch 49/100
198/198 - 0s - loss: 0.0048
Epoch 50/100
198/198 - 0s - loss: 0.0044
Epoch 51/100
198/198 - 0s - loss: 0.0046
Epoch 52/100
198/198 - 0s - loss: 0.0048
Epoch 53/100
198/198 - 0s - loss: 0.0045
Epoch 54/100
198/198 - 0s - loss: 0.0049
Epoch 55/100
198/198 - 0s - loss: 0.0043
Epoch 56/100
198/198 - 0s - loss: 0.0054
Epoch 57/100
198/198 - 0s - loss: 0.0046
Epoch 58/100
198/198 - 0s - loss: 0.0045
Epoch 59/100
198/198 - 0s - loss: 0.0043
Epoch 60/100
198/198 - 0s - loss: 0.0049
Epoch 61/100
198/198 - 0s - loss: 0.0046
Epoch 62/100
198/198 - 0s - loss: 0.0048
Epoch 63/100
198/198 - 0s - loss: 0.0045
Epoch 64/100
198/198 - 0s - loss: 0.0049
Epoch 65/100
198/198 - 0s - loss: 0.0047
Epoch 66/100
198/198 - 0s - loss: 0.0047
Epoch 67/100
198/198 - 0s - loss: 0.0049
Epoch 68/100
198/198 - 0s - loss: 0.0045
Epoch 69/100
198/198 - 0s - loss: 0.0047
Epoch 70/100
198/198 - 0s - loss: 0.0045
Epoch 71/100
198/198 - 0s - loss: 0.0046
Epoch 72/100
198/198 - 0s - loss: 0.0045
Epoch 73/100
198/198 - 0s - loss: 0.0047
Epoch 74/100
198/198 - 0s - loss: 0.0044
Epoch 75/100
198/198 - 0s - loss: 0.0047
Epoch 76/100
198/198 - 0s - loss: 0.0045
Epoch 77/100
198/198 - 0s - loss: 0.0047
Epoch 78/100
198/198 - 0s - loss: 0.0044
Epoch 79/100
198/198 - 0s - loss: 0.0047
Epoch 80/100
198/198 - 0s - loss: 0.0044
Epoch 81/100
198/198 - 0s - loss: 0.0048
Epoch 82/100
198/198 - 0s - loss: 0.0047
Epoch 83/100
198/198 - 0s - loss: 0.0045
Epoch 84/100
198/198 - 0s - loss: 0.0043
Epoch 85/100
198/198 - 0s - loss: 0.0047
Epoch 86/100
198/198 - 0s - loss: 0.0044
Epoch 87/100
198/198 - 0s - loss: 0.0043
Epoch 88/100
198/198 - 0s - loss: 0.0048
Epoch 89/100
198/198 - 0s - loss: 0.0047
Epoch 90/100
198/198 - 0s - loss: 0.0043
Epoch 91/100
198/198 - 0s - loss: 0.0044
Epoch 92/100
198/198 - 0s - loss: 0.0044
Epoch 93/100
198/198 - 0s - loss: 0.0045
Epoch 94/100
198/198 - 0s - loss: 0.0045
Epoch 95/100
198/198 - 0s - loss: 0.0044
Epoch 96/100
198/198 - 0s - loss: 0.0045
Epoch 97/100
198/198 - 0s - loss: 0.0044
Epoch 98/100
198/198 - 0s - loss: 0.0042
Epoch 99/100
198/198 - 0s - loss: 0.0044
Epoch 100/100
198/198 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.068
Train RMSE: 0.147
key_word: stock price
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.470588  0.411765  0.352941
2021-07-25  0.411765  0.470588  0.470588  ...  0.352941  0.470588  0.411765
2021-08-01  0.352941  0.411765  0.470588  ...  0.411765  0.352941  0.470588
2021-08-08  0.411765  0.352941  0.411765  ...  0.411765  0.411765  0.352941
2021-08-15  0.000000  0.411765  0.352941  ...  0.411765  0.411765  0.411765

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_24 (SimpleRNN)    (None, 60)                4380      
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 61        
=================================================================
Total params: 4,441
Trainable params: 4,441
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 1s - loss: 0.0260
Epoch 2/100
198/198 - 0s - loss: 0.0092
Epoch 3/100
198/198 - 0s - loss: 0.0077
Epoch 4/100
198/198 - 0s - loss: 0.0071
Epoch 5/100
198/198 - 0s - loss: 0.0058
Epoch 6/100
198/198 - 0s - loss: 0.0064
Epoch 7/100
198/198 - 0s - loss: 0.0059
Epoch 8/100
198/198 - 0s - loss: 0.0057
Epoch 9/100
198/198 - 0s - loss: 0.0064
Epoch 10/100
198/198 - 0s - loss: 0.0062
Epoch 11/100
198/198 - 0s - loss: 0.0052
Epoch 12/100
198/198 - 0s - loss: 0.0051
Epoch 13/100
198/198 - 0s - loss: 0.0062
Epoch 14/100
198/198 - 0s - loss: 0.0057
Epoch 15/100
198/198 - 0s - loss: 0.0062
Epoch 16/100
198/198 - 0s - loss: 0.0052
Epoch 17/100
198/198 - 0s - loss: 0.0050
Epoch 18/100
198/198 - 0s - loss: 0.0062
Epoch 19/100
198/198 - 0s - loss: 0.0053
Epoch 20/100
198/198 - 0s - loss: 0.0054
Epoch 21/100
198/198 - 0s - loss: 0.0050
Epoch 22/100
198/198 - 0s - loss: 0.0054
Epoch 23/100
198/198 - 0s - loss: 0.0056
Epoch 24/100
198/198 - 0s - loss: 0.0056
Epoch 25/100
198/198 - 0s - loss: 0.0052
Epoch 26/100
198/198 - 0s - loss: 0.0049
Epoch 27/100
198/198 - 0s - loss: 0.0051
Epoch 28/100
198/198 - 0s - loss: 0.0051
Epoch 29/100
198/198 - 0s - loss: 0.0053
Epoch 30/100
198/198 - 0s - loss: 0.0051
Epoch 31/100
198/198 - 0s - loss: 0.0049
Epoch 32/100
198/198 - 0s - loss: 0.0052
Epoch 33/100
198/198 - 0s - loss: 0.0051
Epoch 34/100
198/198 - 0s - loss: 0.0054
Epoch 35/100
198/198 - 0s - loss: 0.0051
Epoch 36/100
198/198 - 0s - loss: 0.0050
Epoch 37/100
198/198 - 0s - loss: 0.0050
Epoch 38/100
198/198 - 0s - loss: 0.0053
Epoch 39/100
198/198 - 0s - loss: 0.0051
Epoch 40/100
198/198 - 0s - loss: 0.0051
Epoch 41/100
198/198 - 0s - loss: 0.0050
Epoch 42/100
198/198 - 0s - loss: 0.0047
Epoch 43/100
198/198 - 0s - loss: 0.0050
Epoch 44/100
198/198 - 0s - loss: 0.0051
Epoch 45/100
198/198 - 0s - loss: 0.0049
Epoch 46/100
198/198 - 0s - loss: 0.0052
Epoch 47/100
198/198 - 0s - loss: 0.0051
Epoch 48/100
198/198 - 0s - loss: 0.0048
Epoch 49/100
198/198 - 0s - loss: 0.0047
Epoch 50/100
198/198 - 0s - loss: 0.0048
Epoch 51/100
198/198 - 0s - loss: 0.0047
Epoch 52/100
198/198 - 0s - loss: 0.0048
Epoch 53/100
198/198 - 0s - loss: 0.0048
Epoch 54/100
198/198 - 0s - loss: 0.0047
Epoch 55/100
198/198 - 0s - loss: 0.0046
Epoch 56/100
198/198 - 0s - loss: 0.0045
Epoch 57/100
198/198 - 0s - loss: 0.0046
Epoch 58/100
198/198 - 0s - loss: 0.0045
Epoch 59/100
198/198 - 0s - loss: 0.0049
Epoch 60/100
198/198 - 0s - loss: 0.0046
Epoch 61/100
198/198 - 0s - loss: 0.0048
Epoch 62/100
198/198 - 0s - loss: 0.0048
Epoch 63/100
198/198 - 0s - loss: 0.0045
Epoch 64/100
198/198 - 0s - loss: 0.0042
Epoch 65/100
198/198 - 0s - loss: 0.0045
Epoch 66/100
198/198 - 0s - loss: 0.0046
Epoch 67/100
198/198 - 0s - loss: 0.0046
Epoch 68/100
198/198 - 0s - loss: 0.0044
Epoch 69/100
198/198 - 0s - loss: 0.0050
Epoch 70/100
198/198 - 0s - loss: 0.0046
Epoch 71/100
198/198 - 0s - loss: 0.0048
Epoch 72/100
198/198 - 0s - loss: 0.0046
Epoch 73/100
198/198 - 0s - loss: 0.0046
Epoch 74/100
198/198 - 0s - loss: 0.0046
Epoch 75/100
198/198 - 0s - loss: 0.0046
Epoch 76/100
198/198 - 0s - loss: 0.0044
Epoch 77/100
198/198 - 0s - loss: 0.0045
Epoch 78/100
198/198 - 0s - loss: 0.0046
Epoch 79/100
198/198 - 0s - loss: 0.0046
Epoch 80/100
198/198 - 0s - loss: 0.0047
Epoch 81/100
198/198 - 0s - loss: 0.0044
Epoch 82/100
198/198 - 0s - loss: 0.0046
Epoch 83/100
198/198 - 0s - loss: 0.0046
Epoch 84/100
198/198 - 0s - loss: 0.0045
Epoch 85/100
198/198 - 0s - loss: 0.0045
Epoch 86/100
198/198 - 0s - loss: 0.0046
Epoch 87/100
198/198 - 0s - loss: 0.0044
Epoch 88/100
198/198 - 0s - loss: 0.0046
Epoch 89/100
198/198 - 0s - loss: 0.0046
Epoch 90/100
198/198 - 0s - loss: 0.0044
Epoch 91/100
198/198 - 0s - loss: 0.0046
Epoch 92/100
198/198 - 0s - loss: 0.0047
Epoch 93/100
198/198 - 0s - loss: 0.0044
Epoch 94/100
198/198 - 0s - loss: 0.0045
Epoch 95/100
198/198 - 0s - loss: 0.0044
Epoch 96/100
198/198 - 0s - loss: 0.0044
Epoch 97/100
198/198 - 0s - loss: 0.0045
Epoch 98/100
198/198 - 0s - loss: 0.0043
Epoch 99/100
198/198 - 0s - loss: 0.0047
Epoch 100/100
198/198 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.063
Train RMSE: 0.143
key_word: stock price
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.235294  0.176471  0.294118
2021-07-25  0.411765  0.470588  0.470588  ...  0.588235  0.235294  0.176471
2021-08-01  0.352941  0.411765  0.470588  ...  0.294118  0.588235  0.235294
2021-08-08  0.411765  0.352941  0.411765  ...  0.470588  0.294118  0.588235
2021-08-15  0.000000  0.411765  0.352941  ...  0.235294  0.470588  0.294118

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_25 (SimpleRNN)    (None, 4)                 116       
_________________________________________________________________
dense_25 (Dense)             (None, 1)                 5         
=================================================================
Total params: 121
Trainable params: 121
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0526
Epoch 2/100
188/188 - 0s - loss: 0.0145
Epoch 3/100
188/188 - 0s - loss: 0.0129
Epoch 4/100
188/188 - 0s - loss: 0.0122
Epoch 5/100
188/188 - 0s - loss: 0.0108
Epoch 6/100
188/188 - 0s - loss: 0.0098
Epoch 7/100
188/188 - 0s - loss: 0.0090
Epoch 8/100
188/188 - 0s - loss: 0.0086
Epoch 9/100
188/188 - 0s - loss: 0.0079
Epoch 10/100
188/188 - 0s - loss: 0.0075
Epoch 11/100
188/188 - 0s - loss: 0.0072
Epoch 12/100
188/188 - 0s - loss: 0.0071
Epoch 13/100
188/188 - 0s - loss: 0.0064
Epoch 14/100
188/188 - 0s - loss: 0.0062
Epoch 15/100
188/188 - 0s - loss: 0.0062
Epoch 16/100
188/188 - 0s - loss: 0.0060
Epoch 17/100
188/188 - 0s - loss: 0.0060
Epoch 18/100
188/188 - 0s - loss: 0.0060
Epoch 19/100
188/188 - 0s - loss: 0.0057
Epoch 20/100
188/188 - 0s - loss: 0.0055
Epoch 21/100
188/188 - 0s - loss: 0.0054
Epoch 22/100
188/188 - 0s - loss: 0.0054
Epoch 23/100
188/188 - 0s - loss: 0.0054
Epoch 24/100
188/188 - 0s - loss: 0.0053
Epoch 25/100
188/188 - 0s - loss: 0.0053
Epoch 26/100
188/188 - 0s - loss: 0.0051
Epoch 27/100
188/188 - 0s - loss: 0.0051
Epoch 28/100
188/188 - 0s - loss: 0.0051
Epoch 29/100
188/188 - 0s - loss: 0.0051
Epoch 30/100
188/188 - 0s - loss: 0.0051
Epoch 31/100
188/188 - 0s - loss: 0.0050
Epoch 32/100
188/188 - 0s - loss: 0.0049
Epoch 33/100
188/188 - 0s - loss: 0.0051
Epoch 34/100
188/188 - 0s - loss: 0.0049
Epoch 35/100
188/188 - 0s - loss: 0.0048
Epoch 36/100
188/188 - 0s - loss: 0.0047
Epoch 37/100
188/188 - 0s - loss: 0.0050
Epoch 38/100
188/188 - 0s - loss: 0.0048
Epoch 39/100
188/188 - 0s - loss: 0.0047
Epoch 40/100
188/188 - 0s - loss: 0.0050
Epoch 41/100
188/188 - 0s - loss: 0.0048
Epoch 42/100
188/188 - 0s - loss: 0.0046
Epoch 43/100
188/188 - 0s - loss: 0.0046
Epoch 44/100
188/188 - 0s - loss: 0.0047
Epoch 45/100
188/188 - 0s - loss: 0.0047
Epoch 46/100
188/188 - 0s - loss: 0.0046
Epoch 47/100
188/188 - 0s - loss: 0.0045
Epoch 48/100
188/188 - 0s - loss: 0.0046
Epoch 49/100
188/188 - 0s - loss: 0.0046
Epoch 50/100
188/188 - 0s - loss: 0.0048
Epoch 51/100
188/188 - 0s - loss: 0.0044
Epoch 52/100
188/188 - 0s - loss: 0.0045
Epoch 53/100
188/188 - 0s - loss: 0.0046
Epoch 54/100
188/188 - 0s - loss: 0.0045
Epoch 55/100
188/188 - 0s - loss: 0.0046
Epoch 56/100
188/188 - 0s - loss: 0.0046
Epoch 57/100
188/188 - 0s - loss: 0.0046
Epoch 58/100
188/188 - 0s - loss: 0.0047
Epoch 59/100
188/188 - 0s - loss: 0.0046
Epoch 60/100
188/188 - 0s - loss: 0.0047
Epoch 61/100
188/188 - 0s - loss: 0.0046
Epoch 62/100
188/188 - 0s - loss: 0.0044
Epoch 63/100
188/188 - 0s - loss: 0.0046
Epoch 64/100
188/188 - 0s - loss: 0.0046
Epoch 65/100
188/188 - 0s - loss: 0.0044
Epoch 66/100
188/188 - 0s - loss: 0.0045
Epoch 67/100
188/188 - 0s - loss: 0.0044
Epoch 68/100
188/188 - 0s - loss: 0.0044
Epoch 69/100
188/188 - 0s - loss: 0.0044
Epoch 70/100
188/188 - 0s - loss: 0.0045
Epoch 71/100
188/188 - 0s - loss: 0.0045
Epoch 72/100
188/188 - 0s - loss: 0.0043
Epoch 73/100
188/188 - 0s - loss: 0.0045
Epoch 74/100
188/188 - 0s - loss: 0.0043
Epoch 75/100
188/188 - 0s - loss: 0.0043
Epoch 76/100
188/188 - 0s - loss: 0.0044
Epoch 77/100
188/188 - 0s - loss: 0.0044
Epoch 78/100
188/188 - 0s - loss: 0.0044
Epoch 79/100
188/188 - 0s - loss: 0.0045
Epoch 80/100
188/188 - 0s - loss: 0.0043
Epoch 81/100
188/188 - 0s - loss: 0.0047
Epoch 82/100
188/188 - 0s - loss: 0.0043
Epoch 83/100
188/188 - 0s - loss: 0.0044
Epoch 84/100
188/188 - 0s - loss: 0.0045
Epoch 85/100
188/188 - 0s - loss: 0.0043
Epoch 86/100
188/188 - 0s - loss: 0.0043
Epoch 87/100
188/188 - 0s - loss: 0.0042
Epoch 88/100
188/188 - 0s - loss: 0.0042
Epoch 89/100
188/188 - 0s - loss: 0.0043
Epoch 90/100
188/188 - 0s - loss: 0.0041
Epoch 91/100
188/188 - 0s - loss: 0.0045
Epoch 92/100
188/188 - 0s - loss: 0.0043
Epoch 93/100
188/188 - 0s - loss: 0.0044
Epoch 94/100
188/188 - 0s - loss: 0.0041
Epoch 95/100
188/188 - 0s - loss: 0.0043
Epoch 96/100
188/188 - 0s - loss: 0.0043
Epoch 97/100
188/188 - 0s - loss: 0.0043
Epoch 98/100
188/188 - 0s - loss: 0.0043
Epoch 99/100
188/188 - 0s - loss: 0.0041
Epoch 100/100
188/188 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.063
Train RMSE: 0.145
key_word: stock price
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.235294  0.176471  0.294118
2021-07-25  0.411765  0.470588  0.470588  ...  0.588235  0.235294  0.176471
2021-08-01  0.352941  0.411765  0.470588  ...  0.294118  0.588235  0.235294
2021-08-08  0.411765  0.352941  0.411765  ...  0.470588  0.294118  0.588235
2021-08-15  0.000000  0.411765  0.352941  ...  0.235294  0.470588  0.294118

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_26 (SimpleRNN)    (None, 8)                 264       
_________________________________________________________________
dense_26 (Dense)             (None, 1)                 9         
=================================================================
Total params: 273
Trainable params: 273
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0220
Epoch 2/100
188/188 - 0s - loss: 0.0137
Epoch 3/100
188/188 - 0s - loss: 0.0124
Epoch 4/100
188/188 - 0s - loss: 0.0108
Epoch 5/100
188/188 - 0s - loss: 0.0101
Epoch 6/100
188/188 - 0s - loss: 0.0091
Epoch 7/100
188/188 - 0s - loss: 0.0094
Epoch 8/100
188/188 - 0s - loss: 0.0079
Epoch 9/100
188/188 - 0s - loss: 0.0077
Epoch 10/100
188/188 - 0s - loss: 0.0079
Epoch 11/100
188/188 - 0s - loss: 0.0068
Epoch 12/100
188/188 - 0s - loss: 0.0068
Epoch 13/100
188/188 - 0s - loss: 0.0060
Epoch 14/100
188/188 - 0s - loss: 0.0061
Epoch 15/100
188/188 - 0s - loss: 0.0059
Epoch 16/100
188/188 - 0s - loss: 0.0061
Epoch 17/100
188/188 - 0s - loss: 0.0060
Epoch 18/100
188/188 - 0s - loss: 0.0062
Epoch 19/100
188/188 - 0s - loss: 0.0056
Epoch 20/100
188/188 - 0s - loss: 0.0052
Epoch 21/100
188/188 - 0s - loss: 0.0055
Epoch 22/100
188/188 - 0s - loss: 0.0055
Epoch 23/100
188/188 - 0s - loss: 0.0054
Epoch 24/100
188/188 - 0s - loss: 0.0054
Epoch 25/100
188/188 - 0s - loss: 0.0051
Epoch 26/100
188/188 - 0s - loss: 0.0050
Epoch 27/100
188/188 - 0s - loss: 0.0053
Epoch 28/100
188/188 - 0s - loss: 0.0049
Epoch 29/100
188/188 - 0s - loss: 0.0052
Epoch 30/100
188/188 - 0s - loss: 0.0051
Epoch 31/100
188/188 - 0s - loss: 0.0049
Epoch 32/100
188/188 - 0s - loss: 0.0051
Epoch 33/100
188/188 - 0s - loss: 0.0053
Epoch 34/100
188/188 - 0s - loss: 0.0048
Epoch 35/100
188/188 - 0s - loss: 0.0050
Epoch 36/100
188/188 - 0s - loss: 0.0051
Epoch 37/100
188/188 - 0s - loss: 0.0048
Epoch 38/100
188/188 - 0s - loss: 0.0049
Epoch 39/100
188/188 - 0s - loss: 0.0047
Epoch 40/100
188/188 - 0s - loss: 0.0045
Epoch 41/100
188/188 - 0s - loss: 0.0049
Epoch 42/100
188/188 - 0s - loss: 0.0046
Epoch 43/100
188/188 - 0s - loss: 0.0046
Epoch 44/100
188/188 - 0s - loss: 0.0049
Epoch 45/100
188/188 - 0s - loss: 0.0047
Epoch 46/100
188/188 - 0s - loss: 0.0052
Epoch 47/100
188/188 - 0s - loss: 0.0049
Epoch 48/100
188/188 - 0s - loss: 0.0045
Epoch 49/100
188/188 - 0s - loss: 0.0047
Epoch 50/100
188/188 - 0s - loss: 0.0047
Epoch 51/100
188/188 - 0s - loss: 0.0046
Epoch 52/100
188/188 - 0s - loss: 0.0048
Epoch 53/100
188/188 - 0s - loss: 0.0045
Epoch 54/100
188/188 - 0s - loss: 0.0046
Epoch 55/100
188/188 - 0s - loss: 0.0045
Epoch 56/100
188/188 - 0s - loss: 0.0049
Epoch 57/100
188/188 - 0s - loss: 0.0046
Epoch 58/100
188/188 - 0s - loss: 0.0044
Epoch 59/100
188/188 - 0s - loss: 0.0045
Epoch 60/100
188/188 - 0s - loss: 0.0047
Epoch 61/100
188/188 - 0s - loss: 0.0045
Epoch 62/100
188/188 - 0s - loss: 0.0046
Epoch 63/100
188/188 - 0s - loss: 0.0045
Epoch 64/100
188/188 - 0s - loss: 0.0046
Epoch 65/100
188/188 - 0s - loss: 0.0046
Epoch 66/100
188/188 - 0s - loss: 0.0049
Epoch 67/100
188/188 - 0s - loss: 0.0046
Epoch 68/100
188/188 - 0s - loss: 0.0044
Epoch 69/100
188/188 - 0s - loss: 0.0045
Epoch 70/100
188/188 - 0s - loss: 0.0044
Epoch 71/100
188/188 - 0s - loss: 0.0048
Epoch 72/100
188/188 - 0s - loss: 0.0047
Epoch 73/100
188/188 - 0s - loss: 0.0045
Epoch 74/100
188/188 - 0s - loss: 0.0045
Epoch 75/100
188/188 - 0s - loss: 0.0044
Epoch 76/100
188/188 - 0s - loss: 0.0046
Epoch 77/100
188/188 - 0s - loss: 0.0047
Epoch 78/100
188/188 - 0s - loss: 0.0045
Epoch 79/100
188/188 - 0s - loss: 0.0045
Epoch 80/100
188/188 - 0s - loss: 0.0044
Epoch 81/100
188/188 - 0s - loss: 0.0046
Epoch 82/100
188/188 - 0s - loss: 0.0045
Epoch 83/100
188/188 - 0s - loss: 0.0045
Epoch 84/100
188/188 - 0s - loss: 0.0044
Epoch 85/100
188/188 - 0s - loss: 0.0043
Epoch 86/100
188/188 - 0s - loss: 0.0045
Epoch 87/100
188/188 - 0s - loss: 0.0046
Epoch 88/100
188/188 - 0s - loss: 0.0045
Epoch 89/100
188/188 - 0s - loss: 0.0045
Epoch 90/100
188/188 - 0s - loss: 0.0044
Epoch 91/100
188/188 - 0s - loss: 0.0045
Epoch 92/100
188/188 - 0s - loss: 0.0048
Epoch 93/100
188/188 - 0s - loss: 0.0043
Epoch 94/100
188/188 - 0s - loss: 0.0044
Epoch 95/100
188/188 - 0s - loss: 0.0045
Epoch 96/100
188/188 - 0s - loss: 0.0045
Epoch 97/100
188/188 - 0s - loss: 0.0043
Epoch 98/100
188/188 - 0s - loss: 0.0045
Epoch 99/100
188/188 - 0s - loss: 0.0046
Epoch 100/100
188/188 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.144
key_word: stock price
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.235294  0.176471  0.294118
2021-07-25  0.411765  0.470588  0.470588  ...  0.588235  0.235294  0.176471
2021-08-01  0.352941  0.411765  0.470588  ...  0.294118  0.588235  0.235294
2021-08-08  0.411765  0.352941  0.411765  ...  0.470588  0.294118  0.588235
2021-08-15  0.000000  0.411765  0.352941  ...  0.235294  0.470588  0.294118

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_27 (SimpleRNN)    (None, 16)                656       
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 17        
=================================================================
Total params: 673
Trainable params: 673
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0179
Epoch 2/100
188/188 - 0s - loss: 0.0144
Epoch 3/100
188/188 - 0s - loss: 0.0117
Epoch 4/100
188/188 - 0s - loss: 0.0106
Epoch 5/100
188/188 - 0s - loss: 0.0092
Epoch 6/100
188/188 - 0s - loss: 0.0078
Epoch 7/100
188/188 - 0s - loss: 0.0071
Epoch 8/100
188/188 - 0s - loss: 0.0066
Epoch 9/100
188/188 - 0s - loss: 0.0070
Epoch 10/100
188/188 - 0s - loss: 0.0056
Epoch 11/100
188/188 - 0s - loss: 0.0052
Epoch 12/100
188/188 - 0s - loss: 0.0056
Epoch 13/100
188/188 - 0s - loss: 0.0052
Epoch 14/100
188/188 - 0s - loss: 0.0050
Epoch 15/100
188/188 - 0s - loss: 0.0052
Epoch 16/100
188/188 - 0s - loss: 0.0048
Epoch 17/100
188/188 - 0s - loss: 0.0047
Epoch 18/100
188/188 - 0s - loss: 0.0051
Epoch 19/100
188/188 - 0s - loss: 0.0051
Epoch 20/100
188/188 - 0s - loss: 0.0052
Epoch 21/100
188/188 - 0s - loss: 0.0049
Epoch 22/100
188/188 - 0s - loss: 0.0050
Epoch 23/100
188/188 - 0s - loss: 0.0048
Epoch 24/100
188/188 - 0s - loss: 0.0045
Epoch 25/100
188/188 - 0s - loss: 0.0051
Epoch 26/100
188/188 - 0s - loss: 0.0052
Epoch 27/100
188/188 - 0s - loss: 0.0050
Epoch 28/100
188/188 - 0s - loss: 0.0050
Epoch 29/100
188/188 - 0s - loss: 0.0051
Epoch 30/100
188/188 - 0s - loss: 0.0048
Epoch 31/100
188/188 - 0s - loss: 0.0046
Epoch 32/100
188/188 - 0s - loss: 0.0050
Epoch 33/100
188/188 - 0s - loss: 0.0047
Epoch 34/100
188/188 - 0s - loss: 0.0050
Epoch 35/100
188/188 - 0s - loss: 0.0047
Epoch 36/100
188/188 - 0s - loss: 0.0044
Epoch 37/100
188/188 - 0s - loss: 0.0050
Epoch 38/100
188/188 - 0s - loss: 0.0052
Epoch 39/100
188/188 - 0s - loss: 0.0051
Epoch 40/100
188/188 - 0s - loss: 0.0046
Epoch 41/100
188/188 - 0s - loss: 0.0044
Epoch 42/100
188/188 - 0s - loss: 0.0048
Epoch 43/100
188/188 - 0s - loss: 0.0048
Epoch 44/100
188/188 - 0s - loss: 0.0048
Epoch 45/100
188/188 - 0s - loss: 0.0046
Epoch 46/100
188/188 - 0s - loss: 0.0053
Epoch 47/100
188/188 - 0s - loss: 0.0045
Epoch 48/100
188/188 - 0s - loss: 0.0045
Epoch 49/100
188/188 - 0s - loss: 0.0046
Epoch 50/100
188/188 - 0s - loss: 0.0045
Epoch 51/100
188/188 - 0s - loss: 0.0044
Epoch 52/100
188/188 - 0s - loss: 0.0047
Epoch 53/100
188/188 - 0s - loss: 0.0051
Epoch 54/100
188/188 - 0s - loss: 0.0046
Epoch 55/100
188/188 - 0s - loss: 0.0044
Epoch 56/100
188/188 - 0s - loss: 0.0045
Epoch 57/100
188/188 - 0s - loss: 0.0046
Epoch 58/100
188/188 - 0s - loss: 0.0043
Epoch 59/100
188/188 - 0s - loss: 0.0044
Epoch 60/100
188/188 - 0s - loss: 0.0046
Epoch 61/100
188/188 - 0s - loss: 0.0045
Epoch 62/100
188/188 - 0s - loss: 0.0044
Epoch 63/100
188/188 - 0s - loss: 0.0046
Epoch 64/100
188/188 - 0s - loss: 0.0049
Epoch 65/100
188/188 - 0s - loss: 0.0047
Epoch 66/100
188/188 - 0s - loss: 0.0043
Epoch 67/100
188/188 - 0s - loss: 0.0045
Epoch 68/100
188/188 - 0s - loss: 0.0044
Epoch 69/100
188/188 - 0s - loss: 0.0045
Epoch 70/100
188/188 - 0s - loss: 0.0043
Epoch 71/100
188/188 - 0s - loss: 0.0048
Epoch 72/100
188/188 - 0s - loss: 0.0045
Epoch 73/100
188/188 - 0s - loss: 0.0046
Epoch 74/100
188/188 - 0s - loss: 0.0043
Epoch 75/100
188/188 - 0s - loss: 0.0047
Epoch 76/100
188/188 - 0s - loss: 0.0043
Epoch 77/100
188/188 - 0s - loss: 0.0045
Epoch 78/100
188/188 - 0s - loss: 0.0046
Epoch 79/100
188/188 - 0s - loss: 0.0043
Epoch 80/100
188/188 - 0s - loss: 0.0046
Epoch 81/100
188/188 - 0s - loss: 0.0045
Epoch 82/100
188/188 - 0s - loss: 0.0044
Epoch 83/100
188/188 - 0s - loss: 0.0045
Epoch 84/100
188/188 - 0s - loss: 0.0045
Epoch 85/100
188/188 - 0s - loss: 0.0045
Epoch 86/100
188/188 - 0s - loss: 0.0044
Epoch 87/100
188/188 - 0s - loss: 0.0048
Epoch 88/100
188/188 - 0s - loss: 0.0045
Epoch 89/100
188/188 - 0s - loss: 0.0049
Epoch 90/100
188/188 - 0s - loss: 0.0043
Epoch 91/100
188/188 - 0s - loss: 0.0046
Epoch 92/100
188/188 - 0s - loss: 0.0044
Epoch 93/100
188/188 - 0s - loss: 0.0047
Epoch 94/100
188/188 - 0s - loss: 0.0048
Epoch 95/100
188/188 - 0s - loss: 0.0044
Epoch 96/100
188/188 - 0s - loss: 0.0044
Epoch 97/100
188/188 - 0s - loss: 0.0042
Epoch 98/100
188/188 - 0s - loss: 0.0044
Epoch 99/100
188/188 - 0s - loss: 0.0044
Epoch 100/100
188/188 - 0s - loss: 0.0047

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.069
Train RMSE: 0.148
key_word: stock price
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.235294  0.176471  0.294118
2021-07-25  0.411765  0.470588  0.470588  ...  0.588235  0.235294  0.176471
2021-08-01  0.352941  0.411765  0.470588  ...  0.294118  0.588235  0.235294
2021-08-08  0.411765  0.352941  0.411765  ...  0.470588  0.294118  0.588235
2021-08-15  0.000000  0.411765  0.352941  ...  0.235294  0.470588  0.294118

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_28 (SimpleRNN)    (None, 32)                1824      
_________________________________________________________________
dense_28 (Dense)             (None, 1)                 33        
=================================================================
Total params: 1,857
Trainable params: 1,857
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0170
Epoch 2/100
188/188 - 0s - loss: 0.0091
Epoch 3/100
188/188 - 0s - loss: 0.0081
Epoch 4/100
188/188 - 0s - loss: 0.0079
Epoch 5/100
188/188 - 0s - loss: 0.0070
Epoch 6/100
188/188 - 0s - loss: 0.0069
Epoch 7/100
188/188 - 0s - loss: 0.0064
Epoch 8/100
188/188 - 0s - loss: 0.0055
Epoch 9/100
188/188 - 0s - loss: 0.0065
Epoch 10/100
188/188 - 0s - loss: 0.0057
Epoch 11/100
188/188 - 0s - loss: 0.0054
Epoch 12/100
188/188 - 0s - loss: 0.0053
Epoch 13/100
188/188 - 0s - loss: 0.0058
Epoch 14/100
188/188 - 0s - loss: 0.0055
Epoch 15/100
188/188 - 0s - loss: 0.0056
Epoch 16/100
188/188 - 0s - loss: 0.0057
Epoch 17/100
188/188 - 0s - loss: 0.0058
Epoch 18/100
188/188 - 0s - loss: 0.0052
Epoch 19/100
188/188 - 0s - loss: 0.0051
Epoch 20/100
188/188 - 0s - loss: 0.0056
Epoch 21/100
188/188 - 0s - loss: 0.0049
Epoch 22/100
188/188 - 0s - loss: 0.0053
Epoch 23/100
188/188 - 0s - loss: 0.0049
Epoch 24/100
188/188 - 0s - loss: 0.0053
Epoch 25/100
188/188 - 0s - loss: 0.0053
Epoch 26/100
188/188 - 0s - loss: 0.0048
Epoch 27/100
188/188 - 0s - loss: 0.0057
Epoch 28/100
188/188 - 0s - loss: 0.0054
Epoch 29/100
188/188 - 0s - loss: 0.0050
Epoch 30/100
188/188 - 0s - loss: 0.0064
Epoch 31/100
188/188 - 0s - loss: 0.0051
Epoch 32/100
188/188 - 0s - loss: 0.0050
Epoch 33/100
188/188 - 0s - loss: 0.0052
Epoch 34/100
188/188 - 0s - loss: 0.0053
Epoch 35/100
188/188 - 0s - loss: 0.0052
Epoch 36/100
188/188 - 0s - loss: 0.0054
Epoch 37/100
188/188 - 0s - loss: 0.0057
Epoch 38/100
188/188 - 0s - loss: 0.0045
Epoch 39/100
188/188 - 0s - loss: 0.0055
Epoch 40/100
188/188 - 0s - loss: 0.0047
Epoch 41/100
188/188 - 0s - loss: 0.0048
Epoch 42/100
188/188 - 0s - loss: 0.0052
Epoch 43/100
188/188 - 0s - loss: 0.0048
Epoch 44/100
188/188 - 0s - loss: 0.0049
Epoch 45/100
188/188 - 0s - loss: 0.0052
Epoch 46/100
188/188 - 0s - loss: 0.0050
Epoch 47/100
188/188 - 0s - loss: 0.0047
Epoch 48/100
188/188 - 0s - loss: 0.0051
Epoch 49/100
188/188 - 0s - loss: 0.0055
Epoch 50/100
188/188 - 0s - loss: 0.0050
Epoch 51/100
188/188 - 0s - loss: 0.0049
Epoch 52/100
188/188 - 0s - loss: 0.0049
Epoch 53/100
188/188 - 0s - loss: 0.0051
Epoch 54/100
188/188 - 0s - loss: 0.0045
Epoch 55/100
188/188 - 0s - loss: 0.0053
Epoch 56/100
188/188 - 0s - loss: 0.0055
Epoch 57/100
188/188 - 0s - loss: 0.0050
Epoch 58/100
188/188 - 0s - loss: 0.0046
Epoch 59/100
188/188 - 0s - loss: 0.0051
Epoch 60/100
188/188 - 0s - loss: 0.0054
Epoch 61/100
188/188 - 0s - loss: 0.0050
Epoch 62/100
188/188 - 0s - loss: 0.0047
Epoch 63/100
188/188 - 0s - loss: 0.0046
Epoch 64/100
188/188 - 0s - loss: 0.0046
Epoch 65/100
188/188 - 0s - loss: 0.0047
Epoch 66/100
188/188 - 0s - loss: 0.0047
Epoch 67/100
188/188 - 0s - loss: 0.0045
Epoch 68/100
188/188 - 0s - loss: 0.0050
Epoch 69/100
188/188 - 0s - loss: 0.0048
Epoch 70/100
188/188 - 0s - loss: 0.0047
Epoch 71/100
188/188 - 0s - loss: 0.0046
Epoch 72/100
188/188 - 0s - loss: 0.0048
Epoch 73/100
188/188 - 0s - loss: 0.0044
Epoch 74/100
188/188 - 0s - loss: 0.0045
Epoch 75/100
188/188 - 0s - loss: 0.0047
Epoch 76/100
188/188 - 0s - loss: 0.0048
Epoch 77/100
188/188 - 0s - loss: 0.0046
Epoch 78/100
188/188 - 0s - loss: 0.0049
Epoch 79/100
188/188 - 0s - loss: 0.0047
Epoch 80/100
188/188 - 0s - loss: 0.0046
Epoch 81/100
188/188 - 0s - loss: 0.0044
Epoch 82/100
188/188 - 0s - loss: 0.0045
Epoch 83/100
188/188 - 0s - loss: 0.0048
Epoch 84/100
188/188 - 0s - loss: 0.0047
Epoch 85/100
188/188 - 0s - loss: 0.0048
Epoch 86/100
188/188 - 0s - loss: 0.0044
Epoch 87/100
188/188 - 0s - loss: 0.0045
Epoch 88/100
188/188 - 0s - loss: 0.0046
Epoch 89/100
188/188 - 0s - loss: 0.0047
Epoch 90/100
188/188 - 0s - loss: 0.0047
Epoch 91/100
188/188 - 0s - loss: 0.0043
Epoch 92/100
188/188 - 0s - loss: 0.0042
Epoch 93/100
188/188 - 0s - loss: 0.0045
Epoch 94/100
188/188 - 0s - loss: 0.0046
Epoch 95/100
188/188 - 0s - loss: 0.0044
Epoch 96/100
188/188 - 0s - loss: 0.0043
Epoch 97/100
188/188 - 0s - loss: 0.0046
Epoch 98/100
188/188 - 0s - loss: 0.0047
Epoch 99/100
188/188 - 0s - loss: 0.0045
Epoch 100/100
188/188 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.063
Train RMSE: 0.148
key_word: stock price
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.470588  0.470588  0.352941  ...  0.235294  0.176471  0.294118
2021-07-25  0.411765  0.470588  0.470588  ...  0.588235  0.235294  0.176471
2021-08-01  0.352941  0.411765  0.470588  ...  0.294118  0.588235  0.235294
2021-08-08  0.411765  0.352941  0.411765  ...  0.470588  0.294118  0.588235
2021-08-15  0.000000  0.411765  0.352941  ...  0.235294  0.470588  0.294118

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_29 (SimpleRNN)    (None, 60)                5100      
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 61        
=================================================================
Total params: 5,161
Trainable params: 5,161
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 1s - loss: 0.0142
Epoch 2/100
188/188 - 0s - loss: 0.0098
Epoch 3/100
188/188 - 0s - loss: 0.0084
Epoch 4/100
188/188 - 0s - loss: 0.0073
Epoch 5/100
188/188 - 0s - loss: 0.0070
Epoch 6/100
188/188 - 0s - loss: 0.0090
Epoch 7/100
188/188 - 0s - loss: 0.0066
Epoch 8/100
188/188 - 0s - loss: 0.0060
Epoch 9/100
188/188 - 0s - loss: 0.0063
Epoch 10/100
188/188 - 0s - loss: 0.0073
Epoch 11/100
188/188 - 0s - loss: 0.0060
Epoch 12/100
188/188 - 0s - loss: 0.0060
Epoch 13/100
188/188 - 0s - loss: 0.0062
Epoch 14/100
188/188 - 0s - loss: 0.0062
Epoch 15/100
188/188 - 0s - loss: 0.0053
Epoch 16/100
188/188 - 0s - loss: 0.0062
Epoch 17/100
188/188 - 0s - loss: 0.0054
Epoch 18/100
188/188 - 0s - loss: 0.0063
Epoch 19/100
188/188 - 0s - loss: 0.0063
Epoch 20/100
188/188 - 0s - loss: 0.0056
Epoch 21/100
188/188 - 0s - loss: 0.0055
Epoch 22/100
188/188 - 0s - loss: 0.0056
Epoch 23/100
188/188 - 0s - loss: 0.0061
Epoch 24/100
188/188 - 0s - loss: 0.0052
Epoch 25/100
188/188 - 0s - loss: 0.0076
Epoch 26/100
188/188 - 0s - loss: 0.0066
Epoch 27/100
188/188 - 0s - loss: 0.0052
Epoch 28/100
188/188 - 0s - loss: 0.0069
Epoch 29/100
188/188 - 0s - loss: 0.0051
Epoch 30/100
188/188 - 0s - loss: 0.0061
Epoch 31/100
188/188 - 0s - loss: 0.0064
Epoch 32/100
188/188 - 0s - loss: 0.0054
Epoch 33/100
188/188 - 0s - loss: 0.0056
Epoch 34/100
188/188 - 0s - loss: 0.0053
Epoch 35/100
188/188 - 0s - loss: 0.0064
Epoch 36/100
188/188 - 0s - loss: 0.0054
Epoch 37/100
188/188 - 0s - loss: 0.0060
Epoch 38/100
188/188 - 0s - loss: 0.0051
Epoch 39/100
188/188 - 0s - loss: 0.0054
Epoch 40/100
188/188 - 0s - loss: 0.0059
Epoch 41/100
188/188 - 0s - loss: 0.0056
Epoch 42/100
188/188 - 0s - loss: 0.0053
Epoch 43/100
188/188 - 0s - loss: 0.0055
Epoch 44/100
188/188 - 0s - loss: 0.0053
Epoch 45/100
188/188 - 0s - loss: 0.0062
Epoch 46/100
188/188 - 0s - loss: 0.0055
Epoch 47/100
188/188 - 0s - loss: 0.0053
Epoch 48/100
188/188 - 0s - loss: 0.0053
Epoch 49/100
188/188 - 0s - loss: 0.0047
Epoch 50/100
188/188 - 0s - loss: 0.0061
Epoch 51/100
188/188 - 0s - loss: 0.0051
Epoch 52/100
188/188 - 0s - loss: 0.0047
Epoch 53/100
188/188 - 0s - loss: 0.0056
Epoch 54/100
188/188 - 0s - loss: 0.0051
Epoch 55/100
188/188 - 0s - loss: 0.0050
Epoch 56/100
188/188 - 0s - loss: 0.0063
Epoch 57/100
188/188 - 0s - loss: 0.0054
Epoch 58/100
188/188 - 0s - loss: 0.0052
Epoch 59/100
188/188 - 0s - loss: 0.0049
Epoch 60/100
188/188 - 0s - loss: 0.0050
Epoch 61/100
188/188 - 0s - loss: 0.0047
Epoch 62/100
188/188 - 0s - loss: 0.0048
Epoch 63/100
188/188 - 0s - loss: 0.0051
Epoch 64/100
188/188 - 0s - loss: 0.0053
Epoch 65/100
188/188 - 0s - loss: 0.0051
Epoch 66/100
188/188 - 0s - loss: 0.0050
Epoch 67/100
188/188 - 0s - loss: 0.0044
Epoch 68/100
188/188 - 0s - loss: 0.0047
Epoch 69/100
188/188 - 0s - loss: 0.0050
Epoch 70/100
188/188 - 0s - loss: 0.0048
Epoch 71/100
188/188 - 0s - loss: 0.0045
Epoch 72/100
188/188 - 0s - loss: 0.0048
Epoch 73/100
188/188 - 0s - loss: 0.0048
Epoch 74/100
188/188 - 0s - loss: 0.0049
Epoch 75/100
188/188 - 0s - loss: 0.0048
Epoch 76/100
188/188 - 0s - loss: 0.0051
Epoch 77/100
188/188 - 0s - loss: 0.0049
Epoch 78/100
188/188 - 0s - loss: 0.0047
Epoch 79/100
188/188 - 0s - loss: 0.0049
Epoch 80/100
188/188 - 0s - loss: 0.0044
Epoch 81/100
188/188 - 0s - loss: 0.0047
Epoch 82/100
188/188 - 0s - loss: 0.0049
Epoch 83/100
188/188 - 0s - loss: 0.0049
Epoch 84/100
188/188 - 0s - loss: 0.0049
Epoch 85/100
188/188 - 0s - loss: 0.0048
Epoch 86/100
188/188 - 0s - loss: 0.0046
Epoch 87/100
188/188 - 0s - loss: 0.0048
Epoch 88/100
188/188 - 0s - loss: 0.0055
Epoch 89/100
188/188 - 0s - loss: 0.0046
Epoch 90/100
188/188 - 0s - loss: 0.0048
Epoch 91/100
188/188 - 0s - loss: 0.0047
Epoch 92/100
188/188 - 0s - loss: 0.0046
Epoch 93/100
188/188 - 0s - loss: 0.0046
Epoch 94/100
188/188 - 0s - loss: 0.0046
Epoch 95/100
188/188 - 0s - loss: 0.0048
Epoch 96/100
188/188 - 0s - loss: 0.0046
Epoch 97/100
188/188 - 0s - loss: 0.0047
Epoch 98/100
188/188 - 0s - loss: 0.0047
Epoch 99/100
188/188 - 0s - loss: 0.0048
Epoch 100/100
188/188 - 0s - loss: 0.0047

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.066
Train RMSE: 0.148
key_word: stock price
window size: 24
N neurons: 60
