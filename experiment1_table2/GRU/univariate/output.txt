
 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.626667  0.453333  0.320000
2021-07-25  0.560000  0.560000  0.480000  ...  0.920000  0.626667  0.453333
2021-08-01  0.426667  0.560000  0.560000  ...  0.280000  0.920000  0.626667
2021-08-08  0.573333  0.426667  0.560000  ...  0.266667  0.280000  0.920000
2021-08-15  0.453333  0.573333  0.426667  ...  0.520000  0.266667  0.280000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 4)                 216       
_________________________________________________________________
dense (Dense)                (None, 1)                 5         
=================================================================
Total params: 221
Trainable params: 221
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0104
Epoch 2/100
198/198 - 0s - loss: 0.0067
Epoch 3/100
198/198 - 0s - loss: 0.0065
Epoch 4/100
198/198 - 0s - loss: 0.0062
Epoch 5/100
198/198 - 0s - loss: 0.0060
Epoch 6/100
198/198 - 0s - loss: 0.0060
Epoch 7/100
198/198 - 0s - loss: 0.0056
Epoch 8/100
198/198 - 0s - loss: 0.0057
Epoch 9/100
198/198 - 0s - loss: 0.0057
Epoch 10/100
198/198 - 0s - loss: 0.0054
Epoch 11/100
198/198 - 0s - loss: 0.0055
Epoch 12/100
198/198 - 0s - loss: 0.0053
Epoch 13/100
198/198 - 0s - loss: 0.0053
Epoch 14/100
198/198 - 0s - loss: 0.0051
Epoch 15/100
198/198 - 0s - loss: 0.0052
Epoch 16/100
198/198 - 0s - loss: 0.0053
Epoch 17/100
198/198 - 0s - loss: 0.0052
Epoch 18/100
198/198 - 0s - loss: 0.0050
Epoch 19/100
198/198 - 0s - loss: 0.0050
Epoch 20/100
198/198 - 0s - loss: 0.0053
Epoch 21/100
198/198 - 0s - loss: 0.0051
Epoch 22/100
198/198 - 0s - loss: 0.0052
Epoch 23/100
198/198 - 0s - loss: 0.0051
Epoch 24/100
198/198 - 0s - loss: 0.0050
Epoch 25/100
198/198 - 0s - loss: 0.0050
Epoch 26/100
198/198 - 0s - loss: 0.0049
Epoch 27/100
198/198 - 0s - loss: 0.0049
Epoch 28/100
198/198 - 0s - loss: 0.0049
Epoch 29/100
198/198 - 0s - loss: 0.0051
Epoch 30/100
198/198 - 0s - loss: 0.0048
Epoch 31/100
198/198 - 0s - loss: 0.0050
Epoch 32/100
198/198 - 0s - loss: 0.0048
Epoch 33/100
198/198 - 0s - loss: 0.0050
Epoch 34/100
198/198 - 0s - loss: 0.0048
Epoch 35/100
198/198 - 0s - loss: 0.0050
Epoch 36/100
198/198 - 0s - loss: 0.0050
Epoch 37/100
198/198 - 0s - loss: 0.0050
Epoch 38/100
198/198 - 0s - loss: 0.0047
Epoch 39/100
198/198 - 0s - loss: 0.0050
Epoch 40/100
198/198 - 0s - loss: 0.0048
Epoch 41/100
198/198 - 0s - loss: 0.0047
Epoch 42/100
198/198 - 0s - loss: 0.0048
Epoch 43/100
198/198 - 0s - loss: 0.0050
Epoch 44/100
198/198 - 0s - loss: 0.0046
Epoch 45/100
198/198 - 0s - loss: 0.0047
Epoch 46/100
198/198 - 0s - loss: 0.0052
Epoch 47/100
198/198 - 0s - loss: 0.0049
Epoch 48/100
198/198 - 0s - loss: 0.0048
Epoch 49/100
198/198 - 0s - loss: 0.0047
Epoch 50/100
198/198 - 0s - loss: 0.0047
Epoch 51/100
198/198 - 0s - loss: 0.0047
Epoch 52/100
198/198 - 0s - loss: 0.0047
Epoch 53/100
198/198 - 0s - loss: 0.0048
Epoch 54/100
198/198 - 0s - loss: 0.0048
Epoch 55/100
198/198 - 0s - loss: 0.0047
Epoch 56/100
198/198 - 0s - loss: 0.0046
Epoch 57/100
198/198 - 0s - loss: 0.0048
Epoch 58/100
198/198 - 0s - loss: 0.0047
Epoch 59/100
198/198 - 0s - loss: 0.0047
Epoch 60/100
198/198 - 0s - loss: 0.0048
Epoch 61/100
198/198 - 0s - loss: 0.0047
Epoch 62/100
198/198 - 0s - loss: 0.0046
Epoch 63/100
198/198 - 0s - loss: 0.0048
Epoch 64/100
198/198 - 0s - loss: 0.0047
Epoch 65/100
198/198 - 0s - loss: 0.0046
Epoch 66/100
198/198 - 0s - loss: 0.0048
Epoch 67/100
198/198 - 0s - loss: 0.0046
Epoch 68/100
198/198 - 0s - loss: 0.0047
Epoch 69/100
198/198 - 0s - loss: 0.0047
Epoch 70/100
198/198 - 0s - loss: 0.0047
Epoch 71/100
198/198 - 0s - loss: 0.0046
Epoch 72/100
198/198 - 0s - loss: 0.0047
Epoch 73/100
198/198 - 0s - loss: 0.0047
Epoch 74/100
198/198 - 0s - loss: 0.0045
Epoch 75/100
198/198 - 0s - loss: 0.0047
Epoch 76/100
198/198 - 0s - loss: 0.0046
Epoch 77/100
198/198 - 0s - loss: 0.0046
Epoch 78/100
198/198 - 0s - loss: 0.0046
Epoch 79/100
198/198 - 0s - loss: 0.0046
Epoch 80/100
198/198 - 0s - loss: 0.0047
Epoch 81/100
198/198 - 0s - loss: 0.0047
Epoch 82/100
198/198 - 0s - loss: 0.0045
Epoch 83/100
198/198 - 0s - loss: 0.0046
Epoch 84/100
198/198 - 0s - loss: 0.0046
Epoch 85/100
198/198 - 0s - loss: 0.0044
Epoch 86/100
198/198 - 0s - loss: 0.0045
Epoch 87/100
198/198 - 0s - loss: 0.0045
Epoch 88/100
198/198 - 0s - loss: 0.0046
Epoch 89/100
198/198 - 0s - loss: 0.0046
Epoch 90/100
198/198 - 0s - loss: 0.0045
Epoch 91/100
198/198 - 0s - loss: 0.0046
Epoch 92/100
198/198 - 0s - loss: 0.0045
Epoch 93/100
198/198 - 0s - loss: 0.0048
Epoch 94/100
198/198 - 0s - loss: 0.0046
Epoch 95/100
198/198 - 0s - loss: 0.0046
Epoch 96/100
198/198 - 0s - loss: 0.0045
Epoch 97/100
198/198 - 0s - loss: 0.0045
Epoch 98/100
198/198 - 0s - loss: 0.0045
Epoch 99/100
198/198 - 0s - loss: 0.0044
Epoch 100/100
198/198 - 0s - loss: 0.0046

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.065
Train RMSE: 0.142
key_word: bitcoin
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.626667  0.453333  0.320000
2021-07-25  0.560000  0.560000  0.480000  ...  0.920000  0.626667  0.453333
2021-08-01  0.426667  0.560000  0.560000  ...  0.280000  0.920000  0.626667
2021-08-08  0.573333  0.426667  0.560000  ...  0.266667  0.280000  0.920000
2021-08-15  0.453333  0.573333  0.426667  ...  0.520000  0.266667  0.280000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 8)                 528       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 9         
=================================================================
Total params: 537
Trainable params: 537
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0975
Epoch 2/100
198/198 - 0s - loss: 0.0072
Epoch 3/100
198/198 - 0s - loss: 0.0069
Epoch 4/100
198/198 - 0s - loss: 0.0068
Epoch 5/100
198/198 - 0s - loss: 0.0065
Epoch 6/100
198/198 - 0s - loss: 0.0065
Epoch 7/100
198/198 - 0s - loss: 0.0062
Epoch 8/100
198/198 - 0s - loss: 0.0058
Epoch 9/100
198/198 - 0s - loss: 0.0058
Epoch 10/100
198/198 - 0s - loss: 0.0058
Epoch 11/100
198/198 - 0s - loss: 0.0056
Epoch 12/100
198/198 - 0s - loss: 0.0058
Epoch 13/100
198/198 - 0s - loss: 0.0055
Epoch 14/100
198/198 - 0s - loss: 0.0054
Epoch 15/100
198/198 - 0s - loss: 0.0054
Epoch 16/100
198/198 - 0s - loss: 0.0052
Epoch 17/100
198/198 - 0s - loss: 0.0057
Epoch 18/100
198/198 - 0s - loss: 0.0054
Epoch 19/100
198/198 - 0s - loss: 0.0048
Epoch 20/100
198/198 - 0s - loss: 0.0051
Epoch 21/100
198/198 - 0s - loss: 0.0052
Epoch 22/100
198/198 - 0s - loss: 0.0052
Epoch 23/100
198/198 - 0s - loss: 0.0051
Epoch 24/100
198/198 - 0s - loss: 0.0052
Epoch 25/100
198/198 - 0s - loss: 0.0053
Epoch 26/100
198/198 - 0s - loss: 0.0049
Epoch 27/100
198/198 - 0s - loss: 0.0048
Epoch 28/100
198/198 - 0s - loss: 0.0051
Epoch 29/100
198/198 - 0s - loss: 0.0048
Epoch 30/100
198/198 - 0s - loss: 0.0050
Epoch 31/100
198/198 - 0s - loss: 0.0050
Epoch 32/100
198/198 - 0s - loss: 0.0050
Epoch 33/100
198/198 - 0s - loss: 0.0046
Epoch 34/100
198/198 - 0s - loss: 0.0047
Epoch 35/100
198/198 - 0s - loss: 0.0052
Epoch 36/100
198/198 - 0s - loss: 0.0049
Epoch 37/100
198/198 - 0s - loss: 0.0045
Epoch 38/100
198/198 - 0s - loss: 0.0049
Epoch 39/100
198/198 - 0s - loss: 0.0049
Epoch 40/100
198/198 - 0s - loss: 0.0049
Epoch 41/100
198/198 - 0s - loss: 0.0048
Epoch 42/100
198/198 - 0s - loss: 0.0049
Epoch 43/100
198/198 - 0s - loss: 0.0051
Epoch 44/100
198/198 - 0s - loss: 0.0048
Epoch 45/100
198/198 - 0s - loss: 0.0044
Epoch 46/100
198/198 - 0s - loss: 0.0046
Epoch 47/100
198/198 - 0s - loss: 0.0047
Epoch 48/100
198/198 - 0s - loss: 0.0047
Epoch 49/100
198/198 - 0s - loss: 0.0046
Epoch 50/100
198/198 - 0s - loss: 0.0047
Epoch 51/100
198/198 - 0s - loss: 0.0048
Epoch 52/100
198/198 - 0s - loss: 0.0046
Epoch 53/100
198/198 - 0s - loss: 0.0046
Epoch 54/100
198/198 - 0s - loss: 0.0047
Epoch 55/100
198/198 - 0s - loss: 0.0046
Epoch 56/100
198/198 - 0s - loss: 0.0048
Epoch 57/100
198/198 - 0s - loss: 0.0048
Epoch 58/100
198/198 - 0s - loss: 0.0047
Epoch 59/100
198/198 - 0s - loss: 0.0047
Epoch 60/100
198/198 - 0s - loss: 0.0047
Epoch 61/100
198/198 - 0s - loss: 0.0047
Epoch 62/100
198/198 - 0s - loss: 0.0045
Epoch 63/100
198/198 - 0s - loss: 0.0044
Epoch 64/100
198/198 - 0s - loss: 0.0044
Epoch 65/100
198/198 - 0s - loss: 0.0047
Epoch 66/100
198/198 - 0s - loss: 0.0045
Epoch 67/100
198/198 - 0s - loss: 0.0045
Epoch 68/100
198/198 - 0s - loss: 0.0045
Epoch 69/100
198/198 - 0s - loss: 0.0044
Epoch 70/100
198/198 - 0s - loss: 0.0046
Epoch 71/100
198/198 - 0s - loss: 0.0046
Epoch 72/100
198/198 - 0s - loss: 0.0045
Epoch 73/100
198/198 - 0s - loss: 0.0043
Epoch 74/100
198/198 - 0s - loss: 0.0047
Epoch 75/100
198/198 - 0s - loss: 0.0046
Epoch 76/100
198/198 - 0s - loss: 0.0042
Epoch 77/100
198/198 - 0s - loss: 0.0043
Epoch 78/100
198/198 - 0s - loss: 0.0044
Epoch 79/100
198/198 - 0s - loss: 0.0043
Epoch 80/100
198/198 - 0s - loss: 0.0044
Epoch 81/100
198/198 - 0s - loss: 0.0046
Epoch 82/100
198/198 - 0s - loss: 0.0044
Epoch 83/100
198/198 - 0s - loss: 0.0042
Epoch 84/100
198/198 - 0s - loss: 0.0043
Epoch 85/100
198/198 - 0s - loss: 0.0045
Epoch 86/100
198/198 - 0s - loss: 0.0041
Epoch 87/100
198/198 - 0s - loss: 0.0042
Epoch 88/100
198/198 - 0s - loss: 0.0041
Epoch 89/100
198/198 - 0s - loss: 0.0041
Epoch 90/100
198/198 - 0s - loss: 0.0044
Epoch 91/100
198/198 - 0s - loss: 0.0045
Epoch 92/100
198/198 - 0s - loss: 0.0042
Epoch 93/100
198/198 - 0s - loss: 0.0042
Epoch 94/100
198/198 - 0s - loss: 0.0043
Epoch 95/100
198/198 - 0s - loss: 0.0042
Epoch 96/100
198/198 - 0s - loss: 0.0042
Epoch 97/100
198/198 - 0s - loss: 0.0041
Epoch 98/100
198/198 - 0s - loss: 0.0039
Epoch 99/100
198/198 - 0s - loss: 0.0045
Epoch 100/100
198/198 - 0s - loss: 0.0042

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.061
Train RMSE: 0.145
key_word: bitcoin
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.626667  0.453333  0.320000
2021-07-25  0.560000  0.560000  0.480000  ...  0.920000  0.626667  0.453333
2021-08-01  0.426667  0.560000  0.560000  ...  0.280000  0.920000  0.626667
2021-08-08  0.573333  0.426667  0.560000  ...  0.266667  0.280000  0.920000
2021-08-15  0.453333  0.573333  0.426667  ...  0.520000  0.266667  0.280000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_2 (GRU)                  (None, 16)                1440      
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 17        
=================================================================
Total params: 1,457
Trainable params: 1,457
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0214
Epoch 2/100
198/198 - 0s - loss: 0.0065
Epoch 3/100
198/198 - 0s - loss: 0.0066
Epoch 4/100
198/198 - 0s - loss: 0.0066
Epoch 5/100
198/198 - 0s - loss: 0.0063
Epoch 6/100
198/198 - 0s - loss: 0.0060
Epoch 7/100
198/198 - 0s - loss: 0.0059
Epoch 8/100
198/198 - 0s - loss: 0.0060
Epoch 9/100
198/198 - 0s - loss: 0.0056
Epoch 10/100
198/198 - 0s - loss: 0.0055
Epoch 11/100
198/198 - 0s - loss: 0.0056
Epoch 12/100
198/198 - 0s - loss: 0.0056
Epoch 13/100
198/198 - 0s - loss: 0.0053
Epoch 14/100
198/198 - 0s - loss: 0.0052
Epoch 15/100
198/198 - 0s - loss: 0.0058
Epoch 16/100
198/198 - 0s - loss: 0.0054
Epoch 17/100
198/198 - 0s - loss: 0.0054
Epoch 18/100
198/198 - 0s - loss: 0.0052
Epoch 19/100
198/198 - 0s - loss: 0.0053
Epoch 20/100
198/198 - 0s - loss: 0.0051
Epoch 21/100
198/198 - 0s - loss: 0.0048
Epoch 22/100
198/198 - 0s - loss: 0.0055
Epoch 23/100
198/198 - 0s - loss: 0.0050
Epoch 24/100
198/198 - 0s - loss: 0.0052
Epoch 25/100
198/198 - 0s - loss: 0.0052
Epoch 26/100
198/198 - 0s - loss: 0.0050
Epoch 27/100
198/198 - 0s - loss: 0.0052
Epoch 28/100
198/198 - 0s - loss: 0.0050
Epoch 29/100
198/198 - 0s - loss: 0.0050
Epoch 30/100
198/198 - 0s - loss: 0.0050
Epoch 31/100
198/198 - 0s - loss: 0.0048
Epoch 32/100
198/198 - 0s - loss: 0.0050
Epoch 33/100
198/198 - 0s - loss: 0.0049
Epoch 34/100
198/198 - 0s - loss: 0.0048
Epoch 35/100
198/198 - 0s - loss: 0.0052
Epoch 36/100
198/198 - 0s - loss: 0.0049
Epoch 37/100
198/198 - 0s - loss: 0.0049
Epoch 38/100
198/198 - 0s - loss: 0.0051
Epoch 39/100
198/198 - 0s - loss: 0.0051
Epoch 40/100
198/198 - 0s - loss: 0.0051
Epoch 41/100
198/198 - 0s - loss: 0.0050
Epoch 42/100
198/198 - 0s - loss: 0.0050
Epoch 43/100
198/198 - 0s - loss: 0.0051
Epoch 44/100
198/198 - 0s - loss: 0.0050
Epoch 45/100
198/198 - 0s - loss: 0.0047
Epoch 46/100
198/198 - 0s - loss: 0.0048
Epoch 47/100
198/198 - 0s - loss: 0.0047
Epoch 48/100
198/198 - 0s - loss: 0.0048
Epoch 49/100
198/198 - 0s - loss: 0.0049
Epoch 50/100
198/198 - 0s - loss: 0.0046
Epoch 51/100
198/198 - 0s - loss: 0.0050
Epoch 52/100
198/198 - 0s - loss: 0.0047
Epoch 53/100
198/198 - 0s - loss: 0.0046
Epoch 54/100
198/198 - 0s - loss: 0.0047
Epoch 55/100
198/198 - 0s - loss: 0.0045
Epoch 56/100
198/198 - 0s - loss: 0.0047
Epoch 57/100
198/198 - 0s - loss: 0.0044
Epoch 58/100
198/198 - 0s - loss: 0.0048
Epoch 59/100
198/198 - 0s - loss: 0.0048
Epoch 60/100
198/198 - 0s - loss: 0.0049
Epoch 61/100
198/198 - 0s - loss: 0.0046
Epoch 62/100
198/198 - 0s - loss: 0.0048
Epoch 63/100
198/198 - 0s - loss: 0.0047
Epoch 64/100
198/198 - 0s - loss: 0.0048
Epoch 65/100
198/198 - 0s - loss: 0.0045
Epoch 66/100
198/198 - 0s - loss: 0.0048
Epoch 67/100
198/198 - 0s - loss: 0.0047
Epoch 68/100
198/198 - 0s - loss: 0.0046
Epoch 69/100
198/198 - 0s - loss: 0.0046
Epoch 70/100
198/198 - 0s - loss: 0.0045
Epoch 71/100
198/198 - 0s - loss: 0.0046
Epoch 72/100
198/198 - 0s - loss: 0.0046
Epoch 73/100
198/198 - 0s - loss: 0.0045
Epoch 74/100
198/198 - 0s - loss: 0.0046
Epoch 75/100
198/198 - 0s - loss: 0.0046
Epoch 76/100
198/198 - 0s - loss: 0.0044
Epoch 77/100
198/198 - 0s - loss: 0.0046
Epoch 78/100
198/198 - 0s - loss: 0.0045
Epoch 79/100
198/198 - 0s - loss: 0.0046
Epoch 80/100
198/198 - 0s - loss: 0.0044
Epoch 81/100
198/198 - 0s - loss: 0.0043
Epoch 82/100
198/198 - 0s - loss: 0.0045
Epoch 83/100
198/198 - 0s - loss: 0.0045
Epoch 84/100
198/198 - 0s - loss: 0.0047
Epoch 85/100
198/198 - 0s - loss: 0.0046
Epoch 86/100
198/198 - 0s - loss: 0.0046
Epoch 87/100
198/198 - 0s - loss: 0.0044
Epoch 88/100
198/198 - 0s - loss: 0.0045
Epoch 89/100
198/198 - 0s - loss: 0.0045
Epoch 90/100
198/198 - 0s - loss: 0.0044
Epoch 91/100
198/198 - 0s - loss: 0.0046
Epoch 92/100
198/198 - 0s - loss: 0.0045
Epoch 93/100
198/198 - 0s - loss: 0.0045
Epoch 94/100
198/198 - 0s - loss: 0.0047
Epoch 95/100
198/198 - 0s - loss: 0.0044
Epoch 96/100
198/198 - 0s - loss: 0.0044
Epoch 97/100
198/198 - 0s - loss: 0.0043
Epoch 98/100
198/198 - 0s - loss: 0.0044
Epoch 99/100
198/198 - 0s - loss: 0.0044
Epoch 100/100
198/198 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.072
Train RMSE: 0.146
key_word: bitcoin
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.626667  0.453333  0.320000
2021-07-25  0.560000  0.560000  0.480000  ...  0.920000  0.626667  0.453333
2021-08-01  0.426667  0.560000  0.560000  ...  0.280000  0.920000  0.626667
2021-08-08  0.573333  0.426667  0.560000  ...  0.266667  0.280000  0.920000
2021-08-15  0.453333  0.573333  0.426667  ...  0.520000  0.266667  0.280000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_3 (GRU)                  (None, 32)                4416      
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 33        
=================================================================
Total params: 4,449
Trainable params: 4,449
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0116
Epoch 2/100
198/198 - 0s - loss: 0.0075
Epoch 3/100
198/198 - 0s - loss: 0.0076
Epoch 4/100
198/198 - 0s - loss: 0.0073
Epoch 5/100
198/198 - 0s - loss: 0.0068
Epoch 6/100
198/198 - 0s - loss: 0.0066
Epoch 7/100
198/198 - 0s - loss: 0.0063
Epoch 8/100
198/198 - 0s - loss: 0.0066
Epoch 9/100
198/198 - 0s - loss: 0.0058
Epoch 10/100
198/198 - 0s - loss: 0.0060
Epoch 11/100
198/198 - 0s - loss: 0.0060
Epoch 12/100
198/198 - 0s - loss: 0.0058
Epoch 13/100
198/198 - 0s - loss: 0.0058
Epoch 14/100
198/198 - 0s - loss: 0.0053
Epoch 15/100
198/198 - 0s - loss: 0.0059
Epoch 16/100
198/198 - 0s - loss: 0.0055
Epoch 17/100
198/198 - 0s - loss: 0.0055
Epoch 18/100
198/198 - 0s - loss: 0.0053
Epoch 19/100
198/198 - 0s - loss: 0.0054
Epoch 20/100
198/198 - 0s - loss: 0.0054
Epoch 21/100
198/198 - 0s - loss: 0.0051
Epoch 22/100
198/198 - 0s - loss: 0.0057
Epoch 23/100
198/198 - 0s - loss: 0.0055
Epoch 24/100
198/198 - 0s - loss: 0.0050
Epoch 25/100
198/198 - 0s - loss: 0.0049
Epoch 26/100
198/198 - 0s - loss: 0.0057
Epoch 27/100
198/198 - 0s - loss: 0.0049
Epoch 28/100
198/198 - 0s - loss: 0.0052
Epoch 29/100
198/198 - 0s - loss: 0.0052
Epoch 30/100
198/198 - 0s - loss: 0.0051
Epoch 31/100
198/198 - 0s - loss: 0.0052
Epoch 32/100
198/198 - 0s - loss: 0.0048
Epoch 33/100
198/198 - 0s - loss: 0.0056
Epoch 34/100
198/198 - 0s - loss: 0.0049
Epoch 35/100
198/198 - 0s - loss: 0.0048
Epoch 36/100
198/198 - 0s - loss: 0.0051
Epoch 37/100
198/198 - 0s - loss: 0.0050
Epoch 38/100
198/198 - 0s - loss: 0.0051
Epoch 39/100
198/198 - 0s - loss: 0.0053
Epoch 40/100
198/198 - 0s - loss: 0.0048
Epoch 41/100
198/198 - 0s - loss: 0.0049
Epoch 42/100
198/198 - 0s - loss: 0.0048
Epoch 43/100
198/198 - 0s - loss: 0.0051
Epoch 44/100
198/198 - 0s - loss: 0.0051
Epoch 45/100
198/198 - 0s - loss: 0.0048
Epoch 46/100
198/198 - 0s - loss: 0.0049
Epoch 47/100
198/198 - 0s - loss: 0.0050
Epoch 48/100
198/198 - 0s - loss: 0.0050
Epoch 49/100
198/198 - 0s - loss: 0.0051
Epoch 50/100
198/198 - 0s - loss: 0.0049
Epoch 51/100
198/198 - 0s - loss: 0.0051
Epoch 52/100
198/198 - 0s - loss: 0.0047
Epoch 53/100
198/198 - 0s - loss: 0.0051
Epoch 54/100
198/198 - 0s - loss: 0.0049
Epoch 55/100
198/198 - 0s - loss: 0.0048
Epoch 56/100
198/198 - 0s - loss: 0.0050
Epoch 57/100
198/198 - 0s - loss: 0.0049
Epoch 58/100
198/198 - 0s - loss: 0.0050
Epoch 59/100
198/198 - 0s - loss: 0.0048
Epoch 60/100
198/198 - 0s - loss: 0.0049
Epoch 61/100
198/198 - 0s - loss: 0.0048
Epoch 62/100
198/198 - 0s - loss: 0.0048
Epoch 63/100
198/198 - 0s - loss: 0.0046
Epoch 64/100
198/198 - 0s - loss: 0.0052
Epoch 65/100
198/198 - 0s - loss: 0.0049
Epoch 66/100
198/198 - 0s - loss: 0.0046
Epoch 67/100
198/198 - 0s - loss: 0.0048
Epoch 68/100
198/198 - 0s - loss: 0.0046
Epoch 69/100
198/198 - 0s - loss: 0.0046
Epoch 70/100
198/198 - 0s - loss: 0.0048
Epoch 71/100
198/198 - 0s - loss: 0.0045
Epoch 72/100
198/198 - 0s - loss: 0.0048
Epoch 73/100
198/198 - 0s - loss: 0.0045
Epoch 74/100
198/198 - 0s - loss: 0.0047
Epoch 75/100
198/198 - 0s - loss: 0.0049
Epoch 76/100
198/198 - 0s - loss: 0.0048
Epoch 77/100
198/198 - 0s - loss: 0.0047
Epoch 78/100
198/198 - 0s - loss: 0.0048
Epoch 79/100
198/198 - 0s - loss: 0.0047
Epoch 80/100
198/198 - 0s - loss: 0.0051
Epoch 81/100
198/198 - 0s - loss: 0.0046
Epoch 82/100
198/198 - 0s - loss: 0.0050
Epoch 83/100
198/198 - 0s - loss: 0.0044
Epoch 84/100
198/198 - 0s - loss: 0.0047
Epoch 85/100
198/198 - 0s - loss: 0.0046
Epoch 86/100
198/198 - 0s - loss: 0.0046
Epoch 87/100
198/198 - 0s - loss: 0.0046
Epoch 88/100
198/198 - 0s - loss: 0.0047
Epoch 89/100
198/198 - 0s - loss: 0.0044
Epoch 90/100
198/198 - 0s - loss: 0.0046
Epoch 91/100
198/198 - 0s - loss: 0.0047
Epoch 92/100
198/198 - 0s - loss: 0.0044
Epoch 93/100
198/198 - 0s - loss: 0.0046
Epoch 94/100
198/198 - 0s - loss: 0.0045
Epoch 95/100
198/198 - 0s - loss: 0.0046
Epoch 96/100
198/198 - 0s - loss: 0.0045
Epoch 97/100
198/198 - 0s - loss: 0.0045
Epoch 98/100
198/198 - 0s - loss: 0.0045
Epoch 99/100
198/198 - 0s - loss: 0.0044
Epoch 100/100
198/198 - 0s - loss: 0.0042

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.069
Train RMSE: 0.146
key_word: bitcoin
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.626667  0.453333  0.320000
2021-07-25  0.560000  0.560000  0.480000  ...  0.920000  0.626667  0.453333
2021-08-01  0.426667  0.560000  0.560000  ...  0.280000  0.920000  0.626667
2021-08-08  0.573333  0.426667  0.560000  ...  0.266667  0.280000  0.920000
2021-08-15  0.453333  0.573333  0.426667  ...  0.520000  0.266667  0.280000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_4 (GRU)                  (None, 60)                13320     
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 61        
=================================================================
Total params: 13,381
Trainable params: 13,381
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0189
Epoch 2/100
198/198 - 0s - loss: 0.0061
Epoch 3/100
198/198 - 0s - loss: 0.0072
Epoch 4/100
198/198 - 0s - loss: 0.0064
Epoch 5/100
198/198 - 0s - loss: 0.0065
Epoch 6/100
198/198 - 0s - loss: 0.0054
Epoch 7/100
198/198 - 0s - loss: 0.0061
Epoch 8/100
198/198 - 0s - loss: 0.0059
Epoch 9/100
198/198 - 0s - loss: 0.0061
Epoch 10/100
198/198 - 0s - loss: 0.0057
Epoch 11/100
198/198 - 0s - loss: 0.0059
Epoch 12/100
198/198 - 0s - loss: 0.0060
Epoch 13/100
198/198 - 0s - loss: 0.0058
Epoch 14/100
198/198 - 0s - loss: 0.0053
Epoch 15/100
198/198 - 0s - loss: 0.0054
Epoch 16/100
198/198 - 0s - loss: 0.0055
Epoch 17/100
198/198 - 0s - loss: 0.0057
Epoch 18/100
198/198 - 0s - loss: 0.0058
Epoch 19/100
198/198 - 0s - loss: 0.0058
Epoch 20/100
198/198 - 0s - loss: 0.0058
Epoch 21/100
198/198 - 0s - loss: 0.0054
Epoch 22/100
198/198 - 0s - loss: 0.0052
Epoch 23/100
198/198 - 0s - loss: 0.0055
Epoch 24/100
198/198 - 0s - loss: 0.0053
Epoch 25/100
198/198 - 0s - loss: 0.0054
Epoch 26/100
198/198 - 0s - loss: 0.0053
Epoch 27/100
198/198 - 0s - loss: 0.0050
Epoch 28/100
198/198 - 0s - loss: 0.0055
Epoch 29/100
198/198 - 0s - loss: 0.0051
Epoch 30/100
198/198 - 0s - loss: 0.0051
Epoch 31/100
198/198 - 0s - loss: 0.0050
Epoch 32/100
198/198 - 0s - loss: 0.0052
Epoch 33/100
198/198 - 0s - loss: 0.0053
Epoch 34/100
198/198 - 0s - loss: 0.0052
Epoch 35/100
198/198 - 0s - loss: 0.0051
Epoch 36/100
198/198 - 0s - loss: 0.0051
Epoch 37/100
198/198 - 0s - loss: 0.0051
Epoch 38/100
198/198 - 0s - loss: 0.0051
Epoch 39/100
198/198 - 0s - loss: 0.0050
Epoch 40/100
198/198 - 0s - loss: 0.0052
Epoch 41/100
198/198 - 0s - loss: 0.0053
Epoch 42/100
198/198 - 0s - loss: 0.0052
Epoch 43/100
198/198 - 0s - loss: 0.0052
Epoch 44/100
198/198 - 0s - loss: 0.0051
Epoch 45/100
198/198 - 0s - loss: 0.0054
Epoch 46/100
198/198 - 0s - loss: 0.0051
Epoch 47/100
198/198 - 0s - loss: 0.0053
Epoch 48/100
198/198 - 0s - loss: 0.0048
Epoch 49/100
198/198 - 0s - loss: 0.0050
Epoch 50/100
198/198 - 0s - loss: 0.0048
Epoch 51/100
198/198 - 0s - loss: 0.0050
Epoch 52/100
198/198 - 0s - loss: 0.0048
Epoch 53/100
198/198 - 0s - loss: 0.0050
Epoch 54/100
198/198 - 0s - loss: 0.0047
Epoch 55/100
198/198 - 0s - loss: 0.0049
Epoch 56/100
198/198 - 0s - loss: 0.0049
Epoch 57/100
198/198 - 0s - loss: 0.0050
Epoch 58/100
198/198 - 0s - loss: 0.0049
Epoch 59/100
198/198 - 0s - loss: 0.0049
Epoch 60/100
198/198 - 0s - loss: 0.0050
Epoch 61/100
198/198 - 0s - loss: 0.0048
Epoch 62/100
198/198 - 0s - loss: 0.0050
Epoch 63/100
198/198 - 0s - loss: 0.0050
Epoch 64/100
198/198 - 0s - loss: 0.0049
Epoch 65/100
198/198 - 0s - loss: 0.0048
Epoch 66/100
198/198 - 0s - loss: 0.0046
Epoch 67/100
198/198 - 0s - loss: 0.0049
Epoch 68/100
198/198 - 0s - loss: 0.0050
Epoch 69/100
198/198 - 0s - loss: 0.0047
Epoch 70/100
198/198 - 0s - loss: 0.0049
Epoch 71/100
198/198 - 0s - loss: 0.0046
Epoch 72/100
198/198 - 0s - loss: 0.0046
Epoch 73/100
198/198 - 0s - loss: 0.0047
Epoch 74/100
198/198 - 0s - loss: 0.0048
Epoch 75/100
198/198 - 0s - loss: 0.0047
Epoch 76/100
198/198 - 0s - loss: 0.0047
Epoch 77/100
198/198 - 0s - loss: 0.0051
Epoch 78/100
198/198 - 0s - loss: 0.0046
Epoch 79/100
198/198 - 0s - loss: 0.0048
Epoch 80/100
198/198 - 0s - loss: 0.0046
Epoch 81/100
198/198 - 0s - loss: 0.0046
Epoch 82/100
198/198 - 0s - loss: 0.0046
Epoch 83/100
198/198 - 0s - loss: 0.0045
Epoch 84/100
198/198 - 0s - loss: 0.0045
Epoch 85/100
198/198 - 0s - loss: 0.0046
Epoch 86/100
198/198 - 0s - loss: 0.0047
Epoch 87/100
198/198 - 0s - loss: 0.0046
Epoch 88/100
198/198 - 0s - loss: 0.0046
Epoch 89/100
198/198 - 0s - loss: 0.0047
Epoch 90/100
198/198 - 0s - loss: 0.0045
Epoch 91/100
198/198 - 0s - loss: 0.0046
Epoch 92/100
198/198 - 0s - loss: 0.0046
Epoch 93/100
198/198 - 0s - loss: 0.0044
Epoch 94/100
198/198 - 0s - loss: 0.0047
Epoch 95/100
198/198 - 0s - loss: 0.0045
Epoch 96/100
198/198 - 0s - loss: 0.0046
Epoch 97/100
198/198 - 0s - loss: 0.0045
Epoch 98/100
198/198 - 0s - loss: 0.0042
Epoch 99/100
198/198 - 0s - loss: 0.0046
Epoch 100/100
198/198 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.065
Train RMSE: 0.144
key_word: bitcoin
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.506667  0.840000  0.453333
2021-07-25  0.560000  0.560000  0.480000  ...  0.546667  0.506667  0.840000
2021-08-01  0.426667  0.560000  0.560000  ...  0.226667  0.546667  0.506667
2021-08-08  0.573333  0.426667  0.560000  ...  0.520000  0.226667  0.546667
2021-08-15  0.453333  0.573333  0.426667  ...  0.480000  0.520000  0.226667

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_5 (GRU)                  (None, 4)                 360       
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 5         
=================================================================
Total params: 365
Trainable params: 365
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0853
Epoch 2/100
188/188 - 0s - loss: 0.0083
Epoch 3/100
188/188 - 0s - loss: 0.0081
Epoch 4/100
188/188 - 0s - loss: 0.0075
Epoch 5/100
188/188 - 0s - loss: 0.0075
Epoch 6/100
188/188 - 0s - loss: 0.0072
Epoch 7/100
188/188 - 0s - loss: 0.0067
Epoch 8/100
188/188 - 0s - loss: 0.0067
Epoch 9/100
188/188 - 0s - loss: 0.0065
Epoch 10/100
188/188 - 0s - loss: 0.0065
Epoch 11/100
188/188 - 0s - loss: 0.0064
Epoch 12/100
188/188 - 0s - loss: 0.0061
Epoch 13/100
188/188 - 0s - loss: 0.0062
Epoch 14/100
188/188 - 0s - loss: 0.0062
Epoch 15/100
188/188 - 0s - loss: 0.0060
Epoch 16/100
188/188 - 0s - loss: 0.0057
Epoch 17/100
188/188 - 0s - loss: 0.0059
Epoch 18/100
188/188 - 0s - loss: 0.0059
Epoch 19/100
188/188 - 0s - loss: 0.0059
Epoch 20/100
188/188 - 0s - loss: 0.0058
Epoch 21/100
188/188 - 0s - loss: 0.0057
Epoch 22/100
188/188 - 0s - loss: 0.0060
Epoch 23/100
188/188 - 0s - loss: 0.0057
Epoch 24/100
188/188 - 0s - loss: 0.0056
Epoch 25/100
188/188 - 0s - loss: 0.0058
Epoch 26/100
188/188 - 0s - loss: 0.0056
Epoch 27/100
188/188 - 0s - loss: 0.0059
Epoch 28/100
188/188 - 0s - loss: 0.0052
Epoch 29/100
188/188 - 0s - loss: 0.0056
Epoch 30/100
188/188 - 0s - loss: 0.0055
Epoch 31/100
188/188 - 0s - loss: 0.0055
Epoch 32/100
188/188 - 0s - loss: 0.0055
Epoch 33/100
188/188 - 0s - loss: 0.0055
Epoch 34/100
188/188 - 0s - loss: 0.0055
Epoch 35/100
188/188 - 0s - loss: 0.0055
Epoch 36/100
188/188 - 0s - loss: 0.0056
Epoch 37/100
188/188 - 0s - loss: 0.0053
Epoch 38/100
188/188 - 0s - loss: 0.0052
Epoch 39/100
188/188 - 0s - loss: 0.0057
Epoch 40/100
188/188 - 0s - loss: 0.0051
Epoch 41/100
188/188 - 0s - loss: 0.0055
Epoch 42/100
188/188 - 0s - loss: 0.0056
Epoch 43/100
188/188 - 0s - loss: 0.0053
Epoch 44/100
188/188 - 0s - loss: 0.0054
Epoch 45/100
188/188 - 0s - loss: 0.0052
Epoch 46/100
188/188 - 0s - loss: 0.0053
Epoch 47/100
188/188 - 0s - loss: 0.0053
Epoch 48/100
188/188 - 0s - loss: 0.0051
Epoch 49/100
188/188 - 0s - loss: 0.0052
Epoch 50/100
188/188 - 0s - loss: 0.0052
Epoch 51/100
188/188 - 0s - loss: 0.0053
Epoch 52/100
188/188 - 0s - loss: 0.0051
Epoch 53/100
188/188 - 0s - loss: 0.0053
Epoch 54/100
188/188 - 0s - loss: 0.0053
Epoch 55/100
188/188 - 0s - loss: 0.0051
Epoch 56/100
188/188 - 0s - loss: 0.0053
Epoch 57/100
188/188 - 0s - loss: 0.0051
Epoch 58/100
188/188 - 0s - loss: 0.0054
Epoch 59/100
188/188 - 0s - loss: 0.0049
Epoch 60/100
188/188 - 0s - loss: 0.0053
Epoch 61/100
188/188 - 0s - loss: 0.0049
Epoch 62/100
188/188 - 0s - loss: 0.0052
Epoch 63/100
188/188 - 0s - loss: 0.0054
Epoch 64/100
188/188 - 0s - loss: 0.0049
Epoch 65/100
188/188 - 0s - loss: 0.0050
Epoch 66/100
188/188 - 0s - loss: 0.0051
Epoch 67/100
188/188 - 0s - loss: 0.0051
Epoch 68/100
188/188 - 0s - loss: 0.0053
Epoch 69/100
188/188 - 0s - loss: 0.0049
Epoch 70/100
188/188 - 0s - loss: 0.0051
Epoch 71/100
188/188 - 0s - loss: 0.0052
Epoch 72/100
188/188 - 0s - loss: 0.0050
Epoch 73/100
188/188 - 0s - loss: 0.0051
Epoch 74/100
188/188 - 0s - loss: 0.0050
Epoch 75/100
188/188 - 0s - loss: 0.0050
Epoch 76/100
188/188 - 0s - loss: 0.0050
Epoch 77/100
188/188 - 0s - loss: 0.0050
Epoch 78/100
188/188 - 0s - loss: 0.0050
Epoch 79/100
188/188 - 0s - loss: 0.0053
Epoch 80/100
188/188 - 0s - loss: 0.0049
Epoch 81/100
188/188 - 0s - loss: 0.0049
Epoch 82/100
188/188 - 0s - loss: 0.0050
Epoch 83/100
188/188 - 0s - loss: 0.0050
Epoch 84/100
188/188 - 0s - loss: 0.0049
Epoch 85/100
188/188 - 0s - loss: 0.0050
Epoch 86/100
188/188 - 0s - loss: 0.0051
Epoch 87/100
188/188 - 0s - loss: 0.0048
Epoch 88/100
188/188 - 0s - loss: 0.0049
Epoch 89/100
188/188 - 0s - loss: 0.0049
Epoch 90/100
188/188 - 0s - loss: 0.0050
Epoch 91/100
188/188 - 0s - loss: 0.0050
Epoch 92/100
188/188 - 0s - loss: 0.0049
Epoch 93/100
188/188 - 0s - loss: 0.0048
Epoch 94/100
188/188 - 0s - loss: 0.0049
Epoch 95/100
188/188 - 0s - loss: 0.0049
Epoch 96/100
188/188 - 0s - loss: 0.0048
Epoch 97/100
188/188 - 0s - loss: 0.0049
Epoch 98/100
188/188 - 0s - loss: 0.0051
Epoch 99/100
188/188 - 0s - loss: 0.0049
Epoch 100/100
188/188 - 0s - loss: 0.0048

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.072
Train RMSE: 0.145
key_word: bitcoin
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.506667  0.840000  0.453333
2021-07-25  0.560000  0.560000  0.480000  ...  0.546667  0.506667  0.840000
2021-08-01  0.426667  0.560000  0.560000  ...  0.226667  0.546667  0.506667
2021-08-08  0.573333  0.426667  0.560000  ...  0.520000  0.226667  0.546667
2021-08-15  0.453333  0.573333  0.426667  ...  0.480000  0.520000  0.226667

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_6 (GRU)                  (None, 8)                 816       
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 9         
=================================================================
Total params: 825
Trainable params: 825
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0885
Epoch 2/100
188/188 - 0s - loss: 0.0076
Epoch 3/100
188/188 - 0s - loss: 0.0081
Epoch 4/100
188/188 - 0s - loss: 0.0073
Epoch 5/100
188/188 - 0s - loss: 0.0072
Epoch 6/100
188/188 - 0s - loss: 0.0074
Epoch 7/100
188/188 - 0s - loss: 0.0069
Epoch 8/100
188/188 - 0s - loss: 0.0068
Epoch 9/100
188/188 - 0s - loss: 0.0064
Epoch 10/100
188/188 - 0s - loss: 0.0065
Epoch 11/100
188/188 - 0s - loss: 0.0063
Epoch 12/100
188/188 - 0s - loss: 0.0065
Epoch 13/100
188/188 - 0s - loss: 0.0063
Epoch 14/100
188/188 - 0s - loss: 0.0061
Epoch 15/100
188/188 - 0s - loss: 0.0060
Epoch 16/100
188/188 - 0s - loss: 0.0058
Epoch 17/100
188/188 - 0s - loss: 0.0058
Epoch 18/100
188/188 - 0s - loss: 0.0058
Epoch 19/100
188/188 - 0s - loss: 0.0056
Epoch 20/100
188/188 - 0s - loss: 0.0058
Epoch 21/100
188/188 - 0s - loss: 0.0056
Epoch 22/100
188/188 - 0s - loss: 0.0058
Epoch 23/100
188/188 - 0s - loss: 0.0055
Epoch 24/100
188/188 - 0s - loss: 0.0055
Epoch 25/100
188/188 - 0s - loss: 0.0054
Epoch 26/100
188/188 - 0s - loss: 0.0058
Epoch 27/100
188/188 - 0s - loss: 0.0057
Epoch 28/100
188/188 - 0s - loss: 0.0054
Epoch 29/100
188/188 - 0s - loss: 0.0054
Epoch 30/100
188/188 - 0s - loss: 0.0055
Epoch 31/100
188/188 - 0s - loss: 0.0054
Epoch 32/100
188/188 - 0s - loss: 0.0055
Epoch 33/100
188/188 - 0s - loss: 0.0054
Epoch 34/100
188/188 - 0s - loss: 0.0054
Epoch 35/100
188/188 - 0s - loss: 0.0052
Epoch 36/100
188/188 - 0s - loss: 0.0054
Epoch 37/100
188/188 - 0s - loss: 0.0053
Epoch 38/100
188/188 - 0s - loss: 0.0050
Epoch 39/100
188/188 - 0s - loss: 0.0053
Epoch 40/100
188/188 - 0s - loss: 0.0053
Epoch 41/100
188/188 - 0s - loss: 0.0050
Epoch 42/100
188/188 - 0s - loss: 0.0054
Epoch 43/100
188/188 - 0s - loss: 0.0053
Epoch 44/100
188/188 - 0s - loss: 0.0053
Epoch 45/100
188/188 - 0s - loss: 0.0050
Epoch 46/100
188/188 - 0s - loss: 0.0054
Epoch 47/100
188/188 - 0s - loss: 0.0053
Epoch 48/100
188/188 - 0s - loss: 0.0051
Epoch 49/100
188/188 - 0s - loss: 0.0052
Epoch 50/100
188/188 - 0s - loss: 0.0054
Epoch 51/100
188/188 - 0s - loss: 0.0052
Epoch 52/100
188/188 - 0s - loss: 0.0053
Epoch 53/100
188/188 - 0s - loss: 0.0051
Epoch 54/100
188/188 - 0s - loss: 0.0051
Epoch 55/100
188/188 - 0s - loss: 0.0051
Epoch 56/100
188/188 - 0s - loss: 0.0051
Epoch 57/100
188/188 - 0s - loss: 0.0049
Epoch 58/100
188/188 - 0s - loss: 0.0051
Epoch 59/100
188/188 - 0s - loss: 0.0051
Epoch 60/100
188/188 - 0s - loss: 0.0050
Epoch 61/100
188/188 - 0s - loss: 0.0052
Epoch 62/100
188/188 - 0s - loss: 0.0049
Epoch 63/100
188/188 - 0s - loss: 0.0050
Epoch 64/100
188/188 - 0s - loss: 0.0049
Epoch 65/100
188/188 - 0s - loss: 0.0052
Epoch 66/100
188/188 - 0s - loss: 0.0046
Epoch 67/100
188/188 - 0s - loss: 0.0053
Epoch 68/100
188/188 - 0s - loss: 0.0050
Epoch 69/100
188/188 - 0s - loss: 0.0050
Epoch 70/100
188/188 - 0s - loss: 0.0050
Epoch 71/100
188/188 - 0s - loss: 0.0048
Epoch 72/100
188/188 - 0s - loss: 0.0048
Epoch 73/100
188/188 - 0s - loss: 0.0051
Epoch 74/100
188/188 - 0s - loss: 0.0049
Epoch 75/100
188/188 - 0s - loss: 0.0051
Epoch 76/100
188/188 - 0s - loss: 0.0052
Epoch 77/100
188/188 - 0s - loss: 0.0049
Epoch 78/100
188/188 - 0s - loss: 0.0048
Epoch 79/100
188/188 - 0s - loss: 0.0051
Epoch 80/100
188/188 - 0s - loss: 0.0049
Epoch 81/100
188/188 - 0s - loss: 0.0047
Epoch 82/100
188/188 - 0s - loss: 0.0050
Epoch 83/100
188/188 - 0s - loss: 0.0049
Epoch 84/100
188/188 - 0s - loss: 0.0049
Epoch 85/100
188/188 - 0s - loss: 0.0048
Epoch 86/100
188/188 - 0s - loss: 0.0047
Epoch 87/100
188/188 - 0s - loss: 0.0051
Epoch 88/100
188/188 - 0s - loss: 0.0049
Epoch 89/100
188/188 - 0s - loss: 0.0048
Epoch 90/100
188/188 - 0s - loss: 0.0048
Epoch 91/100
188/188 - 0s - loss: 0.0047
Epoch 92/100
188/188 - 0s - loss: 0.0049
Epoch 93/100
188/188 - 0s - loss: 0.0048
Epoch 94/100
188/188 - 0s - loss: 0.0049
Epoch 95/100
188/188 - 0s - loss: 0.0047
Epoch 96/100
188/188 - 0s - loss: 0.0049
Epoch 97/100
188/188 - 0s - loss: 0.0047
Epoch 98/100
188/188 - 0s - loss: 0.0049
Epoch 99/100
188/188 - 0s - loss: 0.0047
Epoch 100/100
188/188 - 0s - loss: 0.0047

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.143
key_word: bitcoin
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.506667  0.840000  0.453333
2021-07-25  0.560000  0.560000  0.480000  ...  0.546667  0.506667  0.840000
2021-08-01  0.426667  0.560000  0.560000  ...  0.226667  0.546667  0.506667
2021-08-08  0.573333  0.426667  0.560000  ...  0.520000  0.226667  0.546667
2021-08-15  0.453333  0.573333  0.426667  ...  0.480000  0.520000  0.226667

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_7 (GRU)                  (None, 16)                2016      
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 17        
=================================================================
Total params: 2,033
Trainable params: 2,033
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0157
Epoch 2/100
188/188 - 0s - loss: 0.0084
Epoch 3/100
188/188 - 0s - loss: 0.0079
Epoch 4/100
188/188 - 0s - loss: 0.0075
Epoch 5/100
188/188 - 0s - loss: 0.0075
Epoch 6/100
188/188 - 0s - loss: 0.0072
Epoch 7/100
188/188 - 0s - loss: 0.0070
Epoch 8/100
188/188 - 0s - loss: 0.0072
Epoch 9/100
188/188 - 0s - loss: 0.0067
Epoch 10/100
188/188 - 0s - loss: 0.0066
Epoch 11/100
188/188 - 0s - loss: 0.0061
Epoch 12/100
188/188 - 0s - loss: 0.0066
Epoch 13/100
188/188 - 0s - loss: 0.0063
Epoch 14/100
188/188 - 0s - loss: 0.0062
Epoch 15/100
188/188 - 0s - loss: 0.0063
Epoch 16/100
188/188 - 0s - loss: 0.0063
Epoch 17/100
188/188 - 0s - loss: 0.0060
Epoch 18/100
188/188 - 0s - loss: 0.0056
Epoch 19/100
188/188 - 0s - loss: 0.0058
Epoch 20/100
188/188 - 0s - loss: 0.0056
Epoch 21/100
188/188 - 0s - loss: 0.0057
Epoch 22/100
188/188 - 0s - loss: 0.0062
Epoch 23/100
188/188 - 0s - loss: 0.0059
Epoch 24/100
188/188 - 0s - loss: 0.0057
Epoch 25/100
188/188 - 0s - loss: 0.0054
Epoch 26/100
188/188 - 0s - loss: 0.0056
Epoch 27/100
188/188 - 0s - loss: 0.0056
Epoch 28/100
188/188 - 0s - loss: 0.0054
Epoch 29/100
188/188 - 0s - loss: 0.0053
Epoch 30/100
188/188 - 0s - loss: 0.0055
Epoch 31/100
188/188 - 0s - loss: 0.0057
Epoch 32/100
188/188 - 0s - loss: 0.0052
Epoch 33/100
188/188 - 0s - loss: 0.0053
Epoch 34/100
188/188 - 0s - loss: 0.0051
Epoch 35/100
188/188 - 0s - loss: 0.0052
Epoch 36/100
188/188 - 0s - loss: 0.0053
Epoch 37/100
188/188 - 0s - loss: 0.0054
Epoch 38/100
188/188 - 0s - loss: 0.0053
Epoch 39/100
188/188 - 0s - loss: 0.0049
Epoch 40/100
188/188 - 0s - loss: 0.0052
Epoch 41/100
188/188 - 0s - loss: 0.0055
Epoch 42/100
188/188 - 0s - loss: 0.0051
Epoch 43/100
188/188 - 0s - loss: 0.0051
Epoch 44/100
188/188 - 0s - loss: 0.0052
Epoch 45/100
188/188 - 0s - loss: 0.0049
Epoch 46/100
188/188 - 0s - loss: 0.0050
Epoch 47/100
188/188 - 0s - loss: 0.0053
Epoch 48/100
188/188 - 0s - loss: 0.0050
Epoch 49/100
188/188 - 0s - loss: 0.0053
Epoch 50/100
188/188 - 0s - loss: 0.0054
Epoch 51/100
188/188 - 0s - loss: 0.0051
Epoch 52/100
188/188 - 0s - loss: 0.0048
Epoch 53/100
188/188 - 0s - loss: 0.0049
Epoch 54/100
188/188 - 0s - loss: 0.0052
Epoch 55/100
188/188 - 0s - loss: 0.0049
Epoch 56/100
188/188 - 0s - loss: 0.0053
Epoch 57/100
188/188 - 0s - loss: 0.0050
Epoch 58/100
188/188 - 0s - loss: 0.0049
Epoch 59/100
188/188 - 0s - loss: 0.0050
Epoch 60/100
188/188 - 0s - loss: 0.0051
Epoch 61/100
188/188 - 0s - loss: 0.0050
Epoch 62/100
188/188 - 0s - loss: 0.0048
Epoch 63/100
188/188 - 0s - loss: 0.0051
Epoch 64/100
188/188 - 0s - loss: 0.0046
Epoch 65/100
188/188 - 0s - loss: 0.0047
Epoch 66/100
188/188 - 0s - loss: 0.0049
Epoch 67/100
188/188 - 0s - loss: 0.0049
Epoch 68/100
188/188 - 0s - loss: 0.0047
Epoch 69/100
188/188 - 0s - loss: 0.0050
Epoch 70/100
188/188 - 0s - loss: 0.0049
Epoch 71/100
188/188 - 0s - loss: 0.0048
Epoch 72/100
188/188 - 0s - loss: 0.0046
Epoch 73/100
188/188 - 0s - loss: 0.0048
Epoch 74/100
188/188 - 0s - loss: 0.0047
Epoch 75/100
188/188 - 0s - loss: 0.0048
Epoch 76/100
188/188 - 0s - loss: 0.0047
Epoch 77/100
188/188 - 0s - loss: 0.0050
Epoch 78/100
188/188 - 0s - loss: 0.0046
Epoch 79/100
188/188 - 0s - loss: 0.0048
Epoch 80/100
188/188 - 0s - loss: 0.0048
Epoch 81/100
188/188 - 0s - loss: 0.0046
Epoch 82/100
188/188 - 0s - loss: 0.0047
Epoch 83/100
188/188 - 0s - loss: 0.0049
Epoch 84/100
188/188 - 0s - loss: 0.0046
Epoch 85/100
188/188 - 0s - loss: 0.0043
Epoch 86/100
188/188 - 0s - loss: 0.0046
Epoch 87/100
188/188 - 0s - loss: 0.0048
Epoch 88/100
188/188 - 0s - loss: 0.0045
Epoch 89/100
188/188 - 0s - loss: 0.0046
Epoch 90/100
188/188 - 0s - loss: 0.0044
Epoch 91/100
188/188 - 0s - loss: 0.0045
Epoch 92/100
188/188 - 0s - loss: 0.0048
Epoch 93/100
188/188 - 0s - loss: 0.0044
Epoch 94/100
188/188 - 0s - loss: 0.0047
Epoch 95/100
188/188 - 0s - loss: 0.0045
Epoch 96/100
188/188 - 0s - loss: 0.0046
Epoch 97/100
188/188 - 0s - loss: 0.0045
Epoch 98/100
188/188 - 0s - loss: 0.0044
Epoch 99/100
188/188 - 0s - loss: 0.0045
Epoch 100/100
188/188 - 0s - loss: 0.0045

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.063
Train RMSE: 0.148
key_word: bitcoin
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.506667  0.840000  0.453333
2021-07-25  0.560000  0.560000  0.480000  ...  0.546667  0.506667  0.840000
2021-08-01  0.426667  0.560000  0.560000  ...  0.226667  0.546667  0.506667
2021-08-08  0.573333  0.426667  0.560000  ...  0.520000  0.226667  0.546667
2021-08-15  0.453333  0.573333  0.426667  ...  0.480000  0.520000  0.226667

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_8 (GRU)                  (None, 32)                5568      
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 33        
=================================================================
Total params: 5,601
Trainable params: 5,601
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0167
Epoch 2/100
188/188 - 0s - loss: 0.0075
Epoch 3/100
188/188 - 0s - loss: 0.0077
Epoch 4/100
188/188 - 0s - loss: 0.0074
Epoch 5/100
188/188 - 0s - loss: 0.0065
Epoch 6/100
188/188 - 0s - loss: 0.0061
Epoch 7/100
188/188 - 0s - loss: 0.0071
Epoch 8/100
188/188 - 0s - loss: 0.0066
Epoch 9/100
188/188 - 0s - loss: 0.0062
Epoch 10/100
188/188 - 0s - loss: 0.0062
Epoch 11/100
188/188 - 0s - loss: 0.0060
Epoch 12/100
188/188 - 0s - loss: 0.0063
Epoch 13/100
188/188 - 0s - loss: 0.0059
Epoch 14/100
188/188 - 0s - loss: 0.0064
Epoch 15/100
188/188 - 0s - loss: 0.0061
Epoch 16/100
188/188 - 0s - loss: 0.0057
Epoch 17/100
188/188 - 0s - loss: 0.0057
Epoch 18/100
188/188 - 0s - loss: 0.0062
Epoch 19/100
188/188 - 0s - loss: 0.0054
Epoch 20/100
188/188 - 0s - loss: 0.0055
Epoch 21/100
188/188 - 0s - loss: 0.0055
Epoch 22/100
188/188 - 0s - loss: 0.0055
Epoch 23/100
188/188 - 0s - loss: 0.0056
Epoch 24/100
188/188 - 0s - loss: 0.0057
Epoch 25/100
188/188 - 0s - loss: 0.0054
Epoch 26/100
188/188 - 0s - loss: 0.0058
Epoch 27/100
188/188 - 0s - loss: 0.0054
Epoch 28/100
188/188 - 0s - loss: 0.0052
Epoch 29/100
188/188 - 0s - loss: 0.0052
Epoch 30/100
188/188 - 0s - loss: 0.0056
Epoch 31/100
188/188 - 0s - loss: 0.0051
Epoch 32/100
188/188 - 0s - loss: 0.0055
Epoch 33/100
188/188 - 0s - loss: 0.0051
Epoch 34/100
188/188 - 0s - loss: 0.0051
Epoch 35/100
188/188 - 0s - loss: 0.0051
Epoch 36/100
188/188 - 0s - loss: 0.0050
Epoch 37/100
188/188 - 0s - loss: 0.0052
Epoch 38/100
188/188 - 0s - loss: 0.0055
Epoch 39/100
188/188 - 0s - loss: 0.0053
Epoch 40/100
188/188 - 0s - loss: 0.0052
Epoch 41/100
188/188 - 0s - loss: 0.0053
Epoch 42/100
188/188 - 0s - loss: 0.0055
Epoch 43/100
188/188 - 0s - loss: 0.0053
Epoch 44/100
188/188 - 0s - loss: 0.0055
Epoch 45/100
188/188 - 0s - loss: 0.0051
Epoch 46/100
188/188 - 0s - loss: 0.0054
Epoch 47/100
188/188 - 0s - loss: 0.0051
Epoch 48/100
188/188 - 0s - loss: 0.0050
Epoch 49/100
188/188 - 0s - loss: 0.0051
Epoch 50/100
188/188 - 0s - loss: 0.0052
Epoch 51/100
188/188 - 0s - loss: 0.0051
Epoch 52/100
188/188 - 0s - loss: 0.0052
Epoch 53/100
188/188 - 0s - loss: 0.0049
Epoch 54/100
188/188 - 0s - loss: 0.0048
Epoch 55/100
188/188 - 0s - loss: 0.0053
Epoch 56/100
188/188 - 0s - loss: 0.0053
Epoch 57/100
188/188 - 0s - loss: 0.0048
Epoch 58/100
188/188 - 0s - loss: 0.0048
Epoch 59/100
188/188 - 0s - loss: 0.0050
Epoch 60/100
188/188 - 0s - loss: 0.0052
Epoch 61/100
188/188 - 0s - loss: 0.0055
Epoch 62/100
188/188 - 0s - loss: 0.0051
Epoch 63/100
188/188 - 0s - loss: 0.0050
Epoch 64/100
188/188 - 0s - loss: 0.0048
Epoch 65/100
188/188 - 0s - loss: 0.0048
Epoch 66/100
188/188 - 0s - loss: 0.0046
Epoch 67/100
188/188 - 0s - loss: 0.0050
Epoch 68/100
188/188 - 0s - loss: 0.0051
Epoch 69/100
188/188 - 0s - loss: 0.0051
Epoch 70/100
188/188 - 0s - loss: 0.0051
Epoch 71/100
188/188 - 0s - loss: 0.0049
Epoch 72/100
188/188 - 0s - loss: 0.0049
Epoch 73/100
188/188 - 0s - loss: 0.0050
Epoch 74/100
188/188 - 0s - loss: 0.0050
Epoch 75/100
188/188 - 0s - loss: 0.0050
Epoch 76/100
188/188 - 0s - loss: 0.0048
Epoch 77/100
188/188 - 0s - loss: 0.0051
Epoch 78/100
188/188 - 0s - loss: 0.0048
Epoch 79/100
188/188 - 0s - loss: 0.0049
Epoch 80/100
188/188 - 0s - loss: 0.0051
Epoch 81/100
188/188 - 0s - loss: 0.0049
Epoch 82/100
188/188 - 0s - loss: 0.0046
Epoch 83/100
188/188 - 0s - loss: 0.0050
Epoch 84/100
188/188 - 0s - loss: 0.0048
Epoch 85/100
188/188 - 0s - loss: 0.0050
Epoch 86/100
188/188 - 0s - loss: 0.0049
Epoch 87/100
188/188 - 0s - loss: 0.0046
Epoch 88/100
188/188 - 0s - loss: 0.0048
Epoch 89/100
188/188 - 0s - loss: 0.0048
Epoch 90/100
188/188 - 0s - loss: 0.0050
Epoch 91/100
188/188 - 0s - loss: 0.0048
Epoch 92/100
188/188 - 0s - loss: 0.0048
Epoch 93/100
188/188 - 0s - loss: 0.0051
Epoch 94/100
188/188 - 0s - loss: 0.0046
Epoch 95/100
188/188 - 0s - loss: 0.0048
Epoch 96/100
188/188 - 0s - loss: 0.0051
Epoch 97/100
188/188 - 0s - loss: 0.0048
Epoch 98/100
188/188 - 0s - loss: 0.0047
Epoch 99/100
188/188 - 0s - loss: 0.0046
Epoch 100/100
188/188 - 0s - loss: 0.0050

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.066
Train RMSE: 0.144
key_word: bitcoin
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.560000  0.480000  0.440000  ...  0.506667  0.840000  0.453333
2021-07-25  0.560000  0.560000  0.480000  ...  0.546667  0.506667  0.840000
2021-08-01  0.426667  0.560000  0.560000  ...  0.226667  0.546667  0.506667
2021-08-08  0.573333  0.426667  0.560000  ...  0.520000  0.226667  0.546667
2021-08-15  0.453333  0.573333  0.426667  ...  0.480000  0.520000  0.226667

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_9 (GRU)                  (None, 60)                15480     
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 61        
=================================================================
Total params: 15,541
Trainable params: 15,541
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0163
Epoch 2/100
188/188 - 0s - loss: 0.0068
Epoch 3/100
188/188 - 0s - loss: 0.0078
Epoch 4/100
188/188 - 0s - loss: 0.0078
Epoch 5/100
188/188 - 0s - loss: 0.0063
Epoch 6/100
188/188 - 0s - loss: 0.0065
Epoch 7/100
188/188 - 0s - loss: 0.0066
Epoch 8/100
188/188 - 0s - loss: 0.0061
Epoch 9/100
188/188 - 0s - loss: 0.0056
Epoch 10/100
188/188 - 0s - loss: 0.0059
Epoch 11/100
188/188 - 0s - loss: 0.0064
Epoch 12/100
188/188 - 0s - loss: 0.0068
Epoch 13/100
188/188 - 0s - loss: 0.0055
Epoch 14/100
188/188 - 0s - loss: 0.0062
Epoch 15/100
188/188 - 0s - loss: 0.0058
Epoch 16/100
188/188 - 0s - loss: 0.0061
Epoch 17/100
188/188 - 0s - loss: 0.0061
Epoch 18/100
188/188 - 0s - loss: 0.0057
Epoch 19/100
188/188 - 0s - loss: 0.0059
Epoch 20/100
188/188 - 0s - loss: 0.0053
Epoch 21/100
188/188 - 0s - loss: 0.0058
Epoch 22/100
188/188 - 0s - loss: 0.0056
Epoch 23/100
188/188 - 0s - loss: 0.0055
Epoch 24/100
188/188 - 0s - loss: 0.0057
Epoch 25/100
188/188 - 0s - loss: 0.0055
Epoch 26/100
188/188 - 0s - loss: 0.0055
Epoch 27/100
188/188 - 0s - loss: 0.0052
Epoch 28/100
188/188 - 0s - loss: 0.0055
Epoch 29/100
188/188 - 0s - loss: 0.0054
Epoch 30/100
188/188 - 0s - loss: 0.0055
Epoch 31/100
188/188 - 0s - loss: 0.0055
Epoch 32/100
188/188 - 0s - loss: 0.0052
Epoch 33/100
188/188 - 0s - loss: 0.0054
Epoch 34/100
188/188 - 0s - loss: 0.0053
Epoch 35/100
188/188 - 0s - loss: 0.0053
Epoch 36/100
188/188 - 0s - loss: 0.0051
Epoch 37/100
188/188 - 0s - loss: 0.0055
Epoch 38/100
188/188 - 0s - loss: 0.0055
Epoch 39/100
188/188 - 0s - loss: 0.0054
Epoch 40/100
188/188 - 0s - loss: 0.0052
Epoch 41/100
188/188 - 0s - loss: 0.0053
Epoch 42/100
188/188 - 0s - loss: 0.0052
Epoch 43/100
188/188 - 0s - loss: 0.0051
Epoch 44/100
188/188 - 0s - loss: 0.0052
Epoch 45/100
188/188 - 0s - loss: 0.0049
Epoch 46/100
188/188 - 0s - loss: 0.0054
Epoch 47/100
188/188 - 0s - loss: 0.0051
Epoch 48/100
188/188 - 0s - loss: 0.0054
Epoch 49/100
188/188 - 0s - loss: 0.0054
Epoch 50/100
188/188 - 0s - loss: 0.0055
Epoch 51/100
188/188 - 0s - loss: 0.0053
Epoch 52/100
188/188 - 0s - loss: 0.0050
Epoch 53/100
188/188 - 0s - loss: 0.0049
Epoch 54/100
188/188 - 0s - loss: 0.0052
Epoch 55/100
188/188 - 0s - loss: 0.0052
Epoch 56/100
188/188 - 0s - loss: 0.0052
Epoch 57/100
188/188 - 0s - loss: 0.0050
Epoch 58/100
188/188 - 0s - loss: 0.0051
Epoch 59/100
188/188 - 0s - loss: 0.0050
Epoch 60/100
188/188 - 0s - loss: 0.0053
Epoch 61/100
188/188 - 0s - loss: 0.0051
Epoch 62/100
188/188 - 0s - loss: 0.0050
Epoch 63/100
188/188 - 0s - loss: 0.0053
Epoch 64/100
188/188 - 0s - loss: 0.0051
Epoch 65/100
188/188 - 0s - loss: 0.0050
Epoch 66/100
188/188 - 0s - loss: 0.0051
Epoch 67/100
188/188 - 0s - loss: 0.0049
Epoch 68/100
188/188 - 0s - loss: 0.0049
Epoch 69/100
188/188 - 0s - loss: 0.0053
Epoch 70/100
188/188 - 0s - loss: 0.0052
Epoch 71/100
188/188 - 0s - loss: 0.0051
Epoch 72/100
188/188 - 0s - loss: 0.0054
Epoch 73/100
188/188 - 0s - loss: 0.0048
Epoch 74/100
188/188 - 0s - loss: 0.0050
Epoch 75/100
188/188 - 0s - loss: 0.0052
Epoch 76/100
188/188 - 0s - loss: 0.0049
Epoch 77/100
188/188 - 0s - loss: 0.0051
Epoch 78/100
188/188 - 0s - loss: 0.0048
Epoch 79/100
188/188 - 0s - loss: 0.0050
Epoch 80/100
188/188 - 0s - loss: 0.0049
Epoch 81/100
188/188 - 0s - loss: 0.0049
Epoch 82/100
188/188 - 0s - loss: 0.0051
Epoch 83/100
188/188 - 0s - loss: 0.0047
Epoch 84/100
188/188 - 0s - loss: 0.0050
Epoch 85/100
188/188 - 0s - loss: 0.0048
Epoch 86/100
188/188 - 0s - loss: 0.0049
Epoch 87/100
188/188 - 0s - loss: 0.0052
Epoch 88/100
188/188 - 0s - loss: 0.0048
Epoch 89/100
188/188 - 0s - loss: 0.0053
Epoch 90/100
188/188 - 0s - loss: 0.0048
Epoch 91/100
188/188 - 0s - loss: 0.0046
Epoch 92/100
188/188 - 0s - loss: 0.0048
Epoch 93/100
188/188 - 0s - loss: 0.0049
Epoch 94/100
188/188 - 0s - loss: 0.0049
Epoch 95/100
188/188 - 0s - loss: 0.0048
Epoch 96/100
188/188 - 0s - loss: 0.0050
Epoch 97/100
188/188 - 0s - loss: 0.0050
Epoch 98/100
188/188 - 0s - loss: 0.0048
Epoch 99/100
188/188 - 0s - loss: 0.0048
Epoch 100/100
188/188 - 0s - loss: 0.0047

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.144
key_word: bitcoin
window size: 24
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.638889  0.509259  0.518519
2021-07-25  0.518519  0.518519  0.527778  ...  0.398148  0.638889  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.500000  0.398148  0.638889
2021-08-08  0.425926  0.611111  0.518519  ...  0.509259  0.500000  0.398148
2021-08-15  0.500000  0.425926  0.611111  ...  0.509259  0.509259  0.500000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_10 (GRU)                 (None, 4)                 216       
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 5         
=================================================================
Total params: 221
Trainable params: 221
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0907
Epoch 2/100
198/198 - 0s - loss: 0.0045
Epoch 3/100
198/198 - 0s - loss: 0.0044
Epoch 4/100
198/198 - 0s - loss: 0.0044
Epoch 5/100
198/198 - 0s - loss: 0.0044
Epoch 6/100
198/198 - 0s - loss: 0.0043
Epoch 7/100
198/198 - 0s - loss: 0.0042
Epoch 8/100
198/198 - 0s - loss: 0.0042
Epoch 9/100
198/198 - 0s - loss: 0.0040
Epoch 10/100
198/198 - 0s - loss: 0.0041
Epoch 11/100
198/198 - 0s - loss: 0.0039
Epoch 12/100
198/198 - 0s - loss: 0.0039
Epoch 13/100
198/198 - 0s - loss: 0.0040
Epoch 14/100
198/198 - 0s - loss: 0.0039
Epoch 15/100
198/198 - 0s - loss: 0.0039
Epoch 16/100
198/198 - 0s - loss: 0.0038
Epoch 17/100
198/198 - 0s - loss: 0.0036
Epoch 18/100
198/198 - 0s - loss: 0.0037
Epoch 19/100
198/198 - 0s - loss: 0.0037
Epoch 20/100
198/198 - 0s - loss: 0.0037
Epoch 21/100
198/198 - 0s - loss: 0.0037
Epoch 22/100
198/198 - 0s - loss: 0.0036
Epoch 23/100
198/198 - 0s - loss: 0.0036
Epoch 24/100
198/198 - 0s - loss: 0.0036
Epoch 25/100
198/198 - 0s - loss: 0.0038
Epoch 26/100
198/198 - 0s - loss: 0.0035
Epoch 27/100
198/198 - 0s - loss: 0.0036
Epoch 28/100
198/198 - 0s - loss: 0.0036
Epoch 29/100
198/198 - 0s - loss: 0.0036
Epoch 30/100
198/198 - 0s - loss: 0.0036
Epoch 31/100
198/198 - 0s - loss: 0.0035
Epoch 32/100
198/198 - 0s - loss: 0.0034
Epoch 33/100
198/198 - 0s - loss: 0.0039
Epoch 34/100
198/198 - 0s - loss: 0.0035
Epoch 35/100
198/198 - 0s - loss: 0.0035
Epoch 36/100
198/198 - 0s - loss: 0.0034
Epoch 37/100
198/198 - 0s - loss: 0.0035
Epoch 38/100
198/198 - 0s - loss: 0.0036
Epoch 39/100
198/198 - 0s - loss: 0.0035
Epoch 40/100
198/198 - 0s - loss: 0.0034
Epoch 41/100
198/198 - 0s - loss: 0.0034
Epoch 42/100
198/198 - 0s - loss: 0.0036
Epoch 43/100
198/198 - 0s - loss: 0.0034
Epoch 44/100
198/198 - 0s - loss: 0.0035
Epoch 45/100
198/198 - 0s - loss: 0.0035
Epoch 46/100
198/198 - 0s - loss: 0.0035
Epoch 47/100
198/198 - 0s - loss: 0.0037
Epoch 48/100
198/198 - 0s - loss: 0.0034
Epoch 49/100
198/198 - 0s - loss: 0.0034
Epoch 50/100
198/198 - 0s - loss: 0.0034
Epoch 51/100
198/198 - 0s - loss: 0.0035
Epoch 52/100
198/198 - 0s - loss: 0.0034
Epoch 53/100
198/198 - 0s - loss: 0.0034
Epoch 54/100
198/198 - 0s - loss: 0.0033
Epoch 55/100
198/198 - 0s - loss: 0.0034
Epoch 56/100
198/198 - 0s - loss: 0.0034
Epoch 57/100
198/198 - 0s - loss: 0.0035
Epoch 58/100
198/198 - 0s - loss: 0.0035
Epoch 59/100
198/198 - 0s - loss: 0.0034
Epoch 60/100
198/198 - 0s - loss: 0.0034
Epoch 61/100
198/198 - 0s - loss: 0.0035
Epoch 62/100
198/198 - 0s - loss: 0.0034
Epoch 63/100
198/198 - 0s - loss: 0.0034
Epoch 64/100
198/198 - 0s - loss: 0.0033
Epoch 65/100
198/198 - 0s - loss: 0.0035
Epoch 66/100
198/198 - 0s - loss: 0.0034
Epoch 67/100
198/198 - 0s - loss: 0.0033
Epoch 68/100
198/198 - 0s - loss: 0.0034
Epoch 69/100
198/198 - 0s - loss: 0.0033
Epoch 70/100
198/198 - 0s - loss: 0.0033
Epoch 71/100
198/198 - 0s - loss: 0.0034
Epoch 72/100
198/198 - 0s - loss: 0.0035
Epoch 73/100
198/198 - 0s - loss: 0.0034
Epoch 74/100
198/198 - 0s - loss: 0.0033
Epoch 75/100
198/198 - 0s - loss: 0.0034
Epoch 76/100
198/198 - 0s - loss: 0.0033
Epoch 77/100
198/198 - 0s - loss: 0.0034
Epoch 78/100
198/198 - 0s - loss: 0.0033
Epoch 79/100
198/198 - 0s - loss: 0.0034
Epoch 80/100
198/198 - 0s - loss: 0.0033
Epoch 81/100
198/198 - 0s - loss: 0.0033
Epoch 82/100
198/198 - 0s - loss: 0.0033
Epoch 83/100
198/198 - 0s - loss: 0.0034
Epoch 84/100
198/198 - 0s - loss: 0.0033
Epoch 85/100
198/198 - 0s - loss: 0.0033
Epoch 86/100
198/198 - 0s - loss: 0.0035
Epoch 87/100
198/198 - 0s - loss: 0.0033
Epoch 88/100
198/198 - 0s - loss: 0.0033
Epoch 89/100
198/198 - 0s - loss: 0.0033
Epoch 90/100
198/198 - 0s - loss: 0.0032
Epoch 91/100
198/198 - 0s - loss: 0.0034
Epoch 92/100
198/198 - 0s - loss: 0.0032
Epoch 93/100
198/198 - 0s - loss: 0.0033
Epoch 94/100
198/198 - 0s - loss: 0.0032
Epoch 95/100
198/198 - 0s - loss: 0.0033
Epoch 96/100
198/198 - 0s - loss: 0.0034
Epoch 97/100
198/198 - 0s - loss: 0.0033
Epoch 98/100
198/198 - 0s - loss: 0.0033
Epoch 99/100
198/198 - 0s - loss: 0.0033
Epoch 100/100
198/198 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.055
Train RMSE: 0.100
key_word: COVID-19
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.638889  0.509259  0.518519
2021-07-25  0.518519  0.518519  0.527778  ...  0.398148  0.638889  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.500000  0.398148  0.638889
2021-08-08  0.425926  0.611111  0.518519  ...  0.509259  0.500000  0.398148
2021-08-15  0.500000  0.425926  0.611111  ...  0.509259  0.509259  0.500000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_11 (GRU)                 (None, 8)                 528       
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 9         
=================================================================
Total params: 537
Trainable params: 537
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0101
Epoch 2/100
198/198 - 0s - loss: 0.0037
Epoch 3/100
198/198 - 0s - loss: 0.0037
Epoch 4/100
198/198 - 0s - loss: 0.0039
Epoch 5/100
198/198 - 0s - loss: 0.0037
Epoch 6/100
198/198 - 0s - loss: 0.0037
Epoch 7/100
198/198 - 0s - loss: 0.0038
Epoch 8/100
198/198 - 0s - loss: 0.0036
Epoch 9/100
198/198 - 0s - loss: 0.0037
Epoch 10/100
198/198 - 0s - loss: 0.0036
Epoch 11/100
198/198 - 0s - loss: 0.0039
Epoch 12/100
198/198 - 0s - loss: 0.0037
Epoch 13/100
198/198 - 0s - loss: 0.0040
Epoch 14/100
198/198 - 0s - loss: 0.0038
Epoch 15/100
198/198 - 0s - loss: 0.0035
Epoch 16/100
198/198 - 0s - loss: 0.0039
Epoch 17/100
198/198 - 0s - loss: 0.0035
Epoch 18/100
198/198 - 0s - loss: 0.0038
Epoch 19/100
198/198 - 0s - loss: 0.0037
Epoch 20/100
198/198 - 0s - loss: 0.0036
Epoch 21/100
198/198 - 0s - loss: 0.0038
Epoch 22/100
198/198 - 0s - loss: 0.0034
Epoch 23/100
198/198 - 0s - loss: 0.0036
Epoch 24/100
198/198 - 0s - loss: 0.0036
Epoch 25/100
198/198 - 0s - loss: 0.0036
Epoch 26/100
198/198 - 0s - loss: 0.0035
Epoch 27/100
198/198 - 0s - loss: 0.0036
Epoch 28/100
198/198 - 0s - loss: 0.0035
Epoch 29/100
198/198 - 0s - loss: 0.0035
Epoch 30/100
198/198 - 0s - loss: 0.0036
Epoch 31/100
198/198 - 0s - loss: 0.0035
Epoch 32/100
198/198 - 0s - loss: 0.0034
Epoch 33/100
198/198 - 0s - loss: 0.0035
Epoch 34/100
198/198 - 0s - loss: 0.0037
Epoch 35/100
198/198 - 0s - loss: 0.0035
Epoch 36/100
198/198 - 0s - loss: 0.0036
Epoch 37/100
198/198 - 0s - loss: 0.0036
Epoch 38/100
198/198 - 0s - loss: 0.0035
Epoch 39/100
198/198 - 0s - loss: 0.0035
Epoch 40/100
198/198 - 0s - loss: 0.0035
Epoch 41/100
198/198 - 0s - loss: 0.0037
Epoch 42/100
198/198 - 0s - loss: 0.0035
Epoch 43/100
198/198 - 0s - loss: 0.0036
Epoch 44/100
198/198 - 0s - loss: 0.0034
Epoch 45/100
198/198 - 0s - loss: 0.0036
Epoch 46/100
198/198 - 0s - loss: 0.0035
Epoch 47/100
198/198 - 0s - loss: 0.0034
Epoch 48/100
198/198 - 0s - loss: 0.0034
Epoch 49/100
198/198 - 0s - loss: 0.0035
Epoch 50/100
198/198 - 0s - loss: 0.0034
Epoch 51/100
198/198 - 0s - loss: 0.0034
Epoch 52/100
198/198 - 0s - loss: 0.0034
Epoch 53/100
198/198 - 0s - loss: 0.0034
Epoch 54/100
198/198 - 0s - loss: 0.0034
Epoch 55/100
198/198 - 0s - loss: 0.0035
Epoch 56/100
198/198 - 0s - loss: 0.0034
Epoch 57/100
198/198 - 0s - loss: 0.0035
Epoch 58/100
198/198 - 0s - loss: 0.0035
Epoch 59/100
198/198 - 0s - loss: 0.0034
Epoch 60/100
198/198 - 0s - loss: 0.0035
Epoch 61/100
198/198 - 0s - loss: 0.0034
Epoch 62/100
198/198 - 0s - loss: 0.0035
Epoch 63/100
198/198 - 0s - loss: 0.0035
Epoch 64/100
198/198 - 0s - loss: 0.0034
Epoch 65/100
198/198 - 0s - loss: 0.0034
Epoch 66/100
198/198 - 0s - loss: 0.0033
Epoch 67/100
198/198 - 0s - loss: 0.0034
Epoch 68/100
198/198 - 0s - loss: 0.0035
Epoch 69/100
198/198 - 0s - loss: 0.0034
Epoch 70/100
198/198 - 0s - loss: 0.0034
Epoch 71/100
198/198 - 0s - loss: 0.0034
Epoch 72/100
198/198 - 0s - loss: 0.0034
Epoch 73/100
198/198 - 0s - loss: 0.0035
Epoch 74/100
198/198 - 0s - loss: 0.0034
Epoch 75/100
198/198 - 0s - loss: 0.0034
Epoch 76/100
198/198 - 0s - loss: 0.0033
Epoch 77/100
198/198 - 0s - loss: 0.0037
Epoch 78/100
198/198 - 0s - loss: 0.0033
Epoch 79/100
198/198 - 0s - loss: 0.0033
Epoch 80/100
198/198 - 0s - loss: 0.0034
Epoch 81/100
198/198 - 0s - loss: 0.0033
Epoch 82/100
198/198 - 0s - loss: 0.0035
Epoch 83/100
198/198 - 0s - loss: 0.0033
Epoch 84/100
198/198 - 0s - loss: 0.0033
Epoch 85/100
198/198 - 0s - loss: 0.0034
Epoch 86/100
198/198 - 0s - loss: 0.0034
Epoch 87/100
198/198 - 0s - loss: 0.0033
Epoch 88/100
198/198 - 0s - loss: 0.0034
Epoch 89/100
198/198 - 0s - loss: 0.0033
Epoch 90/100
198/198 - 0s - loss: 0.0033
Epoch 91/100
198/198 - 0s - loss: 0.0032
Epoch 92/100
198/198 - 0s - loss: 0.0034
Epoch 93/100
198/198 - 0s - loss: 0.0033
Epoch 94/100
198/198 - 0s - loss: 0.0033
Epoch 95/100
198/198 - 0s - loss: 0.0033
Epoch 96/100
198/198 - 0s - loss: 0.0032
Epoch 97/100
198/198 - 0s - loss: 0.0034
Epoch 98/100
198/198 - 0s - loss: 0.0032
Epoch 99/100
198/198 - 0s - loss: 0.0034
Epoch 100/100
198/198 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.056
Train RMSE: 0.088
key_word: COVID-19
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.638889  0.509259  0.518519
2021-07-25  0.518519  0.518519  0.527778  ...  0.398148  0.638889  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.500000  0.398148  0.638889
2021-08-08  0.425926  0.611111  0.518519  ...  0.509259  0.500000  0.398148
2021-08-15  0.500000  0.425926  0.611111  ...  0.509259  0.509259  0.500000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_12 (GRU)                 (None, 16)                1440      
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 17        
=================================================================
Total params: 1,457
Trainable params: 1,457
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0477
Epoch 2/100
198/198 - 0s - loss: 0.0037
Epoch 3/100
198/198 - 0s - loss: 0.0038
Epoch 4/100
198/198 - 0s - loss: 0.0039
Epoch 5/100
198/198 - 0s - loss: 0.0040
Epoch 6/100
198/198 - 0s - loss: 0.0039
Epoch 7/100
198/198 - 0s - loss: 0.0037
Epoch 8/100
198/198 - 0s - loss: 0.0038
Epoch 9/100
198/198 - 0s - loss: 0.0037
Epoch 10/100
198/198 - 0s - loss: 0.0038
Epoch 11/100
198/198 - 0s - loss: 0.0040
Epoch 12/100
198/198 - 0s - loss: 0.0039
Epoch 13/100
198/198 - 0s - loss: 0.0037
Epoch 14/100
198/198 - 0s - loss: 0.0037
Epoch 15/100
198/198 - 0s - loss: 0.0038
Epoch 16/100
198/198 - 0s - loss: 0.0039
Epoch 17/100
198/198 - 0s - loss: 0.0039
Epoch 18/100
198/198 - 0s - loss: 0.0038
Epoch 19/100
198/198 - 0s - loss: 0.0039
Epoch 20/100
198/198 - 0s - loss: 0.0036
Epoch 21/100
198/198 - 0s - loss: 0.0038
Epoch 22/100
198/198 - 0s - loss: 0.0036
Epoch 23/100
198/198 - 0s - loss: 0.0036
Epoch 24/100
198/198 - 0s - loss: 0.0039
Epoch 25/100
198/198 - 0s - loss: 0.0037
Epoch 26/100
198/198 - 0s - loss: 0.0036
Epoch 27/100
198/198 - 0s - loss: 0.0037
Epoch 28/100
198/198 - 0s - loss: 0.0037
Epoch 29/100
198/198 - 0s - loss: 0.0036
Epoch 30/100
198/198 - 0s - loss: 0.0037
Epoch 31/100
198/198 - 0s - loss: 0.0038
Epoch 32/100
198/198 - 0s - loss: 0.0036
Epoch 33/100
198/198 - 0s - loss: 0.0037
Epoch 34/100
198/198 - 0s - loss: 0.0035
Epoch 35/100
198/198 - 0s - loss: 0.0037
Epoch 36/100
198/198 - 0s - loss: 0.0036
Epoch 37/100
198/198 - 0s - loss: 0.0037
Epoch 38/100
198/198 - 0s - loss: 0.0034
Epoch 39/100
198/198 - 0s - loss: 0.0037
Epoch 40/100
198/198 - 0s - loss: 0.0037
Epoch 41/100
198/198 - 0s - loss: 0.0036
Epoch 42/100
198/198 - 0s - loss: 0.0036
Epoch 43/100
198/198 - 0s - loss: 0.0035
Epoch 44/100
198/198 - 0s - loss: 0.0036
Epoch 45/100
198/198 - 0s - loss: 0.0034
Epoch 46/100
198/198 - 0s - loss: 0.0036
Epoch 47/100
198/198 - 0s - loss: 0.0035
Epoch 48/100
198/198 - 0s - loss: 0.0034
Epoch 49/100
198/198 - 0s - loss: 0.0034
Epoch 50/100
198/198 - 0s - loss: 0.0035
Epoch 51/100
198/198 - 0s - loss: 0.0035
Epoch 52/100
198/198 - 0s - loss: 0.0035
Epoch 53/100
198/198 - 0s - loss: 0.0036
Epoch 54/100
198/198 - 0s - loss: 0.0035
Epoch 55/100
198/198 - 0s - loss: 0.0034
Epoch 56/100
198/198 - 0s - loss: 0.0034
Epoch 57/100
198/198 - 0s - loss: 0.0035
Epoch 58/100
198/198 - 0s - loss: 0.0035
Epoch 59/100
198/198 - 0s - loss: 0.0035
Epoch 60/100
198/198 - 0s - loss: 0.0034
Epoch 61/100
198/198 - 0s - loss: 0.0034
Epoch 62/100
198/198 - 0s - loss: 0.0033
Epoch 63/100
198/198 - 0s - loss: 0.0035
Epoch 64/100
198/198 - 0s - loss: 0.0035
Epoch 65/100
198/198 - 0s - loss: 0.0034
Epoch 66/100
198/198 - 0s - loss: 0.0035
Epoch 67/100
198/198 - 0s - loss: 0.0035
Epoch 68/100
198/198 - 0s - loss: 0.0034
Epoch 69/100
198/198 - 0s - loss: 0.0034
Epoch 70/100
198/198 - 0s - loss: 0.0035
Epoch 71/100
198/198 - 0s - loss: 0.0034
Epoch 72/100
198/198 - 0s - loss: 0.0035
Epoch 73/100
198/198 - 0s - loss: 0.0034
Epoch 74/100
198/198 - 0s - loss: 0.0033
Epoch 75/100
198/198 - 0s - loss: 0.0035
Epoch 76/100
198/198 - 0s - loss: 0.0034
Epoch 77/100
198/198 - 0s - loss: 0.0033
Epoch 78/100
198/198 - 0s - loss: 0.0035
Epoch 79/100
198/198 - 0s - loss: 0.0034
Epoch 80/100
198/198 - 0s - loss: 0.0034
Epoch 81/100
198/198 - 0s - loss: 0.0035
Epoch 82/100
198/198 - 0s - loss: 0.0034
Epoch 83/100
198/198 - 0s - loss: 0.0034
Epoch 84/100
198/198 - 0s - loss: 0.0034
Epoch 85/100
198/198 - 0s - loss: 0.0035
Epoch 86/100
198/198 - 0s - loss: 0.0034
Epoch 87/100
198/198 - 0s - loss: 0.0034
Epoch 88/100
198/198 - 0s - loss: 0.0036
Epoch 89/100
198/198 - 0s - loss: 0.0035
Epoch 90/100
198/198 - 0s - loss: 0.0033
Epoch 91/100
198/198 - 0s - loss: 0.0032
Epoch 92/100
198/198 - 0s - loss: 0.0033
Epoch 93/100
198/198 - 0s - loss: 0.0035
Epoch 94/100
198/198 - 0s - loss: 0.0034
Epoch 95/100
198/198 - 0s - loss: 0.0033
Epoch 96/100
198/198 - 0s - loss: 0.0034
Epoch 97/100
198/198 - 0s - loss: 0.0034
Epoch 98/100
198/198 - 0s - loss: 0.0033
Epoch 99/100
198/198 - 0s - loss: 0.0034
Epoch 100/100
198/198 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.056
Train RMSE: 0.088
key_word: COVID-19
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.638889  0.509259  0.518519
2021-07-25  0.518519  0.518519  0.527778  ...  0.398148  0.638889  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.500000  0.398148  0.638889
2021-08-08  0.425926  0.611111  0.518519  ...  0.509259  0.500000  0.398148
2021-08-15  0.500000  0.425926  0.611111  ...  0.509259  0.509259  0.500000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_13 (GRU)                 (None, 32)                4416      
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 33        
=================================================================
Total params: 4,449
Trainable params: 4,449
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0066
Epoch 2/100
198/198 - 0s - loss: 0.0043
Epoch 3/100
198/198 - 0s - loss: 0.0044
Epoch 4/100
198/198 - 0s - loss: 0.0043
Epoch 5/100
198/198 - 0s - loss: 0.0041
Epoch 6/100
198/198 - 0s - loss: 0.0040
Epoch 7/100
198/198 - 0s - loss: 0.0045
Epoch 8/100
198/198 - 0s - loss: 0.0044
Epoch 9/100
198/198 - 0s - loss: 0.0042
Epoch 10/100
198/198 - 0s - loss: 0.0039
Epoch 11/100
198/198 - 0s - loss: 0.0041
Epoch 12/100
198/198 - 0s - loss: 0.0039
Epoch 13/100
198/198 - 0s - loss: 0.0039
Epoch 14/100
198/198 - 0s - loss: 0.0039
Epoch 15/100
198/198 - 0s - loss: 0.0039
Epoch 16/100
198/198 - 0s - loss: 0.0040
Epoch 17/100
198/198 - 0s - loss: 0.0037
Epoch 18/100
198/198 - 0s - loss: 0.0037
Epoch 19/100
198/198 - 0s - loss: 0.0038
Epoch 20/100
198/198 - 0s - loss: 0.0037
Epoch 21/100
198/198 - 0s - loss: 0.0040
Epoch 22/100
198/198 - 0s - loss: 0.0037
Epoch 23/100
198/198 - 0s - loss: 0.0039
Epoch 24/100
198/198 - 0s - loss: 0.0036
Epoch 25/100
198/198 - 0s - loss: 0.0037
Epoch 26/100
198/198 - 0s - loss: 0.0037
Epoch 27/100
198/198 - 0s - loss: 0.0036
Epoch 28/100
198/198 - 0s - loss: 0.0037
Epoch 29/100
198/198 - 0s - loss: 0.0035
Epoch 30/100
198/198 - 0s - loss: 0.0036
Epoch 31/100
198/198 - 0s - loss: 0.0034
Epoch 32/100
198/198 - 0s - loss: 0.0037
Epoch 33/100
198/198 - 0s - loss: 0.0036
Epoch 34/100
198/198 - 0s - loss: 0.0037
Epoch 35/100
198/198 - 0s - loss: 0.0035
Epoch 36/100
198/198 - 0s - loss: 0.0036
Epoch 37/100
198/198 - 0s - loss: 0.0035
Epoch 38/100
198/198 - 0s - loss: 0.0037
Epoch 39/100
198/198 - 0s - loss: 0.0034
Epoch 40/100
198/198 - 0s - loss: 0.0034
Epoch 41/100
198/198 - 0s - loss: 0.0035
Epoch 42/100
198/198 - 0s - loss: 0.0038
Epoch 43/100
198/198 - 0s - loss: 0.0035
Epoch 44/100
198/198 - 0s - loss: 0.0035
Epoch 45/100
198/198 - 0s - loss: 0.0035
Epoch 46/100
198/198 - 0s - loss: 0.0034
Epoch 47/100
198/198 - 0s - loss: 0.0036
Epoch 48/100
198/198 - 0s - loss: 0.0035
Epoch 49/100
198/198 - 0s - loss: 0.0035
Epoch 50/100
198/198 - 0s - loss: 0.0033
Epoch 51/100
198/198 - 0s - loss: 0.0035
Epoch 52/100
198/198 - 0s - loss: 0.0033
Epoch 53/100
198/198 - 0s - loss: 0.0033
Epoch 54/100
198/198 - 0s - loss: 0.0035
Epoch 55/100
198/198 - 0s - loss: 0.0035
Epoch 56/100
198/198 - 0s - loss: 0.0036
Epoch 57/100
198/198 - 0s - loss: 0.0035
Epoch 58/100
198/198 - 0s - loss: 0.0033
Epoch 59/100
198/198 - 0s - loss: 0.0037
Epoch 60/100
198/198 - 0s - loss: 0.0036
Epoch 61/100
198/198 - 0s - loss: 0.0034
Epoch 62/100
198/198 - 0s - loss: 0.0035
Epoch 63/100
198/198 - 0s - loss: 0.0034
Epoch 64/100
198/198 - 0s - loss: 0.0034
Epoch 65/100
198/198 - 0s - loss: 0.0034
Epoch 66/100
198/198 - 0s - loss: 0.0035
Epoch 67/100
198/198 - 0s - loss: 0.0033
Epoch 68/100
198/198 - 0s - loss: 0.0035
Epoch 69/100
198/198 - 0s - loss: 0.0034
Epoch 70/100
198/198 - 0s - loss: 0.0033
Epoch 71/100
198/198 - 0s - loss: 0.0035
Epoch 72/100
198/198 - 0s - loss: 0.0033
Epoch 73/100
198/198 - 0s - loss: 0.0034
Epoch 74/100
198/198 - 0s - loss: 0.0034
Epoch 75/100
198/198 - 0s - loss: 0.0033
Epoch 76/100
198/198 - 0s - loss: 0.0034
Epoch 77/100
198/198 - 0s - loss: 0.0034
Epoch 78/100
198/198 - 0s - loss: 0.0033
Epoch 79/100
198/198 - 0s - loss: 0.0036
Epoch 80/100
198/198 - 0s - loss: 0.0034
Epoch 81/100
198/198 - 0s - loss: 0.0034
Epoch 82/100
198/198 - 0s - loss: 0.0034
Epoch 83/100
198/198 - 0s - loss: 0.0033
Epoch 84/100
198/198 - 0s - loss: 0.0034
Epoch 85/100
198/198 - 0s - loss: 0.0033
Epoch 86/100
198/198 - 0s - loss: 0.0035
Epoch 87/100
198/198 - 0s - loss: 0.0034
Epoch 88/100
198/198 - 0s - loss: 0.0034
Epoch 89/100
198/198 - 0s - loss: 0.0033
Epoch 90/100
198/198 - 0s - loss: 0.0035
Epoch 91/100
198/198 - 0s - loss: 0.0033
Epoch 92/100
198/198 - 0s - loss: 0.0033
Epoch 93/100
198/198 - 0s - loss: 0.0033
Epoch 94/100
198/198 - 0s - loss: 0.0035
Epoch 95/100
198/198 - 0s - loss: 0.0033
Epoch 96/100
198/198 - 0s - loss: 0.0033
Epoch 97/100
198/198 - 0s - loss: 0.0034
Epoch 98/100
198/198 - 0s - loss: 0.0033
Epoch 99/100
198/198 - 0s - loss: 0.0032
Epoch 100/100
198/198 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.061
Train RMSE: 0.092
key_word: COVID-19
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.638889  0.509259  0.518519
2021-07-25  0.518519  0.518519  0.527778  ...  0.398148  0.638889  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.500000  0.398148  0.638889
2021-08-08  0.425926  0.611111  0.518519  ...  0.509259  0.500000  0.398148
2021-08-15  0.500000  0.425926  0.611111  ...  0.509259  0.509259  0.500000

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_14 (GRU)                 (None, 60)                13320     
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 61        
=================================================================
Total params: 13,381
Trainable params: 13,381
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0094
Epoch 2/100
198/198 - 0s - loss: 0.0047
Epoch 3/100
198/198 - 0s - loss: 0.0044
Epoch 4/100
198/198 - 0s - loss: 0.0043
Epoch 5/100
198/198 - 0s - loss: 0.0044
Epoch 6/100
198/198 - 0s - loss: 0.0044
Epoch 7/100
198/198 - 0s - loss: 0.0044
Epoch 8/100
198/198 - 0s - loss: 0.0040
Epoch 9/100
198/198 - 0s - loss: 0.0046
Epoch 10/100
198/198 - 0s - loss: 0.0041
Epoch 11/100
198/198 - 0s - loss: 0.0041
Epoch 12/100
198/198 - 0s - loss: 0.0038
Epoch 13/100
198/198 - 0s - loss: 0.0042
Epoch 14/100
198/198 - 0s - loss: 0.0040
Epoch 15/100
198/198 - 0s - loss: 0.0041
Epoch 16/100
198/198 - 0s - loss: 0.0038
Epoch 17/100
198/198 - 0s - loss: 0.0040
Epoch 18/100
198/198 - 0s - loss: 0.0039
Epoch 19/100
198/198 - 0s - loss: 0.0041
Epoch 20/100
198/198 - 0s - loss: 0.0040
Epoch 21/100
198/198 - 0s - loss: 0.0040
Epoch 22/100
198/198 - 0s - loss: 0.0039
Epoch 23/100
198/198 - 0s - loss: 0.0035
Epoch 24/100
198/198 - 0s - loss: 0.0038
Epoch 25/100
198/198 - 0s - loss: 0.0037
Epoch 26/100
198/198 - 0s - loss: 0.0039
Epoch 27/100
198/198 - 0s - loss: 0.0042
Epoch 28/100
198/198 - 0s - loss: 0.0036
Epoch 29/100
198/198 - 0s - loss: 0.0040
Epoch 30/100
198/198 - 0s - loss: 0.0038
Epoch 31/100
198/198 - 0s - loss: 0.0034
Epoch 32/100
198/198 - 0s - loss: 0.0040
Epoch 33/100
198/198 - 0s - loss: 0.0037
Epoch 34/100
198/198 - 0s - loss: 0.0036
Epoch 35/100
198/198 - 0s - loss: 0.0036
Epoch 36/100
198/198 - 0s - loss: 0.0038
Epoch 37/100
198/198 - 0s - loss: 0.0036
Epoch 38/100
198/198 - 0s - loss: 0.0037
Epoch 39/100
198/198 - 0s - loss: 0.0038
Epoch 40/100
198/198 - 0s - loss: 0.0039
Epoch 41/100
198/198 - 0s - loss: 0.0038
Epoch 42/100
198/198 - 0s - loss: 0.0037
Epoch 43/100
198/198 - 0s - loss: 0.0034
Epoch 44/100
198/198 - 0s - loss: 0.0036
Epoch 45/100
198/198 - 0s - loss: 0.0036
Epoch 46/100
198/198 - 0s - loss: 0.0036
Epoch 47/100
198/198 - 0s - loss: 0.0034
Epoch 48/100
198/198 - 0s - loss: 0.0034
Epoch 49/100
198/198 - 0s - loss: 0.0039
Epoch 50/100
198/198 - 0s - loss: 0.0035
Epoch 51/100
198/198 - 0s - loss: 0.0037
Epoch 52/100
198/198 - 0s - loss: 0.0034
Epoch 53/100
198/198 - 0s - loss: 0.0038
Epoch 54/100
198/198 - 0s - loss: 0.0033
Epoch 55/100
198/198 - 0s - loss: 0.0037
Epoch 56/100
198/198 - 0s - loss: 0.0035
Epoch 57/100
198/198 - 0s - loss: 0.0033
Epoch 58/100
198/198 - 0s - loss: 0.0035
Epoch 59/100
198/198 - 0s - loss: 0.0036
Epoch 60/100
198/198 - 0s - loss: 0.0034
Epoch 61/100
198/198 - 0s - loss: 0.0037
Epoch 62/100
198/198 - 0s - loss: 0.0036
Epoch 63/100
198/198 - 0s - loss: 0.0035
Epoch 64/100
198/198 - 0s - loss: 0.0035
Epoch 65/100
198/198 - 0s - loss: 0.0035
Epoch 66/100
198/198 - 0s - loss: 0.0035
Epoch 67/100
198/198 - 0s - loss: 0.0034
Epoch 68/100
198/198 - 0s - loss: 0.0036
Epoch 69/100
198/198 - 0s - loss: 0.0035
Epoch 70/100
198/198 - 0s - loss: 0.0034
Epoch 71/100
198/198 - 0s - loss: 0.0035
Epoch 72/100
198/198 - 0s - loss: 0.0033
Epoch 73/100
198/198 - 0s - loss: 0.0034
Epoch 74/100
198/198 - 0s - loss: 0.0033
Epoch 75/100
198/198 - 0s - loss: 0.0033
Epoch 76/100
198/198 - 0s - loss: 0.0034
Epoch 77/100
198/198 - 0s - loss: 0.0034
Epoch 78/100
198/198 - 0s - loss: 0.0033
Epoch 79/100
198/198 - 0s - loss: 0.0036
Epoch 80/100
198/198 - 0s - loss: 0.0033
Epoch 81/100
198/198 - 0s - loss: 0.0034
Epoch 82/100
198/198 - 0s - loss: 0.0034
Epoch 83/100
198/198 - 0s - loss: 0.0034
Epoch 84/100
198/198 - 0s - loss: 0.0033
Epoch 85/100
198/198 - 0s - loss: 0.0034
Epoch 86/100
198/198 - 0s - loss: 0.0035
Epoch 87/100
198/198 - 0s - loss: 0.0034
Epoch 88/100
198/198 - 0s - loss: 0.0034
Epoch 89/100
198/198 - 0s - loss: 0.0034
Epoch 90/100
198/198 - 0s - loss: 0.0033
Epoch 91/100
198/198 - 0s - loss: 0.0034
Epoch 92/100
198/198 - 0s - loss: 0.0034
Epoch 93/100
198/198 - 0s - loss: 0.0034
Epoch 94/100
198/198 - 0s - loss: 0.0033
Epoch 95/100
198/198 - 0s - loss: 0.0034
Epoch 96/100
198/198 - 0s - loss: 0.0033
Epoch 97/100
198/198 - 0s - loss: 0.0033
Epoch 98/100
198/198 - 0s - loss: 0.0033
Epoch 99/100
198/198 - 0s - loss: 0.0034
Epoch 100/100
198/198 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.056
Train RMSE: 0.087
key_word: COVID-19
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.518519  0.509259  0.527778
2021-07-25  0.518519  0.518519  0.527778  ...  0.518519  0.518519  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.527778  0.518519  0.518519
2021-08-08  0.425926  0.611111  0.518519  ...  0.527778  0.527778  0.518519
2021-08-15  0.500000  0.425926  0.611111  ...  0.518519  0.527778  0.527778

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_15 (GRU)                 (None, 4)                 360       
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 5         
=================================================================
Total params: 365
Trainable params: 365
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0992
Epoch 2/100
188/188 - 0s - loss: 0.0040
Epoch 3/100
188/188 - 0s - loss: 0.0041
Epoch 4/100
188/188 - 0s - loss: 0.0042
Epoch 5/100
188/188 - 0s - loss: 0.0042
Epoch 6/100
188/188 - 0s - loss: 0.0040
Epoch 7/100
188/188 - 0s - loss: 0.0040
Epoch 8/100
188/188 - 0s - loss: 0.0040
Epoch 9/100
188/188 - 0s - loss: 0.0039
Epoch 10/100
188/188 - 0s - loss: 0.0041
Epoch 11/100
188/188 - 0s - loss: 0.0040
Epoch 12/100
188/188 - 0s - loss: 0.0040
Epoch 13/100
188/188 - 0s - loss: 0.0040
Epoch 14/100
188/188 - 0s - loss: 0.0039
Epoch 15/100
188/188 - 0s - loss: 0.0038
Epoch 16/100
188/188 - 0s - loss: 0.0038
Epoch 17/100
188/188 - 0s - loss: 0.0038
Epoch 18/100
188/188 - 0s - loss: 0.0038
Epoch 19/100
188/188 - 0s - loss: 0.0037
Epoch 20/100
188/188 - 0s - loss: 0.0037
Epoch 21/100
188/188 - 0s - loss: 0.0037
Epoch 22/100
188/188 - 0s - loss: 0.0037
Epoch 23/100
188/188 - 0s - loss: 0.0036
Epoch 24/100
188/188 - 0s - loss: 0.0036
Epoch 25/100
188/188 - 0s - loss: 0.0037
Epoch 26/100
188/188 - 0s - loss: 0.0037
Epoch 27/100
188/188 - 0s - loss: 0.0036
Epoch 28/100
188/188 - 0s - loss: 0.0036
Epoch 29/100
188/188 - 0s - loss: 0.0036
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0037
Epoch 32/100
188/188 - 0s - loss: 0.0036
Epoch 33/100
188/188 - 0s - loss: 0.0036
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0036
Epoch 36/100
188/188 - 0s - loss: 0.0036
Epoch 37/100
188/188 - 0s - loss: 0.0036
Epoch 38/100
188/188 - 0s - loss: 0.0036
Epoch 39/100
188/188 - 0s - loss: 0.0037
Epoch 40/100
188/188 - 0s - loss: 0.0034
Epoch 41/100
188/188 - 0s - loss: 0.0037
Epoch 42/100
188/188 - 0s - loss: 0.0035
Epoch 43/100
188/188 - 0s - loss: 0.0035
Epoch 44/100
188/188 - 0s - loss: 0.0034
Epoch 45/100
188/188 - 0s - loss: 0.0035
Epoch 46/100
188/188 - 0s - loss: 0.0035
Epoch 47/100
188/188 - 0s - loss: 0.0035
Epoch 48/100
188/188 - 0s - loss: 0.0036
Epoch 49/100
188/188 - 0s - loss: 0.0035
Epoch 50/100
188/188 - 0s - loss: 0.0034
Epoch 51/100
188/188 - 0s - loss: 0.0035
Epoch 52/100
188/188 - 0s - loss: 0.0034
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0034
Epoch 55/100
188/188 - 0s - loss: 0.0034
Epoch 56/100
188/188 - 0s - loss: 0.0034
Epoch 57/100
188/188 - 0s - loss: 0.0033
Epoch 58/100
188/188 - 0s - loss: 0.0034
Epoch 59/100
188/188 - 0s - loss: 0.0034
Epoch 60/100
188/188 - 0s - loss: 0.0035
Epoch 61/100
188/188 - 0s - loss: 0.0033
Epoch 62/100
188/188 - 0s - loss: 0.0035
Epoch 63/100
188/188 - 0s - loss: 0.0034
Epoch 64/100
188/188 - 0s - loss: 0.0033
Epoch 65/100
188/188 - 0s - loss: 0.0033
Epoch 66/100
188/188 - 0s - loss: 0.0034
Epoch 67/100
188/188 - 0s - loss: 0.0033
Epoch 68/100
188/188 - 0s - loss: 0.0033
Epoch 69/100
188/188 - 0s - loss: 0.0035
Epoch 70/100
188/188 - 0s - loss: 0.0033
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0033
Epoch 73/100
188/188 - 0s - loss: 0.0033
Epoch 74/100
188/188 - 0s - loss: 0.0033
Epoch 75/100
188/188 - 0s - loss: 0.0035
Epoch 76/100
188/188 - 0s - loss: 0.0033
Epoch 77/100
188/188 - 0s - loss: 0.0034
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0034
Epoch 80/100
188/188 - 0s - loss: 0.0033
Epoch 81/100
188/188 - 0s - loss: 0.0032
Epoch 82/100
188/188 - 0s - loss: 0.0032
Epoch 83/100
188/188 - 0s - loss: 0.0032
Epoch 84/100
188/188 - 0s - loss: 0.0033
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0033
Epoch 87/100
188/188 - 0s - loss: 0.0032
Epoch 88/100
188/188 - 0s - loss: 0.0031
Epoch 89/100
188/188 - 0s - loss: 0.0032
Epoch 90/100
188/188 - 0s - loss: 0.0032
Epoch 91/100
188/188 - 0s - loss: 0.0032
Epoch 92/100
188/188 - 0s - loss: 0.0032
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0031
Epoch 96/100
188/188 - 0s - loss: 0.0034
Epoch 97/100
188/188 - 0s - loss: 0.0032
Epoch 98/100
188/188 - 0s - loss: 0.0032
Epoch 99/100
188/188 - 0s - loss: 0.0030
Epoch 100/100
188/188 - 0s - loss: 0.0031

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.054
Train RMSE: 0.101
key_word: COVID-19
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.518519  0.509259  0.527778
2021-07-25  0.518519  0.518519  0.527778  ...  0.518519  0.518519  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.527778  0.518519  0.518519
2021-08-08  0.425926  0.611111  0.518519  ...  0.527778  0.527778  0.518519
2021-08-15  0.500000  0.425926  0.611111  ...  0.518519  0.527778  0.527778

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_16 (GRU)                 (None, 8)                 816       
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 9         
=================================================================
Total params: 825
Trainable params: 825
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0049
Epoch 2/100
188/188 - 0s - loss: 0.0044
Epoch 3/100
188/188 - 0s - loss: 0.0045
Epoch 4/100
188/188 - 0s - loss: 0.0043
Epoch 5/100
188/188 - 0s - loss: 0.0042
Epoch 6/100
188/188 - 0s - loss: 0.0043
Epoch 7/100
188/188 - 0s - loss: 0.0041
Epoch 8/100
188/188 - 0s - loss: 0.0041
Epoch 9/100
188/188 - 0s - loss: 0.0041
Epoch 10/100
188/188 - 0s - loss: 0.0040
Epoch 11/100
188/188 - 0s - loss: 0.0038
Epoch 12/100
188/188 - 0s - loss: 0.0040
Epoch 13/100
188/188 - 0s - loss: 0.0041
Epoch 14/100
188/188 - 0s - loss: 0.0040
Epoch 15/100
188/188 - 0s - loss: 0.0037
Epoch 16/100
188/188 - 0s - loss: 0.0039
Epoch 17/100
188/188 - 0s - loss: 0.0039
Epoch 18/100
188/188 - 0s - loss: 0.0040
Epoch 19/100
188/188 - 0s - loss: 0.0039
Epoch 20/100
188/188 - 0s - loss: 0.0038
Epoch 21/100
188/188 - 0s - loss: 0.0040
Epoch 22/100
188/188 - 0s - loss: 0.0038
Epoch 23/100
188/188 - 0s - loss: 0.0038
Epoch 24/100
188/188 - 0s - loss: 0.0040
Epoch 25/100
188/188 - 0s - loss: 0.0037
Epoch 26/100
188/188 - 0s - loss: 0.0038
Epoch 27/100
188/188 - 0s - loss: 0.0037
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0037
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0037
Epoch 32/100
188/188 - 0s - loss: 0.0036
Epoch 33/100
188/188 - 0s - loss: 0.0038
Epoch 34/100
188/188 - 0s - loss: 0.0037
Epoch 35/100
188/188 - 0s - loss: 0.0040
Epoch 36/100
188/188 - 0s - loss: 0.0039
Epoch 37/100
188/188 - 0s - loss: 0.0036
Epoch 38/100
188/188 - 0s - loss: 0.0037
Epoch 39/100
188/188 - 0s - loss: 0.0037
Epoch 40/100
188/188 - 0s - loss: 0.0037
Epoch 41/100
188/188 - 0s - loss: 0.0036
Epoch 42/100
188/188 - 0s - loss: 0.0037
Epoch 43/100
188/188 - 0s - loss: 0.0036
Epoch 44/100
188/188 - 0s - loss: 0.0036
Epoch 45/100
188/188 - 0s - loss: 0.0037
Epoch 46/100
188/188 - 0s - loss: 0.0036
Epoch 47/100
188/188 - 0s - loss: 0.0035
Epoch 48/100
188/188 - 0s - loss: 0.0035
Epoch 49/100
188/188 - 0s - loss: 0.0036
Epoch 50/100
188/188 - 0s - loss: 0.0035
Epoch 51/100
188/188 - 0s - loss: 0.0037
Epoch 52/100
188/188 - 0s - loss: 0.0035
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0035
Epoch 55/100
188/188 - 0s - loss: 0.0035
Epoch 56/100
188/188 - 0s - loss: 0.0035
Epoch 57/100
188/188 - 0s - loss: 0.0033
Epoch 58/100
188/188 - 0s - loss: 0.0035
Epoch 59/100
188/188 - 0s - loss: 0.0034
Epoch 60/100
188/188 - 0s - loss: 0.0035
Epoch 61/100
188/188 - 0s - loss: 0.0035
Epoch 62/100
188/188 - 0s - loss: 0.0036
Epoch 63/100
188/188 - 0s - loss: 0.0035
Epoch 64/100
188/188 - 0s - loss: 0.0034
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0034
Epoch 67/100
188/188 - 0s - loss: 0.0034
Epoch 68/100
188/188 - 0s - loss: 0.0033
Epoch 69/100
188/188 - 0s - loss: 0.0034
Epoch 70/100
188/188 - 0s - loss: 0.0035
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0034
Epoch 73/100
188/188 - 0s - loss: 0.0035
Epoch 74/100
188/188 - 0s - loss: 0.0032
Epoch 75/100
188/188 - 0s - loss: 0.0034
Epoch 76/100
188/188 - 0s - loss: 0.0034
Epoch 77/100
188/188 - 0s - loss: 0.0034
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0034
Epoch 80/100
188/188 - 0s - loss: 0.0032
Epoch 81/100
188/188 - 0s - loss: 0.0033
Epoch 82/100
188/188 - 0s - loss: 0.0033
Epoch 83/100
188/188 - 0s - loss: 0.0032
Epoch 84/100
188/188 - 0s - loss: 0.0032
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0032
Epoch 87/100
188/188 - 0s - loss: 0.0032
Epoch 88/100
188/188 - 0s - loss: 0.0033
Epoch 89/100
188/188 - 0s - loss: 0.0031
Epoch 90/100
188/188 - 0s - loss: 0.0033
Epoch 91/100
188/188 - 0s - loss: 0.0034
Epoch 92/100
188/188 - 0s - loss: 0.0032
Epoch 93/100
188/188 - 0s - loss: 0.0031
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0033
Epoch 96/100
188/188 - 0s - loss: 0.0032
Epoch 97/100
188/188 - 0s - loss: 0.0031
Epoch 98/100
188/188 - 0s - loss: 0.0034
Epoch 99/100
188/188 - 0s - loss: 0.0030
Epoch 100/100
188/188 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.054
Train RMSE: 0.092
key_word: COVID-19
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.518519  0.509259  0.527778
2021-07-25  0.518519  0.518519  0.527778  ...  0.518519  0.518519  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.527778  0.518519  0.518519
2021-08-08  0.425926  0.611111  0.518519  ...  0.527778  0.527778  0.518519
2021-08-15  0.500000  0.425926  0.611111  ...  0.518519  0.527778  0.527778

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_17 (GRU)                 (None, 16)                2016      
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 17        
=================================================================
Total params: 2,033
Trainable params: 2,033
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0232
Epoch 2/100
188/188 - 0s - loss: 0.0047
Epoch 3/100
188/188 - 0s - loss: 0.0052
Epoch 4/100
188/188 - 0s - loss: 0.0048
Epoch 5/100
188/188 - 0s - loss: 0.0048
Epoch 6/100
188/188 - 0s - loss: 0.0048
Epoch 7/100
188/188 - 0s - loss: 0.0044
Epoch 8/100
188/188 - 0s - loss: 0.0044
Epoch 9/100
188/188 - 0s - loss: 0.0044
Epoch 10/100
188/188 - 0s - loss: 0.0043
Epoch 11/100
188/188 - 0s - loss: 0.0040
Epoch 12/100
188/188 - 0s - loss: 0.0046
Epoch 13/100
188/188 - 0s - loss: 0.0041
Epoch 14/100
188/188 - 0s - loss: 0.0042
Epoch 15/100
188/188 - 0s - loss: 0.0044
Epoch 16/100
188/188 - 0s - loss: 0.0038
Epoch 17/100
188/188 - 0s - loss: 0.0038
Epoch 18/100
188/188 - 0s - loss: 0.0037
Epoch 19/100
188/188 - 0s - loss: 0.0041
Epoch 20/100
188/188 - 0s - loss: 0.0039
Epoch 21/100
188/188 - 0s - loss: 0.0038
Epoch 22/100
188/188 - 0s - loss: 0.0042
Epoch 23/100
188/188 - 0s - loss: 0.0037
Epoch 24/100
188/188 - 0s - loss: 0.0037
Epoch 25/100
188/188 - 0s - loss: 0.0035
Epoch 26/100
188/188 - 0s - loss: 0.0038
Epoch 27/100
188/188 - 0s - loss: 0.0037
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0037
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0037
Epoch 32/100
188/188 - 0s - loss: 0.0035
Epoch 33/100
188/188 - 0s - loss: 0.0034
Epoch 34/100
188/188 - 0s - loss: 0.0038
Epoch 35/100
188/188 - 0s - loss: 0.0035
Epoch 36/100
188/188 - 0s - loss: 0.0035
Epoch 37/100
188/188 - 0s - loss: 0.0037
Epoch 38/100
188/188 - 0s - loss: 0.0036
Epoch 39/100
188/188 - 0s - loss: 0.0036
Epoch 40/100
188/188 - 0s - loss: 0.0039
Epoch 41/100
188/188 - 0s - loss: 0.0036
Epoch 42/100
188/188 - 0s - loss: 0.0033
Epoch 43/100
188/188 - 0s - loss: 0.0038
Epoch 44/100
188/188 - 0s - loss: 0.0038
Epoch 45/100
188/188 - 0s - loss: 0.0033
Epoch 46/100
188/188 - 0s - loss: 0.0035
Epoch 47/100
188/188 - 0s - loss: 0.0033
Epoch 48/100
188/188 - 0s - loss: 0.0033
Epoch 49/100
188/188 - 0s - loss: 0.0033
Epoch 50/100
188/188 - 0s - loss: 0.0034
Epoch 51/100
188/188 - 0s - loss: 0.0033
Epoch 52/100
188/188 - 0s - loss: 0.0033
Epoch 53/100
188/188 - 0s - loss: 0.0036
Epoch 54/100
188/188 - 0s - loss: 0.0032
Epoch 55/100
188/188 - 0s - loss: 0.0032
Epoch 56/100
188/188 - 0s - loss: 0.0038
Epoch 57/100
188/188 - 0s - loss: 0.0033
Epoch 58/100
188/188 - 0s - loss: 0.0035
Epoch 59/100
188/188 - 0s - loss: 0.0032
Epoch 60/100
188/188 - 0s - loss: 0.0036
Epoch 61/100
188/188 - 0s - loss: 0.0032
Epoch 62/100
188/188 - 0s - loss: 0.0034
Epoch 63/100
188/188 - 0s - loss: 0.0033
Epoch 64/100
188/188 - 0s - loss: 0.0034
Epoch 65/100
188/188 - 0s - loss: 0.0033
Epoch 66/100
188/188 - 0s - loss: 0.0033
Epoch 67/100
188/188 - 0s - loss: 0.0034
Epoch 68/100
188/188 - 0s - loss: 0.0037
Epoch 69/100
188/188 - 0s - loss: 0.0032
Epoch 70/100
188/188 - 0s - loss: 0.0033
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0033
Epoch 73/100
188/188 - 0s - loss: 0.0035
Epoch 74/100
188/188 - 0s - loss: 0.0035
Epoch 75/100
188/188 - 0s - loss: 0.0032
Epoch 76/100
188/188 - 0s - loss: 0.0032
Epoch 77/100
188/188 - 0s - loss: 0.0032
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0032
Epoch 80/100
188/188 - 0s - loss: 0.0033
Epoch 81/100
188/188 - 0s - loss: 0.0033
Epoch 82/100
188/188 - 0s - loss: 0.0031
Epoch 83/100
188/188 - 0s - loss: 0.0031
Epoch 84/100
188/188 - 0s - loss: 0.0032
Epoch 85/100
188/188 - 0s - loss: 0.0032
Epoch 86/100
188/188 - 0s - loss: 0.0030
Epoch 87/100
188/188 - 0s - loss: 0.0031
Epoch 88/100
188/188 - 0s - loss: 0.0031
Epoch 89/100
188/188 - 0s - loss: 0.0032
Epoch 90/100
188/188 - 0s - loss: 0.0033
Epoch 91/100
188/188 - 0s - loss: 0.0030
Epoch 92/100
188/188 - 0s - loss: 0.0033
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0030
Epoch 95/100
188/188 - 0s - loss: 0.0030
Epoch 96/100
188/188 - 0s - loss: 0.0032
Epoch 97/100
188/188 - 0s - loss: 0.0033
Epoch 98/100
188/188 - 0s - loss: 0.0031
Epoch 99/100
188/188 - 0s - loss: 0.0033
Epoch 100/100
188/188 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.053
Train RMSE: 0.100
key_word: COVID-19
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.518519  0.509259  0.527778
2021-07-25  0.518519  0.518519  0.527778  ...  0.518519  0.518519  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.527778  0.518519  0.518519
2021-08-08  0.425926  0.611111  0.518519  ...  0.527778  0.527778  0.518519
2021-08-15  0.500000  0.425926  0.611111  ...  0.518519  0.527778  0.527778

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_18 (GRU)                 (None, 32)                5568      
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 33        
=================================================================
Total params: 5,601
Trainable params: 5,601
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0161
Epoch 2/100
188/188 - 0s - loss: 0.0047
Epoch 3/100
188/188 - 0s - loss: 0.0051
Epoch 4/100
188/188 - 0s - loss: 0.0048
Epoch 5/100
188/188 - 0s - loss: 0.0042
Epoch 6/100
188/188 - 0s - loss: 0.0054
Epoch 7/100
188/188 - 0s - loss: 0.0041
Epoch 8/100
188/188 - 0s - loss: 0.0041
Epoch 9/100
188/188 - 0s - loss: 0.0039
Epoch 10/100
188/188 - 0s - loss: 0.0044
Epoch 11/100
188/188 - 0s - loss: 0.0040
Epoch 12/100
188/188 - 0s - loss: 0.0039
Epoch 13/100
188/188 - 0s - loss: 0.0050
Epoch 14/100
188/188 - 0s - loss: 0.0039
Epoch 15/100
188/188 - 0s - loss: 0.0042
Epoch 16/100
188/188 - 0s - loss: 0.0038
Epoch 17/100
188/188 - 0s - loss: 0.0047
Epoch 18/100
188/188 - 0s - loss: 0.0037
Epoch 19/100
188/188 - 0s - loss: 0.0038
Epoch 20/100
188/188 - 0s - loss: 0.0041
Epoch 21/100
188/188 - 0s - loss: 0.0039
Epoch 22/100
188/188 - 0s - loss: 0.0039
Epoch 23/100
188/188 - 0s - loss: 0.0040
Epoch 24/100
188/188 - 0s - loss: 0.0033
Epoch 25/100
188/188 - 0s - loss: 0.0041
Epoch 26/100
188/188 - 0s - loss: 0.0038
Epoch 27/100
188/188 - 0s - loss: 0.0038
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0035
Epoch 30/100
188/188 - 0s - loss: 0.0039
Epoch 31/100
188/188 - 0s - loss: 0.0036
Epoch 32/100
188/188 - 0s - loss: 0.0036
Epoch 33/100
188/188 - 0s - loss: 0.0036
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0038
Epoch 36/100
188/188 - 0s - loss: 0.0035
Epoch 37/100
188/188 - 0s - loss: 0.0035
Epoch 38/100
188/188 - 0s - loss: 0.0036
Epoch 39/100
188/188 - 0s - loss: 0.0035
Epoch 40/100
188/188 - 0s - loss: 0.0037
Epoch 41/100
188/188 - 0s - loss: 0.0034
Epoch 42/100
188/188 - 0s - loss: 0.0034
Epoch 43/100
188/188 - 0s - loss: 0.0034
Epoch 44/100
188/188 - 0s - loss: 0.0036
Epoch 45/100
188/188 - 0s - loss: 0.0034
Epoch 46/100
188/188 - 0s - loss: 0.0036
Epoch 47/100
188/188 - 0s - loss: 0.0036
Epoch 48/100
188/188 - 0s - loss: 0.0034
Epoch 49/100
188/188 - 0s - loss: 0.0034
Epoch 50/100
188/188 - 0s - loss: 0.0036
Epoch 51/100
188/188 - 0s - loss: 0.0033
Epoch 52/100
188/188 - 0s - loss: 0.0034
Epoch 53/100
188/188 - 0s - loss: 0.0032
Epoch 54/100
188/188 - 0s - loss: 0.0033
Epoch 55/100
188/188 - 0s - loss: 0.0035
Epoch 56/100
188/188 - 0s - loss: 0.0035
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0034
Epoch 59/100
188/188 - 0s - loss: 0.0033
Epoch 60/100
188/188 - 0s - loss: 0.0034
Epoch 61/100
188/188 - 0s - loss: 0.0033
Epoch 62/100
188/188 - 0s - loss: 0.0035
Epoch 63/100
188/188 - 0s - loss: 0.0035
Epoch 64/100
188/188 - 0s - loss: 0.0033
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0033
Epoch 67/100
188/188 - 0s - loss: 0.0033
Epoch 68/100
188/188 - 0s - loss: 0.0031
Epoch 69/100
188/188 - 0s - loss: 0.0034
Epoch 70/100
188/188 - 0s - loss: 0.0032
Epoch 71/100
188/188 - 0s - loss: 0.0032
Epoch 72/100
188/188 - 0s - loss: 0.0034
Epoch 73/100
188/188 - 0s - loss: 0.0031
Epoch 74/100
188/188 - 0s - loss: 0.0034
Epoch 75/100
188/188 - 0s - loss: 0.0033
Epoch 76/100
188/188 - 0s - loss: 0.0032
Epoch 77/100
188/188 - 0s - loss: 0.0032
Epoch 78/100
188/188 - 0s - loss: 0.0034
Epoch 79/100
188/188 - 0s - loss: 0.0033
Epoch 80/100
188/188 - 0s - loss: 0.0032
Epoch 81/100
188/188 - 0s - loss: 0.0033
Epoch 82/100
188/188 - 0s - loss: 0.0032
Epoch 83/100
188/188 - 0s - loss: 0.0032
Epoch 84/100
188/188 - 0s - loss: 0.0030
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0033
Epoch 87/100
188/188 - 0s - loss: 0.0032
Epoch 88/100
188/188 - 0s - loss: 0.0031
Epoch 89/100
188/188 - 0s - loss: 0.0033
Epoch 90/100
188/188 - 0s - loss: 0.0031
Epoch 91/100
188/188 - 0s - loss: 0.0030
Epoch 92/100
188/188 - 0s - loss: 0.0036
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0031
Epoch 96/100
188/188 - 0s - loss: 0.0033
Epoch 97/100
188/188 - 0s - loss: 0.0033
Epoch 98/100
188/188 - 0s - loss: 0.0031
Epoch 99/100
188/188 - 0s - loss: 0.0030
Epoch 100/100
188/188 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.055
Train RMSE: 0.099
key_word: COVID-19
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.518519  0.527778  0.527778  ...  0.518519  0.509259  0.527778
2021-07-25  0.518519  0.518519  0.527778  ...  0.518519  0.518519  0.509259
2021-08-01  0.611111  0.518519  0.518519  ...  0.527778  0.518519  0.518519
2021-08-08  0.425926  0.611111  0.518519  ...  0.527778  0.527778  0.518519
2021-08-15  0.500000  0.425926  0.611111  ...  0.518519  0.527778  0.527778

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_20"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_19 (GRU)                 (None, 60)                15480     
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 61        
=================================================================
Total params: 15,541
Trainable params: 15,541
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0070
Epoch 2/100
188/188 - 0s - loss: 0.0047
Epoch 3/100
188/188 - 0s - loss: 0.0050
Epoch 4/100
188/188 - 0s - loss: 0.0047
Epoch 5/100
188/188 - 0s - loss: 0.0046
Epoch 6/100
188/188 - 0s - loss: 0.0043
Epoch 7/100
188/188 - 0s - loss: 0.0047
Epoch 8/100
188/188 - 0s - loss: 0.0040
Epoch 9/100
188/188 - 0s - loss: 0.0044
Epoch 10/100
188/188 - 0s - loss: 0.0040
Epoch 11/100
188/188 - 0s - loss: 0.0040
Epoch 12/100
188/188 - 0s - loss: 0.0044
Epoch 13/100
188/188 - 0s - loss: 0.0043
Epoch 14/100
188/188 - 0s - loss: 0.0043
Epoch 15/100
188/188 - 0s - loss: 0.0036
Epoch 16/100
188/188 - 0s - loss: 0.0049
Epoch 17/100
188/188 - 0s - loss: 0.0037
Epoch 18/100
188/188 - 0s - loss: 0.0042
Epoch 19/100
188/188 - 0s - loss: 0.0041
Epoch 20/100
188/188 - 0s - loss: 0.0036
Epoch 21/100
188/188 - 0s - loss: 0.0036
Epoch 22/100
188/188 - 0s - loss: 0.0037
Epoch 23/100
188/188 - 0s - loss: 0.0036
Epoch 24/100
188/188 - 0s - loss: 0.0036
Epoch 25/100
188/188 - 0s - loss: 0.0036
Epoch 26/100
188/188 - 0s - loss: 0.0039
Epoch 27/100
188/188 - 0s - loss: 0.0036
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0039
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0040
Epoch 32/100
188/188 - 0s - loss: 0.0037
Epoch 33/100
188/188 - 0s - loss: 0.0036
Epoch 34/100
188/188 - 0s - loss: 0.0037
Epoch 35/100
188/188 - 0s - loss: 0.0035
Epoch 36/100
188/188 - 0s - loss: 0.0035
Epoch 37/100
188/188 - 0s - loss: 0.0036
Epoch 38/100
188/188 - 0s - loss: 0.0035
Epoch 39/100
188/188 - 0s - loss: 0.0036
Epoch 40/100
188/188 - 0s - loss: 0.0036
Epoch 41/100
188/188 - 0s - loss: 0.0035
Epoch 42/100
188/188 - 0s - loss: 0.0036
Epoch 43/100
188/188 - 0s - loss: 0.0037
Epoch 44/100
188/188 - 0s - loss: 0.0033
Epoch 45/100
188/188 - 0s - loss: 0.0033
Epoch 46/100
188/188 - 0s - loss: 0.0034
Epoch 47/100
188/188 - 0s - loss: 0.0033
Epoch 48/100
188/188 - 0s - loss: 0.0036
Epoch 49/100
188/188 - 0s - loss: 0.0033
Epoch 50/100
188/188 - 0s - loss: 0.0039
Epoch 51/100
188/188 - 0s - loss: 0.0034
Epoch 52/100
188/188 - 0s - loss: 0.0032
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0037
Epoch 55/100
188/188 - 0s - loss: 0.0033
Epoch 56/100
188/188 - 0s - loss: 0.0035
Epoch 57/100
188/188 - 0s - loss: 0.0037
Epoch 58/100
188/188 - 0s - loss: 0.0035
Epoch 59/100
188/188 - 0s - loss: 0.0033
Epoch 60/100
188/188 - 0s - loss: 0.0034
Epoch 61/100
188/188 - 0s - loss: 0.0034
Epoch 62/100
188/188 - 0s - loss: 0.0033
Epoch 63/100
188/188 - 0s - loss: 0.0035
Epoch 64/100
188/188 - 0s - loss: 0.0035
Epoch 65/100
188/188 - 0s - loss: 0.0033
Epoch 66/100
188/188 - 0s - loss: 0.0034
Epoch 67/100
188/188 - 0s - loss: 0.0034
Epoch 68/100
188/188 - 0s - loss: 0.0033
Epoch 69/100
188/188 - 0s - loss: 0.0032
Epoch 70/100
188/188 - 0s - loss: 0.0034
Epoch 71/100
188/188 - 0s - loss: 0.0032
Epoch 72/100
188/188 - 0s - loss: 0.0032
Epoch 73/100
188/188 - 0s - loss: 0.0033
Epoch 74/100
188/188 - 0s - loss: 0.0032
Epoch 75/100
188/188 - 0s - loss: 0.0032
Epoch 76/100
188/188 - 0s - loss: 0.0033
Epoch 77/100
188/188 - 0s - loss: 0.0034
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0032
Epoch 80/100
188/188 - 0s - loss: 0.0031
Epoch 81/100
188/188 - 0s - loss: 0.0032
Epoch 82/100
188/188 - 0s - loss: 0.0034
Epoch 83/100
188/188 - 0s - loss: 0.0032
Epoch 84/100
188/188 - 0s - loss: 0.0032
Epoch 85/100
188/188 - 0s - loss: 0.0032
Epoch 86/100
188/188 - 0s - loss: 0.0030
Epoch 87/100
188/188 - 0s - loss: 0.0033
Epoch 88/100
188/188 - 0s - loss: 0.0032
Epoch 89/100
188/188 - 0s - loss: 0.0033
Epoch 90/100
188/188 - 0s - loss: 0.0034
Epoch 91/100
188/188 - 0s - loss: 0.0032
Epoch 92/100
188/188 - 0s - loss: 0.0031
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0031
Epoch 96/100
188/188 - 0s - loss: 0.0031
Epoch 97/100
188/188 - 0s - loss: 0.0032
Epoch 98/100
188/188 - 0s - loss: 0.0033
Epoch 99/100
188/188 - 0s - loss: 0.0032
Epoch 100/100
188/188 - 0s - loss: 0.0030

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.052
Train RMSE: 0.096
key_word: COVID-19
window size: 24
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.444444  0.444444  0.388889
2021-07-25  0.500000  0.444444  0.500000  ...  0.444444  0.444444  0.444444
2021-08-01  0.388889  0.500000  0.444444  ...  0.444444  0.444444  0.444444
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.444444  0.444444
2021-08-15  0.000000  0.444444  0.388889  ...  0.444444  0.444444  0.444444

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_21"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_20 (GRU)                 (None, 4)                 216       
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 5         
=================================================================
Total params: 221
Trainable params: 221
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.1099
Epoch 2/100
198/198 - 0s - loss: 0.0058
Epoch 3/100
198/198 - 0s - loss: 0.0056
Epoch 4/100
198/198 - 0s - loss: 0.0055
Epoch 5/100
198/198 - 0s - loss: 0.0056
Epoch 6/100
198/198 - 0s - loss: 0.0055
Epoch 7/100
198/198 - 0s - loss: 0.0052
Epoch 8/100
198/198 - 0s - loss: 0.0053
Epoch 9/100
198/198 - 0s - loss: 0.0053
Epoch 10/100
198/198 - 0s - loss: 0.0050
Epoch 11/100
198/198 - 0s - loss: 0.0050
Epoch 12/100
198/198 - 0s - loss: 0.0051
Epoch 13/100
198/198 - 0s - loss: 0.0051
Epoch 14/100
198/198 - 0s - loss: 0.0049
Epoch 15/100
198/198 - 0s - loss: 0.0048
Epoch 16/100
198/198 - 0s - loss: 0.0048
Epoch 17/100
198/198 - 0s - loss: 0.0047
Epoch 18/100
198/198 - 0s - loss: 0.0048
Epoch 19/100
198/198 - 0s - loss: 0.0048
Epoch 20/100
198/198 - 0s - loss: 0.0047
Epoch 21/100
198/198 - 0s - loss: 0.0047
Epoch 22/100
198/198 - 0s - loss: 0.0046
Epoch 23/100
198/198 - 0s - loss: 0.0046
Epoch 24/100
198/198 - 0s - loss: 0.0045
Epoch 25/100
198/198 - 0s - loss: 0.0045
Epoch 26/100
198/198 - 0s - loss: 0.0045
Epoch 27/100
198/198 - 0s - loss: 0.0045
Epoch 28/100
198/198 - 0s - loss: 0.0044
Epoch 29/100
198/198 - 0s - loss: 0.0045
Epoch 30/100
198/198 - 0s - loss: 0.0044
Epoch 31/100
198/198 - 0s - loss: 0.0045
Epoch 32/100
198/198 - 0s - loss: 0.0044
Epoch 33/100
198/198 - 0s - loss: 0.0044
Epoch 34/100
198/198 - 0s - loss: 0.0044
Epoch 35/100
198/198 - 0s - loss: 0.0045
Epoch 36/100
198/198 - 0s - loss: 0.0043
Epoch 37/100
198/198 - 0s - loss: 0.0043
Epoch 38/100
198/198 - 0s - loss: 0.0043
Epoch 39/100
198/198 - 0s - loss: 0.0042
Epoch 40/100
198/198 - 0s - loss: 0.0044
Epoch 41/100
198/198 - 0s - loss: 0.0043
Epoch 42/100
198/198 - 0s - loss: 0.0044
Epoch 43/100
198/198 - 0s - loss: 0.0042
Epoch 44/100
198/198 - 0s - loss: 0.0043
Epoch 45/100
198/198 - 0s - loss: 0.0042
Epoch 46/100
198/198 - 0s - loss: 0.0042
Epoch 47/100
198/198 - 0s - loss: 0.0043
Epoch 48/100
198/198 - 0s - loss: 0.0043
Epoch 49/100
198/198 - 0s - loss: 0.0043
Epoch 50/100
198/198 - 0s - loss: 0.0042
Epoch 51/100
198/198 - 0s - loss: 0.0042
Epoch 52/100
198/198 - 0s - loss: 0.0043
Epoch 53/100
198/198 - 0s - loss: 0.0041
Epoch 54/100
198/198 - 0s - loss: 0.0042
Epoch 55/100
198/198 - 0s - loss: 0.0042
Epoch 56/100
198/198 - 0s - loss: 0.0042
Epoch 57/100
198/198 - 0s - loss: 0.0041
Epoch 58/100
198/198 - 0s - loss: 0.0042
Epoch 59/100
198/198 - 0s - loss: 0.0042
Epoch 60/100
198/198 - 0s - loss: 0.0041
Epoch 61/100
198/198 - 0s - loss: 0.0041
Epoch 62/100
198/198 - 0s - loss: 0.0043
Epoch 63/100
198/198 - 0s - loss: 0.0041
Epoch 64/100
198/198 - 0s - loss: 0.0041
Epoch 65/100
198/198 - 0s - loss: 0.0040
Epoch 66/100
198/198 - 0s - loss: 0.0041
Epoch 67/100
198/198 - 0s - loss: 0.0042
Epoch 68/100
198/198 - 0s - loss: 0.0042
Epoch 69/100
198/198 - 0s - loss: 0.0041
Epoch 70/100
198/198 - 0s - loss: 0.0041
Epoch 71/100
198/198 - 0s - loss: 0.0041
Epoch 72/100
198/198 - 0s - loss: 0.0041
Epoch 73/100
198/198 - 0s - loss: 0.0042
Epoch 74/100
198/198 - 0s - loss: 0.0042
Epoch 75/100
198/198 - 0s - loss: 0.0041
Epoch 76/100
198/198 - 0s - loss: 0.0041
Epoch 77/100
198/198 - 0s - loss: 0.0041
Epoch 78/100
198/198 - 0s - loss: 0.0042
Epoch 79/100
198/198 - 0s - loss: 0.0041
Epoch 80/100
198/198 - 0s - loss: 0.0041
Epoch 81/100
198/198 - 0s - loss: 0.0040
Epoch 82/100
198/198 - 0s - loss: 0.0040
Epoch 83/100
198/198 - 0s - loss: 0.0041
Epoch 84/100
198/198 - 0s - loss: 0.0039
Epoch 85/100
198/198 - 0s - loss: 0.0041
Epoch 86/100
198/198 - 0s - loss: 0.0040
Epoch 87/100
198/198 - 0s - loss: 0.0039
Epoch 88/100
198/198 - 0s - loss: 0.0041
Epoch 89/100
198/198 - 0s - loss: 0.0041
Epoch 90/100
198/198 - 0s - loss: 0.0041
Epoch 91/100
198/198 - 0s - loss: 0.0040
Epoch 92/100
198/198 - 0s - loss: 0.0040
Epoch 93/100
198/198 - 0s - loss: 0.0040
Epoch 94/100
198/198 - 0s - loss: 0.0040
Epoch 95/100
198/198 - 0s - loss: 0.0040
Epoch 96/100
198/198 - 0s - loss: 0.0041
Epoch 97/100
198/198 - 0s - loss: 0.0040
Epoch 98/100
198/198 - 0s - loss: 0.0042
Epoch 99/100
198/198 - 0s - loss: 0.0040
Epoch 100/100
198/198 - 0s - loss: 0.0041

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.062
Train RMSE: 0.135
key_word: stock price
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.444444  0.444444  0.388889
2021-07-25  0.500000  0.444444  0.500000  ...  0.444444  0.444444  0.444444
2021-08-01  0.388889  0.500000  0.444444  ...  0.444444  0.444444  0.444444
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.444444  0.444444
2021-08-15  0.000000  0.444444  0.388889  ...  0.444444  0.444444  0.444444

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_22"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_21 (GRU)                 (None, 8)                 528       
_________________________________________________________________
dense_21 (Dense)             (None, 1)                 9         
=================================================================
Total params: 537
Trainable params: 537
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0530
Epoch 2/100
198/198 - 0s - loss: 0.0048
Epoch 3/100
198/198 - 0s - loss: 0.0048
Epoch 4/100
198/198 - 0s - loss: 0.0049
Epoch 5/100
198/198 - 0s - loss: 0.0050
Epoch 6/100
198/198 - 0s - loss: 0.0047
Epoch 7/100
198/198 - 0s - loss: 0.0046
Epoch 8/100
198/198 - 0s - loss: 0.0049
Epoch 9/100
198/198 - 0s - loss: 0.0046
Epoch 10/100
198/198 - 0s - loss: 0.0045
Epoch 11/100
198/198 - 0s - loss: 0.0046
Epoch 12/100
198/198 - 0s - loss: 0.0045
Epoch 13/100
198/198 - 0s - loss: 0.0044
Epoch 14/100
198/198 - 0s - loss: 0.0044
Epoch 15/100
198/198 - 0s - loss: 0.0042
Epoch 16/100
198/198 - 0s - loss: 0.0044
Epoch 17/100
198/198 - 0s - loss: 0.0044
Epoch 18/100
198/198 - 0s - loss: 0.0045
Epoch 19/100
198/198 - 0s - loss: 0.0043
Epoch 20/100
198/198 - 0s - loss: 0.0043
Epoch 21/100
198/198 - 0s - loss: 0.0044
Epoch 22/100
198/198 - 0s - loss: 0.0043
Epoch 23/100
198/198 - 0s - loss: 0.0042
Epoch 24/100
198/198 - 0s - loss: 0.0044
Epoch 25/100
198/198 - 0s - loss: 0.0043
Epoch 26/100
198/198 - 0s - loss: 0.0043
Epoch 27/100
198/198 - 0s - loss: 0.0042
Epoch 28/100
198/198 - 0s - loss: 0.0043
Epoch 29/100
198/198 - 0s - loss: 0.0042
Epoch 30/100
198/198 - 0s - loss: 0.0041
Epoch 31/100
198/198 - 0s - loss: 0.0040
Epoch 32/100
198/198 - 0s - loss: 0.0041
Epoch 33/100
198/198 - 0s - loss: 0.0044
Epoch 34/100
198/198 - 0s - loss: 0.0041
Epoch 35/100
198/198 - 0s - loss: 0.0042
Epoch 36/100
198/198 - 0s - loss: 0.0043
Epoch 37/100
198/198 - 0s - loss: 0.0042
Epoch 38/100
198/198 - 0s - loss: 0.0040
Epoch 39/100
198/198 - 0s - loss: 0.0044
Epoch 40/100
198/198 - 0s - loss: 0.0042
Epoch 41/100
198/198 - 0s - loss: 0.0041
Epoch 42/100
198/198 - 0s - loss: 0.0041
Epoch 43/100
198/198 - 0s - loss: 0.0042
Epoch 44/100
198/198 - 0s - loss: 0.0041
Epoch 45/100
198/198 - 0s - loss: 0.0041
Epoch 46/100
198/198 - 0s - loss: 0.0041
Epoch 47/100
198/198 - 0s - loss: 0.0042
Epoch 48/100
198/198 - 0s - loss: 0.0041
Epoch 49/100
198/198 - 0s - loss: 0.0041
Epoch 50/100
198/198 - 0s - loss: 0.0040
Epoch 51/100
198/198 - 0s - loss: 0.0041
Epoch 52/100
198/198 - 0s - loss: 0.0043
Epoch 53/100
198/198 - 0s - loss: 0.0041
Epoch 54/100
198/198 - 0s - loss: 0.0043
Epoch 55/100
198/198 - 0s - loss: 0.0041
Epoch 56/100
198/198 - 0s - loss: 0.0042
Epoch 57/100
198/198 - 0s - loss: 0.0041
Epoch 58/100
198/198 - 0s - loss: 0.0041
Epoch 59/100
198/198 - 0s - loss: 0.0038
Epoch 60/100
198/198 - 0s - loss: 0.0040
Epoch 61/100
198/198 - 0s - loss: 0.0043
Epoch 62/100
198/198 - 0s - loss: 0.0041
Epoch 63/100
198/198 - 0s - loss: 0.0040
Epoch 64/100
198/198 - 0s - loss: 0.0041
Epoch 65/100
198/198 - 0s - loss: 0.0042
Epoch 66/100
198/198 - 0s - loss: 0.0043
Epoch 67/100
198/198 - 0s - loss: 0.0040
Epoch 68/100
198/198 - 0s - loss: 0.0041
Epoch 69/100
198/198 - 0s - loss: 0.0040
Epoch 70/100
198/198 - 0s - loss: 0.0040
Epoch 71/100
198/198 - 0s - loss: 0.0041
Epoch 72/100
198/198 - 0s - loss: 0.0040
Epoch 73/100
198/198 - 0s - loss: 0.0040
Epoch 74/100
198/198 - 0s - loss: 0.0041
Epoch 75/100
198/198 - 0s - loss: 0.0040
Epoch 76/100
198/198 - 0s - loss: 0.0040
Epoch 77/100
198/198 - 0s - loss: 0.0041
Epoch 78/100
198/198 - 0s - loss: 0.0039
Epoch 79/100
198/198 - 0s - loss: 0.0040
Epoch 80/100
198/198 - 0s - loss: 0.0040
Epoch 81/100
198/198 - 0s - loss: 0.0041
Epoch 82/100
198/198 - 0s - loss: 0.0041
Epoch 83/100
198/198 - 0s - loss: 0.0041
Epoch 84/100
198/198 - 0s - loss: 0.0040
Epoch 85/100
198/198 - 0s - loss: 0.0040
Epoch 86/100
198/198 - 0s - loss: 0.0040
Epoch 87/100
198/198 - 0s - loss: 0.0042
Epoch 88/100
198/198 - 0s - loss: 0.0039
Epoch 89/100
198/198 - 0s - loss: 0.0040
Epoch 90/100
198/198 - 0s - loss: 0.0040
Epoch 91/100
198/198 - 0s - loss: 0.0041
Epoch 92/100
198/198 - 0s - loss: 0.0040
Epoch 93/100
198/198 - 0s - loss: 0.0040
Epoch 94/100
198/198 - 0s - loss: 0.0042
Epoch 95/100
198/198 - 0s - loss: 0.0039
Epoch 96/100
198/198 - 0s - loss: 0.0039
Epoch 97/100
198/198 - 0s - loss: 0.0040
Epoch 98/100
198/198 - 0s - loss: 0.0041
Epoch 99/100
198/198 - 0s - loss: 0.0040
Epoch 100/100
198/198 - 0s - loss: 0.0039

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.140
key_word: stock price
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.444444  0.444444  0.388889
2021-07-25  0.500000  0.444444  0.500000  ...  0.444444  0.444444  0.444444
2021-08-01  0.388889  0.500000  0.444444  ...  0.444444  0.444444  0.444444
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.444444  0.444444
2021-08-15  0.000000  0.444444  0.388889  ...  0.444444  0.444444  0.444444

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_23"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_22 (GRU)                 (None, 16)                1440      
_________________________________________________________________
dense_22 (Dense)             (None, 1)                 17        
=================================================================
Total params: 1,457
Trainable params: 1,457
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0124
Epoch 2/100
198/198 - 0s - loss: 0.0061
Epoch 3/100
198/198 - 0s - loss: 0.0057
Epoch 4/100
198/198 - 0s - loss: 0.0054
Epoch 5/100
198/198 - 0s - loss: 0.0055
Epoch 6/100
198/198 - 0s - loss: 0.0054
Epoch 7/100
198/198 - 0s - loss: 0.0050
Epoch 8/100
198/198 - 0s - loss: 0.0053
Epoch 9/100
198/198 - 0s - loss: 0.0048
Epoch 10/100
198/198 - 0s - loss: 0.0048
Epoch 11/100
198/198 - 0s - loss: 0.0049
Epoch 12/100
198/198 - 0s - loss: 0.0048
Epoch 13/100
198/198 - 0s - loss: 0.0049
Epoch 14/100
198/198 - 0s - loss: 0.0051
Epoch 15/100
198/198 - 0s - loss: 0.0046
Epoch 16/100
198/198 - 0s - loss: 0.0048
Epoch 17/100
198/198 - 0s - loss: 0.0045
Epoch 18/100
198/198 - 0s - loss: 0.0047
Epoch 19/100
198/198 - 0s - loss: 0.0043
Epoch 20/100
198/198 - 0s - loss: 0.0045
Epoch 21/100
198/198 - 0s - loss: 0.0044
Epoch 22/100
198/198 - 0s - loss: 0.0043
Epoch 23/100
198/198 - 0s - loss: 0.0046
Epoch 24/100
198/198 - 0s - loss: 0.0045
Epoch 25/100
198/198 - 0s - loss: 0.0047
Epoch 26/100
198/198 - 0s - loss: 0.0048
Epoch 27/100
198/198 - 0s - loss: 0.0043
Epoch 28/100
198/198 - 0s - loss: 0.0045
Epoch 29/100
198/198 - 0s - loss: 0.0043
Epoch 30/100
198/198 - 0s - loss: 0.0046
Epoch 31/100
198/198 - 0s - loss: 0.0042
Epoch 32/100
198/198 - 0s - loss: 0.0042
Epoch 33/100
198/198 - 0s - loss: 0.0046
Epoch 34/100
198/198 - 0s - loss: 0.0043
Epoch 35/100
198/198 - 0s - loss: 0.0044
Epoch 36/100
198/198 - 0s - loss: 0.0042
Epoch 37/100
198/198 - 0s - loss: 0.0044
Epoch 38/100
198/198 - 0s - loss: 0.0042
Epoch 39/100
198/198 - 0s - loss: 0.0041
Epoch 40/100
198/198 - 0s - loss: 0.0044
Epoch 41/100
198/198 - 0s - loss: 0.0044
Epoch 42/100
198/198 - 0s - loss: 0.0045
Epoch 43/100
198/198 - 0s - loss: 0.0041
Epoch 44/100
198/198 - 0s - loss: 0.0042
Epoch 45/100
198/198 - 0s - loss: 0.0042
Epoch 46/100
198/198 - 0s - loss: 0.0042
Epoch 47/100
198/198 - 0s - loss: 0.0042
Epoch 48/100
198/198 - 0s - loss: 0.0042
Epoch 49/100
198/198 - 0s - loss: 0.0043
Epoch 50/100
198/198 - 0s - loss: 0.0043
Epoch 51/100
198/198 - 0s - loss: 0.0044
Epoch 52/100
198/198 - 0s - loss: 0.0043
Epoch 53/100
198/198 - 0s - loss: 0.0043
Epoch 54/100
198/198 - 0s - loss: 0.0041
Epoch 55/100
198/198 - 0s - loss: 0.0042
Epoch 56/100
198/198 - 0s - loss: 0.0041
Epoch 57/100
198/198 - 0s - loss: 0.0041
Epoch 58/100
198/198 - 0s - loss: 0.0040
Epoch 59/100
198/198 - 0s - loss: 0.0042
Epoch 60/100
198/198 - 0s - loss: 0.0043
Epoch 61/100
198/198 - 0s - loss: 0.0043
Epoch 62/100
198/198 - 0s - loss: 0.0040
Epoch 63/100
198/198 - 0s - loss: 0.0040
Epoch 64/100
198/198 - 0s - loss: 0.0042
Epoch 65/100
198/198 - 0s - loss: 0.0041
Epoch 66/100
198/198 - 0s - loss: 0.0040
Epoch 67/100
198/198 - 0s - loss: 0.0043
Epoch 68/100
198/198 - 0s - loss: 0.0040
Epoch 69/100
198/198 - 0s - loss: 0.0043
Epoch 70/100
198/198 - 0s - loss: 0.0041
Epoch 71/100
198/198 - 0s - loss: 0.0039
Epoch 72/100
198/198 - 0s - loss: 0.0039
Epoch 73/100
198/198 - 0s - loss: 0.0041
Epoch 74/100
198/198 - 0s - loss: 0.0041
Epoch 75/100
198/198 - 0s - loss: 0.0043
Epoch 76/100
198/198 - 0s - loss: 0.0041
Epoch 77/100
198/198 - 0s - loss: 0.0042
Epoch 78/100
198/198 - 0s - loss: 0.0040
Epoch 79/100
198/198 - 0s - loss: 0.0041
Epoch 80/100
198/198 - 0s - loss: 0.0041
Epoch 81/100
198/198 - 0s - loss: 0.0041
Epoch 82/100
198/198 - 0s - loss: 0.0041
Epoch 83/100
198/198 - 0s - loss: 0.0040
Epoch 84/100
198/198 - 0s - loss: 0.0041
Epoch 85/100
198/198 - 0s - loss: 0.0040
Epoch 86/100
198/198 - 0s - loss: 0.0041
Epoch 87/100
198/198 - 0s - loss: 0.0039
Epoch 88/100
198/198 - 0s - loss: 0.0039
Epoch 89/100
198/198 - 0s - loss: 0.0041
Epoch 90/100
198/198 - 0s - loss: 0.0040
Epoch 91/100
198/198 - 0s - loss: 0.0042
Epoch 92/100
198/198 - 0s - loss: 0.0038
Epoch 93/100
198/198 - 0s - loss: 0.0040
Epoch 94/100
198/198 - 0s - loss: 0.0042
Epoch 95/100
198/198 - 0s - loss: 0.0040
Epoch 96/100
198/198 - 0s - loss: 0.0042
Epoch 97/100
198/198 - 0s - loss: 0.0040
Epoch 98/100
198/198 - 0s - loss: 0.0041
Epoch 99/100
198/198 - 0s - loss: 0.0040
Epoch 100/100
198/198 - 0s - loss: 0.0040

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.061
Train RMSE: 0.136
key_word: stock price
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.444444  0.444444  0.388889
2021-07-25  0.500000  0.444444  0.500000  ...  0.444444  0.444444  0.444444
2021-08-01  0.388889  0.500000  0.444444  ...  0.444444  0.444444  0.444444
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.444444  0.444444
2021-08-15  0.000000  0.444444  0.388889  ...  0.444444  0.444444  0.444444

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_24"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_23 (GRU)                 (None, 32)                4416      
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 33        
=================================================================
Total params: 4,449
Trainable params: 4,449
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0325
Epoch 2/100
198/198 - 0s - loss: 0.0064
Epoch 3/100
198/198 - 0s - loss: 0.0062
Epoch 4/100
198/198 - 0s - loss: 0.0058
Epoch 5/100
198/198 - 0s - loss: 0.0057
Epoch 6/100
198/198 - 0s - loss: 0.0052
Epoch 7/100
198/198 - 0s - loss: 0.0054
Epoch 8/100
198/198 - 0s - loss: 0.0052
Epoch 9/100
198/198 - 0s - loss: 0.0052
Epoch 10/100
198/198 - 0s - loss: 0.0048
Epoch 11/100
198/198 - 0s - loss: 0.0052
Epoch 12/100
198/198 - 0s - loss: 0.0048
Epoch 13/100
198/198 - 0s - loss: 0.0050
Epoch 14/100
198/198 - 0s - loss: 0.0048
Epoch 15/100
198/198 - 0s - loss: 0.0052
Epoch 16/100
198/198 - 0s - loss: 0.0048
Epoch 17/100
198/198 - 0s - loss: 0.0047
Epoch 18/100
198/198 - 0s - loss: 0.0046
Epoch 19/100
198/198 - 0s - loss: 0.0045
Epoch 20/100
198/198 - 0s - loss: 0.0050
Epoch 21/100
198/198 - 0s - loss: 0.0046
Epoch 22/100
198/198 - 0s - loss: 0.0045
Epoch 23/100
198/198 - 0s - loss: 0.0045
Epoch 24/100
198/198 - 0s - loss: 0.0044
Epoch 25/100
198/198 - 0s - loss: 0.0044
Epoch 26/100
198/198 - 0s - loss: 0.0043
Epoch 27/100
198/198 - 0s - loss: 0.0045
Epoch 28/100
198/198 - 0s - loss: 0.0044
Epoch 29/100
198/198 - 0s - loss: 0.0045
Epoch 30/100
198/198 - 0s - loss: 0.0044
Epoch 31/100
198/198 - 0s - loss: 0.0043
Epoch 32/100
198/198 - 0s - loss: 0.0043
Epoch 33/100
198/198 - 0s - loss: 0.0043
Epoch 34/100
198/198 - 0s - loss: 0.0046
Epoch 35/100
198/198 - 0s - loss: 0.0043
Epoch 36/100
198/198 - 0s - loss: 0.0043
Epoch 37/100
198/198 - 0s - loss: 0.0043
Epoch 38/100
198/198 - 0s - loss: 0.0045
Epoch 39/100
198/198 - 0s - loss: 0.0044
Epoch 40/100
198/198 - 0s - loss: 0.0045
Epoch 41/100
198/198 - 0s - loss: 0.0043
Epoch 42/100
198/198 - 0s - loss: 0.0042
Epoch 43/100
198/198 - 0s - loss: 0.0040
Epoch 44/100
198/198 - 0s - loss: 0.0044
Epoch 45/100
198/198 - 0s - loss: 0.0044
Epoch 46/100
198/198 - 0s - loss: 0.0043
Epoch 47/100
198/198 - 0s - loss: 0.0044
Epoch 48/100
198/198 - 0s - loss: 0.0043
Epoch 49/100
198/198 - 0s - loss: 0.0043
Epoch 50/100
198/198 - 0s - loss: 0.0040
Epoch 51/100
198/198 - 0s - loss: 0.0044
Epoch 52/100
198/198 - 0s - loss: 0.0042
Epoch 53/100
198/198 - 0s - loss: 0.0043
Epoch 54/100
198/198 - 0s - loss: 0.0043
Epoch 55/100
198/198 - 0s - loss: 0.0042
Epoch 56/100
198/198 - 0s - loss: 0.0043
Epoch 57/100
198/198 - 0s - loss: 0.0042
Epoch 58/100
198/198 - 0s - loss: 0.0041
Epoch 59/100
198/198 - 0s - loss: 0.0041
Epoch 60/100
198/198 - 0s - loss: 0.0040
Epoch 61/100
198/198 - 0s - loss: 0.0041
Epoch 62/100
198/198 - 0s - loss: 0.0041
Epoch 63/100
198/198 - 0s - loss: 0.0044
Epoch 64/100
198/198 - 0s - loss: 0.0042
Epoch 65/100
198/198 - 0s - loss: 0.0041
Epoch 66/100
198/198 - 0s - loss: 0.0043
Epoch 67/100
198/198 - 0s - loss: 0.0041
Epoch 68/100
198/198 - 0s - loss: 0.0042
Epoch 69/100
198/198 - 0s - loss: 0.0042
Epoch 70/100
198/198 - 0s - loss: 0.0042
Epoch 71/100
198/198 - 0s - loss: 0.0042
Epoch 72/100
198/198 - 0s - loss: 0.0042
Epoch 73/100
198/198 - 0s - loss: 0.0042
Epoch 74/100
198/198 - 0s - loss: 0.0042
Epoch 75/100
198/198 - 0s - loss: 0.0040
Epoch 76/100
198/198 - 0s - loss: 0.0042
Epoch 77/100
198/198 - 0s - loss: 0.0042
Epoch 78/100
198/198 - 0s - loss: 0.0042
Epoch 79/100
198/198 - 0s - loss: 0.0041
Epoch 80/100
198/198 - 0s - loss: 0.0040
Epoch 81/100
198/198 - 0s - loss: 0.0041
Epoch 82/100
198/198 - 0s - loss: 0.0041
Epoch 83/100
198/198 - 0s - loss: 0.0041
Epoch 84/100
198/198 - 0s - loss: 0.0040
Epoch 85/100
198/198 - 0s - loss: 0.0043
Epoch 86/100
198/198 - 0s - loss: 0.0041
Epoch 87/100
198/198 - 0s - loss: 0.0041
Epoch 88/100
198/198 - 0s - loss: 0.0040
Epoch 89/100
198/198 - 0s - loss: 0.0044
Epoch 90/100
198/198 - 0s - loss: 0.0041
Epoch 91/100
198/198 - 0s - loss: 0.0040
Epoch 92/100
198/198 - 0s - loss: 0.0041
Epoch 93/100
198/198 - 0s - loss: 0.0040
Epoch 94/100
198/198 - 0s - loss: 0.0040
Epoch 95/100
198/198 - 0s - loss: 0.0041
Epoch 96/100
198/198 - 0s - loss: 0.0039
Epoch 97/100
198/198 - 0s - loss: 0.0041
Epoch 98/100
198/198 - 0s - loss: 0.0040
Epoch 99/100
198/198 - 0s - loss: 0.0038
Epoch 100/100
198/198 - 0s - loss: 0.0041

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.062
Train RMSE: 0.137
key_word: stock price
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.444444  0.444444  0.388889
2021-07-25  0.500000  0.444444  0.500000  ...  0.444444  0.444444  0.444444
2021-08-01  0.388889  0.500000  0.444444  ...  0.444444  0.444444  0.444444
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.444444  0.444444
2021-08-15  0.000000  0.444444  0.388889  ...  0.444444  0.444444  0.444444

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_25"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_24 (GRU)                 (None, 60)                13320     
_________________________________________________________________
dense_24 (Dense)             (None, 1)                 61        
=================================================================
Total params: 13,381
Trainable params: 13,381
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
198/198 - 2s - loss: 0.0131
Epoch 2/100
198/198 - 0s - loss: 0.0051
Epoch 3/100
198/198 - 0s - loss: 0.0050
Epoch 4/100
198/198 - 0s - loss: 0.0050
Epoch 5/100
198/198 - 0s - loss: 0.0052
Epoch 6/100
198/198 - 0s - loss: 0.0051
Epoch 7/100
198/198 - 0s - loss: 0.0051
Epoch 8/100
198/198 - 0s - loss: 0.0052
Epoch 9/100
198/198 - 0s - loss: 0.0047
Epoch 10/100
198/198 - 0s - loss: 0.0049
Epoch 11/100
198/198 - 0s - loss: 0.0047
Epoch 12/100
198/198 - 0s - loss: 0.0053
Epoch 13/100
198/198 - 0s - loss: 0.0049
Epoch 14/100
198/198 - 0s - loss: 0.0045
Epoch 15/100
198/198 - 0s - loss: 0.0045
Epoch 16/100
198/198 - 0s - loss: 0.0049
Epoch 17/100
198/198 - 0s - loss: 0.0048
Epoch 18/100
198/198 - 0s - loss: 0.0045
Epoch 19/100
198/198 - 0s - loss: 0.0045
Epoch 20/100
198/198 - 0s - loss: 0.0044
Epoch 21/100
198/198 - 0s - loss: 0.0046
Epoch 22/100
198/198 - 0s - loss: 0.0045
Epoch 23/100
198/198 - 0s - loss: 0.0045
Epoch 24/100
198/198 - 0s - loss: 0.0045
Epoch 25/100
198/198 - 0s - loss: 0.0045
Epoch 26/100
198/198 - 0s - loss: 0.0046
Epoch 27/100
198/198 - 0s - loss: 0.0052
Epoch 28/100
198/198 - 0s - loss: 0.0046
Epoch 29/100
198/198 - 0s - loss: 0.0044
Epoch 30/100
198/198 - 0s - loss: 0.0045
Epoch 31/100
198/198 - 0s - loss: 0.0043
Epoch 32/100
198/198 - 0s - loss: 0.0046
Epoch 33/100
198/198 - 0s - loss: 0.0048
Epoch 34/100
198/198 - 0s - loss: 0.0048
Epoch 35/100
198/198 - 0s - loss: 0.0045
Epoch 36/100
198/198 - 0s - loss: 0.0045
Epoch 37/100
198/198 - 0s - loss: 0.0044
Epoch 38/100
198/198 - 0s - loss: 0.0042
Epoch 39/100
198/198 - 0s - loss: 0.0042
Epoch 40/100
198/198 - 0s - loss: 0.0042
Epoch 41/100
198/198 - 0s - loss: 0.0043
Epoch 42/100
198/198 - 0s - loss: 0.0042
Epoch 43/100
198/198 - 0s - loss: 0.0044
Epoch 44/100
198/198 - 0s - loss: 0.0043
Epoch 45/100
198/198 - 0s - loss: 0.0043
Epoch 46/100
198/198 - 0s - loss: 0.0043
Epoch 47/100
198/198 - 0s - loss: 0.0044
Epoch 48/100
198/198 - 0s - loss: 0.0044
Epoch 49/100
198/198 - 0s - loss: 0.0042
Epoch 50/100
198/198 - 0s - loss: 0.0043
Epoch 51/100
198/198 - 0s - loss: 0.0041
Epoch 52/100
198/198 - 0s - loss: 0.0045
Epoch 53/100
198/198 - 0s - loss: 0.0042
Epoch 54/100
198/198 - 0s - loss: 0.0044
Epoch 55/100
198/198 - 0s - loss: 0.0041
Epoch 56/100
198/198 - 0s - loss: 0.0045
Epoch 57/100
198/198 - 0s - loss: 0.0042
Epoch 58/100
198/198 - 0s - loss: 0.0042
Epoch 59/100
198/198 - 0s - loss: 0.0044
Epoch 60/100
198/198 - 0s - loss: 0.0042
Epoch 61/100
198/198 - 0s - loss: 0.0043
Epoch 62/100
198/198 - 0s - loss: 0.0044
Epoch 63/100
198/198 - 0s - loss: 0.0044
Epoch 64/100
198/198 - 0s - loss: 0.0041
Epoch 65/100
198/198 - 0s - loss: 0.0041
Epoch 66/100
198/198 - 0s - loss: 0.0041
Epoch 67/100
198/198 - 0s - loss: 0.0041
Epoch 68/100
198/198 - 0s - loss: 0.0043
Epoch 69/100
198/198 - 0s - loss: 0.0042
Epoch 70/100
198/198 - 0s - loss: 0.0042
Epoch 71/100
198/198 - 0s - loss: 0.0042
Epoch 72/100
198/198 - 0s - loss: 0.0041
Epoch 73/100
198/198 - 0s - loss: 0.0042
Epoch 74/100
198/198 - 0s - loss: 0.0041
Epoch 75/100
198/198 - 0s - loss: 0.0041
Epoch 76/100
198/198 - 0s - loss: 0.0040
Epoch 77/100
198/198 - 0s - loss: 0.0039
Epoch 78/100
198/198 - 0s - loss: 0.0041
Epoch 79/100
198/198 - 0s - loss: 0.0041
Epoch 80/100
198/198 - 0s - loss: 0.0040
Epoch 81/100
198/198 - 0s - loss: 0.0040
Epoch 82/100
198/198 - 0s - loss: 0.0041
Epoch 83/100
198/198 - 0s - loss: 0.0042
Epoch 84/100
198/198 - 0s - loss: 0.0041
Epoch 85/100
198/198 - 0s - loss: 0.0045
Epoch 86/100
198/198 - 0s - loss: 0.0043
Epoch 87/100
198/198 - 0s - loss: 0.0042
Epoch 88/100
198/198 - 0s - loss: 0.0041
Epoch 89/100
198/198 - 0s - loss: 0.0041
Epoch 90/100
198/198 - 0s - loss: 0.0040
Epoch 91/100
198/198 - 0s - loss: 0.0040
Epoch 92/100
198/198 - 0s - loss: 0.0041
Epoch 93/100
198/198 - 0s - loss: 0.0042
Epoch 94/100
198/198 - 0s - loss: 0.0040
Epoch 95/100
198/198 - 0s - loss: 0.0041
Epoch 96/100
198/198 - 0s - loss: 0.0041
Epoch 97/100
198/198 - 0s - loss: 0.0040
Epoch 98/100
198/198 - 0s - loss: 0.0041
Epoch 99/100
198/198 - 0s - loss: 0.0042
Epoch 100/100
198/198 - 0s - loss: 0.0040

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.063
Train RMSE: 0.134
key_word: stock price
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.277778  0.166667  0.444444
2021-07-25  0.500000  0.444444  0.500000  ...  0.611111  0.277778  0.166667
2021-08-01  0.388889  0.500000  0.444444  ...  0.333333  0.611111  0.277778
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.333333  0.611111
2021-08-15  0.000000  0.444444  0.388889  ...  0.333333  0.444444  0.333333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_26"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_25 (GRU)                 (None, 4)                 360       
_________________________________________________________________
dense_25 (Dense)             (None, 1)                 5         
=================================================================
Total params: 365
Trainable params: 365
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0069
Epoch 2/100
188/188 - 0s - loss: 0.0053
Epoch 3/100
188/188 - 0s - loss: 0.0054
Epoch 4/100
188/188 - 0s - loss: 0.0052
Epoch 5/100
188/188 - 0s - loss: 0.0051
Epoch 6/100
188/188 - 0s - loss: 0.0050
Epoch 7/100
188/188 - 0s - loss: 0.0049
Epoch 8/100
188/188 - 0s - loss: 0.0050
Epoch 9/100
188/188 - 0s - loss: 0.0049
Epoch 10/100
188/188 - 0s - loss: 0.0050
Epoch 11/100
188/188 - 0s - loss: 0.0049
Epoch 12/100
188/188 - 0s - loss: 0.0048
Epoch 13/100
188/188 - 0s - loss: 0.0050
Epoch 14/100
188/188 - 0s - loss: 0.0048
Epoch 15/100
188/188 - 0s - loss: 0.0049
Epoch 16/100
188/188 - 0s - loss: 0.0047
Epoch 17/100
188/188 - 0s - loss: 0.0049
Epoch 18/100
188/188 - 0s - loss: 0.0048
Epoch 19/100
188/188 - 0s - loss: 0.0049
Epoch 20/100
188/188 - 0s - loss: 0.0047
Epoch 21/100
188/188 - 0s - loss: 0.0047
Epoch 22/100
188/188 - 0s - loss: 0.0048
Epoch 23/100
188/188 - 0s - loss: 0.0047
Epoch 24/100
188/188 - 0s - loss: 0.0047
Epoch 25/100
188/188 - 0s - loss: 0.0047
Epoch 26/100
188/188 - 0s - loss: 0.0047
Epoch 27/100
188/188 - 0s - loss: 0.0046
Epoch 28/100
188/188 - 0s - loss: 0.0046
Epoch 29/100
188/188 - 0s - loss: 0.0047
Epoch 30/100
188/188 - 0s - loss: 0.0048
Epoch 31/100
188/188 - 0s - loss: 0.0046
Epoch 32/100
188/188 - 0s - loss: 0.0046
Epoch 33/100
188/188 - 0s - loss: 0.0045
Epoch 34/100
188/188 - 0s - loss: 0.0047
Epoch 35/100
188/188 - 0s - loss: 0.0046
Epoch 36/100
188/188 - 0s - loss: 0.0046
Epoch 37/100
188/188 - 0s - loss: 0.0046
Epoch 38/100
188/188 - 0s - loss: 0.0046
Epoch 39/100
188/188 - 0s - loss: 0.0045
Epoch 40/100
188/188 - 0s - loss: 0.0045
Epoch 41/100
188/188 - 0s - loss: 0.0047
Epoch 42/100
188/188 - 0s - loss: 0.0044
Epoch 43/100
188/188 - 0s - loss: 0.0044
Epoch 44/100
188/188 - 0s - loss: 0.0045
Epoch 45/100
188/188 - 0s - loss: 0.0045
Epoch 46/100
188/188 - 0s - loss: 0.0044
Epoch 47/100
188/188 - 0s - loss: 0.0045
Epoch 48/100
188/188 - 0s - loss: 0.0046
Epoch 49/100
188/188 - 0s - loss: 0.0045
Epoch 50/100
188/188 - 0s - loss: 0.0044
Epoch 51/100
188/188 - 0s - loss: 0.0045
Epoch 52/100
188/188 - 0s - loss: 0.0044
Epoch 53/100
188/188 - 0s - loss: 0.0045
Epoch 54/100
188/188 - 0s - loss: 0.0043
Epoch 55/100
188/188 - 0s - loss: 0.0045
Epoch 56/100
188/188 - 0s - loss: 0.0045
Epoch 57/100
188/188 - 0s - loss: 0.0045
Epoch 58/100
188/188 - 0s - loss: 0.0045
Epoch 59/100
188/188 - 0s - loss: 0.0045
Epoch 60/100
188/188 - 0s - loss: 0.0043
Epoch 61/100
188/188 - 0s - loss: 0.0044
Epoch 62/100
188/188 - 0s - loss: 0.0044
Epoch 63/100
188/188 - 0s - loss: 0.0044
Epoch 64/100
188/188 - 0s - loss: 0.0046
Epoch 65/100
188/188 - 0s - loss: 0.0044
Epoch 66/100
188/188 - 0s - loss: 0.0042
Epoch 67/100
188/188 - 0s - loss: 0.0042
Epoch 68/100
188/188 - 0s - loss: 0.0044
Epoch 69/100
188/188 - 0s - loss: 0.0043
Epoch 70/100
188/188 - 0s - loss: 0.0044
Epoch 71/100
188/188 - 0s - loss: 0.0044
Epoch 72/100
188/188 - 0s - loss: 0.0043
Epoch 73/100
188/188 - 0s - loss: 0.0044
Epoch 74/100
188/188 - 0s - loss: 0.0043
Epoch 75/100
188/188 - 0s - loss: 0.0043
Epoch 76/100
188/188 - 0s - loss: 0.0043
Epoch 77/100
188/188 - 0s - loss: 0.0043
Epoch 78/100
188/188 - 0s - loss: 0.0043
Epoch 79/100
188/188 - 0s - loss: 0.0044
Epoch 80/100
188/188 - 0s - loss: 0.0044
Epoch 81/100
188/188 - 0s - loss: 0.0043
Epoch 82/100
188/188 - 0s - loss: 0.0043
Epoch 83/100
188/188 - 0s - loss: 0.0043
Epoch 84/100
188/188 - 0s - loss: 0.0043
Epoch 85/100
188/188 - 0s - loss: 0.0042
Epoch 86/100
188/188 - 0s - loss: 0.0042
Epoch 87/100
188/188 - 0s - loss: 0.0044
Epoch 88/100
188/188 - 0s - loss: 0.0042
Epoch 89/100
188/188 - 0s - loss: 0.0042
Epoch 90/100
188/188 - 0s - loss: 0.0043
Epoch 91/100
188/188 - 0s - loss: 0.0044
Epoch 92/100
188/188 - 0s - loss: 0.0042
Epoch 93/100
188/188 - 0s - loss: 0.0041
Epoch 94/100
188/188 - 0s - loss: 0.0042
Epoch 95/100
188/188 - 0s - loss: 0.0043
Epoch 96/100
188/188 - 0s - loss: 0.0042
Epoch 97/100
188/188 - 0s - loss: 0.0042
Epoch 98/100
188/188 - 0s - loss: 0.0042
Epoch 99/100
188/188 - 0s - loss: 0.0044
Epoch 100/100
188/188 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.139
key_word: stock price
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.277778  0.166667  0.444444
2021-07-25  0.500000  0.444444  0.500000  ...  0.611111  0.277778  0.166667
2021-08-01  0.388889  0.500000  0.444444  ...  0.333333  0.611111  0.277778
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.333333  0.611111
2021-08-15  0.000000  0.444444  0.388889  ...  0.333333  0.444444  0.333333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_27"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_26 (GRU)                 (None, 8)                 816       
_________________________________________________________________
dense_26 (Dense)             (None, 1)                 9         
=================================================================
Total params: 825
Trainable params: 825
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0254
Epoch 2/100
188/188 - 0s - loss: 0.0053
Epoch 3/100
188/188 - 0s - loss: 0.0052
Epoch 4/100
188/188 - 0s - loss: 0.0052
Epoch 5/100
188/188 - 0s - loss: 0.0050
Epoch 6/100
188/188 - 0s - loss: 0.0052
Epoch 7/100
188/188 - 0s - loss: 0.0052
Epoch 8/100
188/188 - 0s - loss: 0.0050
Epoch 9/100
188/188 - 0s - loss: 0.0050
Epoch 10/100
188/188 - 0s - loss: 0.0049
Epoch 11/100
188/188 - 0s - loss: 0.0050
Epoch 12/100
188/188 - 0s - loss: 0.0050
Epoch 13/100
188/188 - 0s - loss: 0.0048
Epoch 14/100
188/188 - 0s - loss: 0.0048
Epoch 15/100
188/188 - 0s - loss: 0.0049
Epoch 16/100
188/188 - 0s - loss: 0.0048
Epoch 17/100
188/188 - 0s - loss: 0.0047
Epoch 18/100
188/188 - 0s - loss: 0.0047
Epoch 19/100
188/188 - 0s - loss: 0.0048
Epoch 20/100
188/188 - 0s - loss: 0.0049
Epoch 21/100
188/188 - 0s - loss: 0.0046
Epoch 22/100
188/188 - 0s - loss: 0.0046
Epoch 23/100
188/188 - 0s - loss: 0.0051
Epoch 24/100
188/188 - 0s - loss: 0.0047
Epoch 25/100
188/188 - 0s - loss: 0.0047
Epoch 26/100
188/188 - 0s - loss: 0.0048
Epoch 27/100
188/188 - 0s - loss: 0.0045
Epoch 28/100
188/188 - 0s - loss: 0.0046
Epoch 29/100
188/188 - 0s - loss: 0.0046
Epoch 30/100
188/188 - 0s - loss: 0.0047
Epoch 31/100
188/188 - 0s - loss: 0.0045
Epoch 32/100
188/188 - 0s - loss: 0.0046
Epoch 33/100
188/188 - 0s - loss: 0.0047
Epoch 34/100
188/188 - 0s - loss: 0.0046
Epoch 35/100
188/188 - 0s - loss: 0.0046
Epoch 36/100
188/188 - 0s - loss: 0.0048
Epoch 37/100
188/188 - 0s - loss: 0.0044
Epoch 38/100
188/188 - 0s - loss: 0.0045
Epoch 39/100
188/188 - 0s - loss: 0.0047
Epoch 40/100
188/188 - 0s - loss: 0.0046
Epoch 41/100
188/188 - 0s - loss: 0.0047
Epoch 42/100
188/188 - 0s - loss: 0.0044
Epoch 43/100
188/188 - 0s - loss: 0.0045
Epoch 44/100
188/188 - 0s - loss: 0.0045
Epoch 45/100
188/188 - 0s - loss: 0.0045
Epoch 46/100
188/188 - 0s - loss: 0.0044
Epoch 47/100
188/188 - 0s - loss: 0.0046
Epoch 48/100
188/188 - 0s - loss: 0.0043
Epoch 49/100
188/188 - 0s - loss: 0.0046
Epoch 50/100
188/188 - 0s - loss: 0.0044
Epoch 51/100
188/188 - 0s - loss: 0.0043
Epoch 52/100
188/188 - 0s - loss: 0.0045
Epoch 53/100
188/188 - 0s - loss: 0.0044
Epoch 54/100
188/188 - 0s - loss: 0.0044
Epoch 55/100
188/188 - 0s - loss: 0.0045
Epoch 56/100
188/188 - 0s - loss: 0.0044
Epoch 57/100
188/188 - 0s - loss: 0.0046
Epoch 58/100
188/188 - 0s - loss: 0.0044
Epoch 59/100
188/188 - 0s - loss: 0.0045
Epoch 60/100
188/188 - 0s - loss: 0.0046
Epoch 61/100
188/188 - 0s - loss: 0.0043
Epoch 62/100
188/188 - 0s - loss: 0.0044
Epoch 63/100
188/188 - 0s - loss: 0.0045
Epoch 64/100
188/188 - 0s - loss: 0.0045
Epoch 65/100
188/188 - 0s - loss: 0.0043
Epoch 66/100
188/188 - 0s - loss: 0.0047
Epoch 67/100
188/188 - 0s - loss: 0.0044
Epoch 68/100
188/188 - 0s - loss: 0.0043
Epoch 69/100
188/188 - 0s - loss: 0.0044
Epoch 70/100
188/188 - 0s - loss: 0.0045
Epoch 71/100
188/188 - 0s - loss: 0.0043
Epoch 72/100
188/188 - 0s - loss: 0.0043
Epoch 73/100
188/188 - 0s - loss: 0.0043
Epoch 74/100
188/188 - 0s - loss: 0.0042
Epoch 75/100
188/188 - 0s - loss: 0.0045
Epoch 76/100
188/188 - 0s - loss: 0.0044
Epoch 77/100
188/188 - 0s - loss: 0.0043
Epoch 78/100
188/188 - 0s - loss: 0.0043
Epoch 79/100
188/188 - 0s - loss: 0.0044
Epoch 80/100
188/188 - 0s - loss: 0.0043
Epoch 81/100
188/188 - 0s - loss: 0.0042
Epoch 82/100
188/188 - 0s - loss: 0.0045
Epoch 83/100
188/188 - 0s - loss: 0.0044
Epoch 84/100
188/188 - 0s - loss: 0.0043
Epoch 85/100
188/188 - 0s - loss: 0.0044
Epoch 86/100
188/188 - 0s - loss: 0.0043
Epoch 87/100
188/188 - 0s - loss: 0.0046
Epoch 88/100
188/188 - 0s - loss: 0.0043
Epoch 89/100
188/188 - 0s - loss: 0.0044
Epoch 90/100
188/188 - 0s - loss: 0.0044
Epoch 91/100
188/188 - 0s - loss: 0.0043
Epoch 92/100
188/188 - 0s - loss: 0.0044
Epoch 93/100
188/188 - 0s - loss: 0.0043
Epoch 94/100
188/188 - 0s - loss: 0.0043
Epoch 95/100
188/188 - 0s - loss: 0.0042
Epoch 96/100
188/188 - 0s - loss: 0.0043
Epoch 97/100
188/188 - 0s - loss: 0.0043
Epoch 98/100
188/188 - 0s - loss: 0.0043
Epoch 99/100
188/188 - 0s - loss: 0.0042
Epoch 100/100
188/188 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.138
key_word: stock price
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.277778  0.166667  0.444444
2021-07-25  0.500000  0.444444  0.500000  ...  0.611111  0.277778  0.166667
2021-08-01  0.388889  0.500000  0.444444  ...  0.333333  0.611111  0.277778
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.333333  0.611111
2021-08-15  0.000000  0.444444  0.388889  ...  0.333333  0.444444  0.333333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_28"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_27 (GRU)                 (None, 16)                2016      
_________________________________________________________________
dense_27 (Dense)             (None, 1)                 17        
=================================================================
Total params: 2,033
Trainable params: 2,033
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0101
Epoch 2/100
188/188 - 0s - loss: 0.0061
Epoch 3/100
188/188 - 0s - loss: 0.0059
Epoch 4/100
188/188 - 0s - loss: 0.0059
Epoch 5/100
188/188 - 0s - loss: 0.0052
Epoch 6/100
188/188 - 0s - loss: 0.0052
Epoch 7/100
188/188 - 0s - loss: 0.0055
Epoch 8/100
188/188 - 0s - loss: 0.0049
Epoch 9/100
188/188 - 0s - loss: 0.0050
Epoch 10/100
188/188 - 0s - loss: 0.0051
Epoch 11/100
188/188 - 0s - loss: 0.0049
Epoch 12/100
188/188 - 0s - loss: 0.0050
Epoch 13/100
188/188 - 0s - loss: 0.0050
Epoch 14/100
188/188 - 0s - loss: 0.0049
Epoch 15/100
188/188 - 0s - loss: 0.0052
Epoch 16/100
188/188 - 0s - loss: 0.0046
Epoch 17/100
188/188 - 0s - loss: 0.0048
Epoch 18/100
188/188 - 0s - loss: 0.0046
Epoch 19/100
188/188 - 0s - loss: 0.0048
Epoch 20/100
188/188 - 0s - loss: 0.0047
Epoch 21/100
188/188 - 0s - loss: 0.0046
Epoch 22/100
188/188 - 0s - loss: 0.0045
Epoch 23/100
188/188 - 0s - loss: 0.0044
Epoch 24/100
188/188 - 0s - loss: 0.0045
Epoch 25/100
188/188 - 0s - loss: 0.0046
Epoch 26/100
188/188 - 0s - loss: 0.0046
Epoch 27/100
188/188 - 0s - loss: 0.0045
Epoch 28/100
188/188 - 0s - loss: 0.0046
Epoch 29/100
188/188 - 0s - loss: 0.0045
Epoch 30/100
188/188 - 0s - loss: 0.0047
Epoch 31/100
188/188 - 0s - loss: 0.0047
Epoch 32/100
188/188 - 0s - loss: 0.0046
Epoch 33/100
188/188 - 0s - loss: 0.0045
Epoch 34/100
188/188 - 0s - loss: 0.0043
Epoch 35/100
188/188 - 0s - loss: 0.0044
Epoch 36/100
188/188 - 0s - loss: 0.0046
Epoch 37/100
188/188 - 0s - loss: 0.0043
Epoch 38/100
188/188 - 0s - loss: 0.0044
Epoch 39/100
188/188 - 0s - loss: 0.0044
Epoch 40/100
188/188 - 0s - loss: 0.0046
Epoch 41/100
188/188 - 0s - loss: 0.0045
Epoch 42/100
188/188 - 0s - loss: 0.0043
Epoch 43/100
188/188 - 0s - loss: 0.0045
Epoch 44/100
188/188 - 0s - loss: 0.0045
Epoch 45/100
188/188 - 0s - loss: 0.0043
Epoch 46/100
188/188 - 0s - loss: 0.0043
Epoch 47/100
188/188 - 0s - loss: 0.0044
Epoch 48/100
188/188 - 0s - loss: 0.0044
Epoch 49/100
188/188 - 0s - loss: 0.0044
Epoch 50/100
188/188 - 0s - loss: 0.0044
Epoch 51/100
188/188 - 0s - loss: 0.0044
Epoch 52/100
188/188 - 0s - loss: 0.0043
Epoch 53/100
188/188 - 0s - loss: 0.0043
Epoch 54/100
188/188 - 0s - loss: 0.0043
Epoch 55/100
188/188 - 0s - loss: 0.0043
Epoch 56/100
188/188 - 0s - loss: 0.0043
Epoch 57/100
188/188 - 0s - loss: 0.0044
Epoch 58/100
188/188 - 0s - loss: 0.0044
Epoch 59/100
188/188 - 0s - loss: 0.0045
Epoch 60/100
188/188 - 0s - loss: 0.0044
Epoch 61/100
188/188 - 0s - loss: 0.0043
Epoch 62/100
188/188 - 0s - loss: 0.0044
Epoch 63/100
188/188 - 0s - loss: 0.0041
Epoch 64/100
188/188 - 0s - loss: 0.0043
Epoch 65/100
188/188 - 0s - loss: 0.0044
Epoch 66/100
188/188 - 0s - loss: 0.0042
Epoch 67/100
188/188 - 0s - loss: 0.0043
Epoch 68/100
188/188 - 0s - loss: 0.0043
Epoch 69/100
188/188 - 0s - loss: 0.0043
Epoch 70/100
188/188 - 0s - loss: 0.0043
Epoch 71/100
188/188 - 0s - loss: 0.0046
Epoch 72/100
188/188 - 0s - loss: 0.0042
Epoch 73/100
188/188 - 0s - loss: 0.0042
Epoch 74/100
188/188 - 0s - loss: 0.0042
Epoch 75/100
188/188 - 0s - loss: 0.0045
Epoch 76/100
188/188 - 0s - loss: 0.0042
Epoch 77/100
188/188 - 0s - loss: 0.0044
Epoch 78/100
188/188 - 0s - loss: 0.0046
Epoch 79/100
188/188 - 0s - loss: 0.0044
Epoch 80/100
188/188 - 0s - loss: 0.0042
Epoch 81/100
188/188 - 0s - loss: 0.0043
Epoch 82/100
188/188 - 0s - loss: 0.0042
Epoch 83/100
188/188 - 0s - loss: 0.0042
Epoch 84/100
188/188 - 0s - loss: 0.0041
Epoch 85/100
188/188 - 0s - loss: 0.0044
Epoch 86/100
188/188 - 0s - loss: 0.0043
Epoch 87/100
188/188 - 0s - loss: 0.0045
Epoch 88/100
188/188 - 0s - loss: 0.0041
Epoch 89/100
188/188 - 0s - loss: 0.0047
Epoch 90/100
188/188 - 0s - loss: 0.0043
Epoch 91/100
188/188 - 0s - loss: 0.0041
Epoch 92/100
188/188 - 0s - loss: 0.0042
Epoch 93/100
188/188 - 0s - loss: 0.0042
Epoch 94/100
188/188 - 0s - loss: 0.0042
Epoch 95/100
188/188 - 0s - loss: 0.0044
Epoch 96/100
188/188 - 0s - loss: 0.0042
Epoch 97/100
188/188 - 0s - loss: 0.0043
Epoch 98/100
188/188 - 0s - loss: 0.0044
Epoch 99/100
188/188 - 0s - loss: 0.0042
Epoch 100/100
188/188 - 0s - loss: 0.0042

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.063
Train RMSE: 0.137
key_word: stock price
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.277778  0.166667  0.444444
2021-07-25  0.500000  0.444444  0.500000  ...  0.611111  0.277778  0.166667
2021-08-01  0.388889  0.500000  0.444444  ...  0.333333  0.611111  0.277778
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.333333  0.611111
2021-08-15  0.000000  0.444444  0.388889  ...  0.333333  0.444444  0.333333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_29"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_28 (GRU)                 (None, 32)                5568      
_________________________________________________________________
dense_28 (Dense)             (None, 1)                 33        
=================================================================
Total params: 5,601
Trainable params: 5,601
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0182
Epoch 2/100
188/188 - 0s - loss: 0.0052
Epoch 3/100
188/188 - 0s - loss: 0.0054
Epoch 4/100
188/188 - 0s - loss: 0.0049
Epoch 5/100
188/188 - 0s - loss: 0.0047
Epoch 6/100
188/188 - 0s - loss: 0.0053
Epoch 7/100
188/188 - 0s - loss: 0.0049
Epoch 8/100
188/188 - 0s - loss: 0.0056
Epoch 9/100
188/188 - 0s - loss: 0.0048
Epoch 10/100
188/188 - 0s - loss: 0.0050
Epoch 11/100
188/188 - 0s - loss: 0.0051
Epoch 12/100
188/188 - 0s - loss: 0.0050
Epoch 13/100
188/188 - 0s - loss: 0.0047
Epoch 14/100
188/188 - 0s - loss: 0.0051
Epoch 15/100
188/188 - 0s - loss: 0.0051
Epoch 16/100
188/188 - 0s - loss: 0.0055
Epoch 17/100
188/188 - 0s - loss: 0.0045
Epoch 18/100
188/188 - 0s - loss: 0.0046
Epoch 19/100
188/188 - 0s - loss: 0.0046
Epoch 20/100
188/188 - 0s - loss: 0.0049
Epoch 21/100
188/188 - 0s - loss: 0.0048
Epoch 22/100
188/188 - 0s - loss: 0.0050
Epoch 23/100
188/188 - 0s - loss: 0.0045
Epoch 24/100
188/188 - 0s - loss: 0.0046
Epoch 25/100
188/188 - 0s - loss: 0.0051
Epoch 26/100
188/188 - 0s - loss: 0.0048
Epoch 27/100
188/188 - 0s - loss: 0.0046
Epoch 28/100
188/188 - 0s - loss: 0.0045
Epoch 29/100
188/188 - 0s - loss: 0.0046
Epoch 30/100
188/188 - 0s - loss: 0.0046
Epoch 31/100
188/188 - 0s - loss: 0.0045
Epoch 32/100
188/188 - 0s - loss: 0.0044
Epoch 33/100
188/188 - 0s - loss: 0.0046
Epoch 34/100
188/188 - 0s - loss: 0.0048
Epoch 35/100
188/188 - 0s - loss: 0.0047
Epoch 36/100
188/188 - 0s - loss: 0.0045
Epoch 37/100
188/188 - 0s - loss: 0.0046
Epoch 38/100
188/188 - 0s - loss: 0.0046
Epoch 39/100
188/188 - 0s - loss: 0.0046
Epoch 40/100
188/188 - 0s - loss: 0.0044
Epoch 41/100
188/188 - 0s - loss: 0.0048
Epoch 42/100
188/188 - 0s - loss: 0.0044
Epoch 43/100
188/188 - 0s - loss: 0.0046
Epoch 44/100
188/188 - 0s - loss: 0.0043
Epoch 45/100
188/188 - 0s - loss: 0.0046
Epoch 46/100
188/188 - 0s - loss: 0.0048
Epoch 47/100
188/188 - 0s - loss: 0.0045
Epoch 48/100
188/188 - 0s - loss: 0.0046
Epoch 49/100
188/188 - 0s - loss: 0.0046
Epoch 50/100
188/188 - 0s - loss: 0.0044
Epoch 51/100
188/188 - 0s - loss: 0.0045
Epoch 52/100
188/188 - 0s - loss: 0.0044
Epoch 53/100
188/188 - 0s - loss: 0.0046
Epoch 54/100
188/188 - 0s - loss: 0.0044
Epoch 55/100
188/188 - 0s - loss: 0.0044
Epoch 56/100
188/188 - 0s - loss: 0.0043
Epoch 57/100
188/188 - 0s - loss: 0.0045
Epoch 58/100
188/188 - 0s - loss: 0.0045
Epoch 59/100
188/188 - 0s - loss: 0.0044
Epoch 60/100
188/188 - 0s - loss: 0.0044
Epoch 61/100
188/188 - 0s - loss: 0.0043
Epoch 62/100
188/188 - 0s - loss: 0.0044
Epoch 63/100
188/188 - 0s - loss: 0.0043
Epoch 64/100
188/188 - 0s - loss: 0.0045
Epoch 65/100
188/188 - 0s - loss: 0.0044
Epoch 66/100
188/188 - 0s - loss: 0.0046
Epoch 67/100
188/188 - 0s - loss: 0.0043
Epoch 68/100
188/188 - 0s - loss: 0.0043
Epoch 69/100
188/188 - 0s - loss: 0.0045
Epoch 70/100
188/188 - 0s - loss: 0.0043
Epoch 71/100
188/188 - 0s - loss: 0.0045
Epoch 72/100
188/188 - 0s - loss: 0.0044
Epoch 73/100
188/188 - 0s - loss: 0.0044
Epoch 74/100
188/188 - 0s - loss: 0.0044
Epoch 75/100
188/188 - 0s - loss: 0.0044
Epoch 76/100
188/188 - 0s - loss: 0.0045
Epoch 77/100
188/188 - 0s - loss: 0.0043
Epoch 78/100
188/188 - 0s - loss: 0.0042
Epoch 79/100
188/188 - 0s - loss: 0.0043
Epoch 80/100
188/188 - 0s - loss: 0.0045
Epoch 81/100
188/188 - 0s - loss: 0.0045
Epoch 82/100
188/188 - 0s - loss: 0.0042
Epoch 83/100
188/188 - 0s - loss: 0.0041
Epoch 84/100
188/188 - 0s - loss: 0.0044
Epoch 85/100
188/188 - 0s - loss: 0.0043
Epoch 86/100
188/188 - 0s - loss: 0.0042
Epoch 87/100
188/188 - 0s - loss: 0.0043
Epoch 88/100
188/188 - 0s - loss: 0.0042
Epoch 89/100
188/188 - 0s - loss: 0.0044
Epoch 90/100
188/188 - 0s - loss: 0.0041
Epoch 91/100
188/188 - 0s - loss: 0.0043
Epoch 92/100
188/188 - 0s - loss: 0.0043
Epoch 93/100
188/188 - 0s - loss: 0.0042
Epoch 94/100
188/188 - 0s - loss: 0.0043
Epoch 95/100
188/188 - 0s - loss: 0.0043
Epoch 96/100
188/188 - 0s - loss: 0.0044
Epoch 97/100
188/188 - 0s - loss: 0.0043
Epoch 98/100
188/188 - 0s - loss: 0.0043
Epoch 99/100
188/188 - 0s - loss: 0.0043
Epoch 100/100
188/188 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.136
key_word: stock price
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-18  0.444444  0.500000  0.388889  ...  0.277778  0.166667  0.444444
2021-07-25  0.500000  0.444444  0.500000  ...  0.611111  0.277778  0.166667
2021-08-01  0.388889  0.500000  0.444444  ...  0.333333  0.611111  0.277778
2021-08-08  0.444444  0.388889  0.500000  ...  0.444444  0.333333  0.611111
2021-08-15  0.000000  0.444444  0.388889  ...  0.333333  0.444444  0.333333

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_30"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_29 (GRU)                 (None, 60)                15480     
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 61        
=================================================================
Total params: 15,541
Trainable params: 15,541
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0114
Epoch 2/100
188/188 - 0s - loss: 0.0059
Epoch 3/100
188/188 - 0s - loss: 0.0060
Epoch 4/100
188/188 - 0s - loss: 0.0064
Epoch 5/100
188/188 - 0s - loss: 0.0058
Epoch 6/100
188/188 - 0s - loss: 0.0063
Epoch 7/100
188/188 - 0s - loss: 0.0064
Epoch 8/100
188/188 - 0s - loss: 0.0052
Epoch 9/100
188/188 - 0s - loss: 0.0058
Epoch 10/100
188/188 - 0s - loss: 0.0054
Epoch 11/100
188/188 - 0s - loss: 0.0048
Epoch 12/100
188/188 - 0s - loss: 0.0051
Epoch 13/100
188/188 - 0s - loss: 0.0050
Epoch 14/100
188/188 - 0s - loss: 0.0050
Epoch 15/100
188/188 - 0s - loss: 0.0047
Epoch 16/100
188/188 - 0s - loss: 0.0049
Epoch 17/100
188/188 - 0s - loss: 0.0053
Epoch 18/100
188/188 - 0s - loss: 0.0050
Epoch 19/100
188/188 - 0s - loss: 0.0048
Epoch 20/100
188/188 - 0s - loss: 0.0051
Epoch 21/100
188/188 - 0s - loss: 0.0046
Epoch 22/100
188/188 - 0s - loss: 0.0051
Epoch 23/100
188/188 - 0s - loss: 0.0046
Epoch 24/100
188/188 - 0s - loss: 0.0047
Epoch 25/100
188/188 - 0s - loss: 0.0045
Epoch 26/100
188/188 - 0s - loss: 0.0047
Epoch 27/100
188/188 - 0s - loss: 0.0046
Epoch 28/100
188/188 - 0s - loss: 0.0046
Epoch 29/100
188/188 - 0s - loss: 0.0047
Epoch 30/100
188/188 - 0s - loss: 0.0047
Epoch 31/100
188/188 - 0s - loss: 0.0050
Epoch 32/100
188/188 - 0s - loss: 0.0047
Epoch 33/100
188/188 - 0s - loss: 0.0045
Epoch 34/100
188/188 - 0s - loss: 0.0046
Epoch 35/100
188/188 - 0s - loss: 0.0046
Epoch 36/100
188/188 - 0s - loss: 0.0046
Epoch 37/100
188/188 - 0s - loss: 0.0046
Epoch 38/100
188/188 - 0s - loss: 0.0046
Epoch 39/100
188/188 - 0s - loss: 0.0044
Epoch 40/100
188/188 - 0s - loss: 0.0045
Epoch 41/100
188/188 - 0s - loss: 0.0044
Epoch 42/100
188/188 - 0s - loss: 0.0045
Epoch 43/100
188/188 - 0s - loss: 0.0046
Epoch 44/100
188/188 - 0s - loss: 0.0046
Epoch 45/100
188/188 - 0s - loss: 0.0044
Epoch 46/100
188/188 - 0s - loss: 0.0044
Epoch 47/100
188/188 - 0s - loss: 0.0044
Epoch 48/100
188/188 - 0s - loss: 0.0046
Epoch 49/100
188/188 - 0s - loss: 0.0046
Epoch 50/100
188/188 - 0s - loss: 0.0046
Epoch 51/100
188/188 - 0s - loss: 0.0044
Epoch 52/100
188/188 - 0s - loss: 0.0045
Epoch 53/100
188/188 - 0s - loss: 0.0046
Epoch 54/100
188/188 - 0s - loss: 0.0044
Epoch 55/100
188/188 - 0s - loss: 0.0044
Epoch 56/100
188/188 - 0s - loss: 0.0044
Epoch 57/100
188/188 - 0s - loss: 0.0045
Epoch 58/100
188/188 - 0s - loss: 0.0043
Epoch 59/100
188/188 - 0s - loss: 0.0044
Epoch 60/100
188/188 - 0s - loss: 0.0047
Epoch 61/100
188/188 - 0s - loss: 0.0043
Epoch 62/100
188/188 - 0s - loss: 0.0048
Epoch 63/100
188/188 - 0s - loss: 0.0044
Epoch 64/100
188/188 - 0s - loss: 0.0044
Epoch 65/100
188/188 - 0s - loss: 0.0044
Epoch 66/100
188/188 - 0s - loss: 0.0045
Epoch 67/100
188/188 - 0s - loss: 0.0042
Epoch 68/100
188/188 - 0s - loss: 0.0043
Epoch 69/100
188/188 - 0s - loss: 0.0043
Epoch 70/100
188/188 - 0s - loss: 0.0046
Epoch 71/100
188/188 - 0s - loss: 0.0043
Epoch 72/100
188/188 - 0s - loss: 0.0045
Epoch 73/100
188/188 - 0s - loss: 0.0045
Epoch 74/100
188/188 - 0s - loss: 0.0045
Epoch 75/100
188/188 - 0s - loss: 0.0043
Epoch 76/100
188/188 - 0s - loss: 0.0041
Epoch 77/100
188/188 - 0s - loss: 0.0044
Epoch 78/100
188/188 - 0s - loss: 0.0045
Epoch 79/100
188/188 - 0s - loss: 0.0043
Epoch 80/100
188/188 - 0s - loss: 0.0043
Epoch 81/100
188/188 - 0s - loss: 0.0043
Epoch 82/100
188/188 - 0s - loss: 0.0042
Epoch 83/100
188/188 - 0s - loss: 0.0041
Epoch 84/100
188/188 - 0s - loss: 0.0045
Epoch 85/100
188/188 - 0s - loss: 0.0043
Epoch 86/100
188/188 - 0s - loss: 0.0042
Epoch 87/100
188/188 - 0s - loss: 0.0045
Epoch 88/100
188/188 - 0s - loss: 0.0043
Epoch 89/100
188/188 - 0s - loss: 0.0043
Epoch 90/100
188/188 - 0s - loss: 0.0043
Epoch 91/100
188/188 - 0s - loss: 0.0045
Epoch 92/100
188/188 - 0s - loss: 0.0042
Epoch 93/100
188/188 - 0s - loss: 0.0044
Epoch 94/100
188/188 - 0s - loss: 0.0043
Epoch 95/100
188/188 - 0s - loss: 0.0043
Epoch 96/100
188/188 - 0s - loss: 0.0044
Epoch 97/100
188/188 - 0s - loss: 0.0044
Epoch 98/100
188/188 - 0s - loss: 0.0043
Epoch 99/100
188/188 - 0s - loss: 0.0043
Epoch 100/100
188/188 - 0s - loss: 0.0043

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.066
Train RMSE: 0.136
key_word: stock price
window size: 24
N neurons: 60
