
 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.397260  0.301370  0.630137
2021-07-18  0.534247  0.465753  0.410959  ...  0.657534  0.397260  0.301370
2021-07-25  0.534247  0.534247  0.465753  ...  0.876712  0.657534  0.397260
2021-08-01  0.410959  0.534247  0.534247  ...  0.205479  0.876712  0.657534
2021-08-08  0.534247  0.410959  0.534247  ...  0.273973  0.205479  0.876712

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_112"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_112 (LSTM)              (None, 4)                 272       
_________________________________________________________________
dense_110 (Dense)            (None, 1)                 5         
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0369
Epoch 2/100
197/197 - 0s - loss: 0.0058
Epoch 3/100
197/197 - 0s - loss: 0.0059
Epoch 4/100
197/197 - 0s - loss: 0.0059
Epoch 5/100
197/197 - 0s - loss: 0.0058
Epoch 6/100
197/197 - 0s - loss: 0.0058
Epoch 7/100
197/197 - 0s - loss: 0.0058
Epoch 8/100
197/197 - 0s - loss: 0.0060
Epoch 9/100
197/197 - 0s - loss: 0.0059
Epoch 10/100
197/197 - 0s - loss: 0.0057
Epoch 11/100
197/197 - 0s - loss: 0.0058
Epoch 12/100
197/197 - 0s - loss: 0.0059
Epoch 13/100
197/197 - 0s - loss: 0.0058
Epoch 14/100
197/197 - 0s - loss: 0.0057
Epoch 15/100
197/197 - 0s - loss: 0.0058
Epoch 16/100
197/197 - 0s - loss: 0.0058
Epoch 17/100
197/197 - 0s - loss: 0.0057
Epoch 18/100
197/197 - 0s - loss: 0.0057
Epoch 19/100
197/197 - 0s - loss: 0.0058
Epoch 20/100
197/197 - 0s - loss: 0.0057
Epoch 21/100
197/197 - 0s - loss: 0.0057
Epoch 22/100
197/197 - 0s - loss: 0.0057
Epoch 23/100
197/197 - 0s - loss: 0.0057
Epoch 24/100
197/197 - 0s - loss: 0.0056
Epoch 25/100
197/197 - 0s - loss: 0.0057
Epoch 26/100
197/197 - 0s - loss: 0.0057
Epoch 27/100
197/197 - 0s - loss: 0.0057
Epoch 28/100
197/197 - 0s - loss: 0.0055
Epoch 29/100
197/197 - 0s - loss: 0.0056
Epoch 30/100
197/197 - 0s - loss: 0.0055
Epoch 31/100
197/197 - 0s - loss: 0.0055
Epoch 32/100
197/197 - 0s - loss: 0.0054
Epoch 33/100
197/197 - 0s - loss: 0.0056
Epoch 34/100
197/197 - 0s - loss: 0.0055
Epoch 35/100
197/197 - 0s - loss: 0.0056
Epoch 36/100
197/197 - 0s - loss: 0.0055
Epoch 37/100
197/197 - 0s - loss: 0.0054
Epoch 38/100
197/197 - 0s - loss: 0.0054
Epoch 39/100
197/197 - 0s - loss: 0.0056
Epoch 40/100
197/197 - 0s - loss: 0.0055
Epoch 41/100
197/197 - 0s - loss: 0.0054
Epoch 42/100
197/197 - 0s - loss: 0.0053
Epoch 43/100
197/197 - 0s - loss: 0.0054
Epoch 44/100
197/197 - 0s - loss: 0.0054
Epoch 45/100
197/197 - 0s - loss: 0.0053
Epoch 46/100
197/197 - 0s - loss: 0.0054
Epoch 47/100
197/197 - 0s - loss: 0.0054
Epoch 48/100
197/197 - 0s - loss: 0.0053
Epoch 49/100
197/197 - 0s - loss: 0.0054
Epoch 50/100
197/197 - 0s - loss: 0.0053
Epoch 51/100
197/197 - 0s - loss: 0.0051
Epoch 52/100
197/197 - 0s - loss: 0.0056
Epoch 53/100
197/197 - 0s - loss: 0.0053
Epoch 54/100
197/197 - 0s - loss: 0.0054
Epoch 55/100
197/197 - 0s - loss: 0.0052
Epoch 56/100
197/197 - 0s - loss: 0.0053
Epoch 57/100
197/197 - 0s - loss: 0.0052
Epoch 58/100
197/197 - 0s - loss: 0.0054
Epoch 59/100
197/197 - 0s - loss: 0.0052
Epoch 60/100
197/197 - 0s - loss: 0.0052
Epoch 61/100
197/197 - 0s - loss: 0.0051
Epoch 62/100
197/197 - 0s - loss: 0.0053
Epoch 63/100
197/197 - 0s - loss: 0.0053
Epoch 64/100
197/197 - 0s - loss: 0.0051
Epoch 65/100
197/197 - 0s - loss: 0.0052
Epoch 66/100
197/197 - 0s - loss: 0.0052
Epoch 67/100
197/197 - 0s - loss: 0.0050
Epoch 68/100
197/197 - 0s - loss: 0.0052
Epoch 69/100
197/197 - 0s - loss: 0.0050
Epoch 70/100
197/197 - 0s - loss: 0.0051
Epoch 71/100
197/197 - 0s - loss: 0.0052
Epoch 72/100
197/197 - 0s - loss: 0.0051
Epoch 73/100
197/197 - 0s - loss: 0.0048
Epoch 74/100
197/197 - 0s - loss: 0.0051
Epoch 75/100
197/197 - 0s - loss: 0.0050
Epoch 76/100
197/197 - 0s - loss: 0.0051
Epoch 77/100
197/197 - 0s - loss: 0.0050
Epoch 78/100
197/197 - 0s - loss: 0.0049
Epoch 79/100
197/197 - 0s - loss: 0.0050
Epoch 80/100
197/197 - 0s - loss: 0.0048
Epoch 81/100
197/197 - 0s - loss: 0.0050
Epoch 82/100
197/197 - 0s - loss: 0.0049
Epoch 83/100
197/197 - 0s - loss: 0.0049
Epoch 84/100
197/197 - 0s - loss: 0.0048
Epoch 85/100
197/197 - 0s - loss: 0.0051
Epoch 86/100
197/197 - 0s - loss: 0.0050
Epoch 87/100
197/197 - 0s - loss: 0.0048
Epoch 88/100
197/197 - 0s - loss: 0.0049
Epoch 89/100
197/197 - 0s - loss: 0.0050
Epoch 90/100
197/197 - 0s - loss: 0.0049
Epoch 91/100
197/197 - 0s - loss: 0.0047
Epoch 92/100
197/197 - 0s - loss: 0.0048
Epoch 93/100
197/197 - 0s - loss: 0.0047
Epoch 94/100
197/197 - 0s - loss: 0.0047
Epoch 95/100
197/197 - 0s - loss: 0.0048
Epoch 96/100
197/197 - 0s - loss: 0.0048
Epoch 97/100
197/197 - 0s - loss: 0.0047
Epoch 98/100
197/197 - 0s - loss: 0.0048
Epoch 99/100
197/197 - 0s - loss: 0.0048
Epoch 100/100
197/197 - 0s - loss: 0.0048

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.159
key_word: bitcoin
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.397260  0.301370  0.630137
2021-07-18  0.534247  0.465753  0.410959  ...  0.657534  0.397260  0.301370
2021-07-25  0.534247  0.534247  0.465753  ...  0.876712  0.657534  0.397260
2021-08-01  0.410959  0.534247  0.534247  ...  0.205479  0.876712  0.657534
2021-08-08  0.534247  0.410959  0.534247  ...  0.273973  0.205479  0.876712

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_113"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_113 (LSTM)              (None, 8)                 672       
_________________________________________________________________
dense_111 (Dense)            (None, 1)                 9         
=================================================================
Total params: 681
Trainable params: 681
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0261
Epoch 2/100
197/197 - 0s - loss: 0.0066
Epoch 3/100
197/197 - 0s - loss: 0.0063
Epoch 4/100
197/197 - 0s - loss: 0.0066
Epoch 5/100
197/197 - 0s - loss: 0.0068
Epoch 6/100
197/197 - 0s - loss: 0.0062
Epoch 7/100
197/197 - 0s - loss: 0.0057
Epoch 8/100
197/197 - 0s - loss: 0.0061
Epoch 9/100
197/197 - 0s - loss: 0.0060
Epoch 10/100
197/197 - 0s - loss: 0.0059
Epoch 11/100
197/197 - 0s - loss: 0.0060
Epoch 12/100
197/197 - 0s - loss: 0.0060
Epoch 13/100
197/197 - 0s - loss: 0.0058
Epoch 14/100
197/197 - 0s - loss: 0.0063
Epoch 15/100
197/197 - 0s - loss: 0.0058
Epoch 16/100
197/197 - 0s - loss: 0.0056
Epoch 17/100
197/197 - 0s - loss: 0.0058
Epoch 18/100
197/197 - 0s - loss: 0.0056
Epoch 19/100
197/197 - 0s - loss: 0.0056
Epoch 20/100
197/197 - 0s - loss: 0.0055
Epoch 21/100
197/197 - 0s - loss: 0.0053
Epoch 22/100
197/197 - 0s - loss: 0.0057
Epoch 23/100
197/197 - 0s - loss: 0.0054
Epoch 24/100
197/197 - 0s - loss: 0.0055
Epoch 25/100
197/197 - 0s - loss: 0.0056
Epoch 26/100
197/197 - 0s - loss: 0.0057
Epoch 27/100
197/197 - 0s - loss: 0.0055
Epoch 28/100
197/197 - 0s - loss: 0.0055
Epoch 29/100
197/197 - 0s - loss: 0.0055
Epoch 30/100
197/197 - 0s - loss: 0.0053
Epoch 31/100
197/197 - 0s - loss: 0.0054
Epoch 32/100
197/197 - 0s - loss: 0.0056
Epoch 33/100
197/197 - 0s - loss: 0.0054
Epoch 34/100
197/197 - 0s - loss: 0.0054
Epoch 35/100
197/197 - 0s - loss: 0.0054
Epoch 36/100
197/197 - 0s - loss: 0.0055
Epoch 37/100
197/197 - 0s - loss: 0.0054
Epoch 38/100
197/197 - 0s - loss: 0.0053
Epoch 39/100
197/197 - 0s - loss: 0.0053
Epoch 40/100
197/197 - 0s - loss: 0.0053
Epoch 41/100
197/197 - 0s - loss: 0.0055
Epoch 42/100
197/197 - 0s - loss: 0.0053
Epoch 43/100
197/197 - 0s - loss: 0.0052
Epoch 44/100
197/197 - 0s - loss: 0.0053
Epoch 45/100
197/197 - 0s - loss: 0.0052
Epoch 46/100
197/197 - 0s - loss: 0.0054
Epoch 47/100
197/197 - 0s - loss: 0.0055
Epoch 48/100
197/197 - 0s - loss: 0.0052
Epoch 49/100
197/197 - 0s - loss: 0.0053
Epoch 50/100
197/197 - 0s - loss: 0.0051
Epoch 51/100
197/197 - 0s - loss: 0.0052
Epoch 52/100
197/197 - 0s - loss: 0.0050
Epoch 53/100
197/197 - 0s - loss: 0.0054
Epoch 54/100
197/197 - 0s - loss: 0.0051
Epoch 55/100
197/197 - 0s - loss: 0.0051
Epoch 56/100
197/197 - 0s - loss: 0.0053
Epoch 57/100
197/197 - 0s - loss: 0.0051
Epoch 58/100
197/197 - 0s - loss: 0.0052
Epoch 59/100
197/197 - 0s - loss: 0.0053
Epoch 60/100
197/197 - 0s - loss: 0.0052
Epoch 61/100
197/197 - 0s - loss: 0.0052
Epoch 62/100
197/197 - 0s - loss: 0.0050
Epoch 63/100
197/197 - 0s - loss: 0.0052
Epoch 64/100
197/197 - 0s - loss: 0.0051
Epoch 65/100
197/197 - 0s - loss: 0.0052
Epoch 66/100
197/197 - 0s - loss: 0.0050
Epoch 67/100
197/197 - 0s - loss: 0.0050
Epoch 68/100
197/197 - 0s - loss: 0.0050
Epoch 69/100
197/197 - 0s - loss: 0.0051
Epoch 70/100
197/197 - 0s - loss: 0.0050
Epoch 71/100
197/197 - 0s - loss: 0.0050
Epoch 72/100
197/197 - 0s - loss: 0.0051
Epoch 73/100
197/197 - 0s - loss: 0.0051
Epoch 74/100
197/197 - 0s - loss: 0.0052
Epoch 75/100
197/197 - 0s - loss: 0.0051
Epoch 76/100
197/197 - 0s - loss: 0.0052
Epoch 77/100
197/197 - 0s - loss: 0.0049
Epoch 78/100
197/197 - 0s - loss: 0.0051
Epoch 79/100
197/197 - 0s - loss: 0.0050
Epoch 80/100
197/197 - 0s - loss: 0.0053
Epoch 81/100
197/197 - 0s - loss: 0.0051
Epoch 82/100
197/197 - 0s - loss: 0.0050
Epoch 83/100
197/197 - 0s - loss: 0.0050
Epoch 84/100
197/197 - 0s - loss: 0.0051
Epoch 85/100
197/197 - 0s - loss: 0.0051
Epoch 86/100
197/197 - 0s - loss: 0.0051
Epoch 87/100
197/197 - 0s - loss: 0.0050
Epoch 88/100
197/197 - 0s - loss: 0.0050
Epoch 89/100
197/197 - 0s - loss: 0.0051
Epoch 90/100
197/197 - 0s - loss: 0.0049
Epoch 91/100
197/197 - 0s - loss: 0.0050
Epoch 92/100
197/197 - 0s - loss: 0.0051
Epoch 93/100
197/197 - 0s - loss: 0.0050
Epoch 94/100
197/197 - 0s - loss: 0.0049
Epoch 95/100
197/197 - 0s - loss: 0.0052
Epoch 96/100
197/197 - 0s - loss: 0.0051
Epoch 97/100
197/197 - 0s - loss: 0.0051
Epoch 98/100
197/197 - 0s - loss: 0.0050
Epoch 99/100
197/197 - 0s - loss: 0.0049
Epoch 100/100
197/197 - 0s - loss: 0.0051

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.069
Train RMSE: 0.152
key_word: bitcoin
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.397260  0.301370  0.630137
2021-07-18  0.534247  0.465753  0.410959  ...  0.657534  0.397260  0.301370
2021-07-25  0.534247  0.534247  0.465753  ...  0.876712  0.657534  0.397260
2021-08-01  0.410959  0.534247  0.534247  ...  0.205479  0.876712  0.657534
2021-08-08  0.534247  0.410959  0.534247  ...  0.273973  0.205479  0.876712

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_114"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_114 (LSTM)              (None, 16)                1856      
_________________________________________________________________
dense_112 (Dense)            (None, 1)                 17        
=================================================================
Total params: 1,873
Trainable params: 1,873
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0272
Epoch 2/100
197/197 - 0s - loss: 0.0061
Epoch 3/100
197/197 - 0s - loss: 0.0061
Epoch 4/100
197/197 - 0s - loss: 0.0060
Epoch 5/100
197/197 - 0s - loss: 0.0062
Epoch 6/100
197/197 - 0s - loss: 0.0060
Epoch 7/100
197/197 - 0s - loss: 0.0059
Epoch 8/100
197/197 - 0s - loss: 0.0059
Epoch 9/100
197/197 - 0s - loss: 0.0061
Epoch 10/100
197/197 - 0s - loss: 0.0058
Epoch 11/100
197/197 - 0s - loss: 0.0058
Epoch 12/100
197/197 - 0s - loss: 0.0059
Epoch 13/100
197/197 - 0s - loss: 0.0059
Epoch 14/100
197/197 - 0s - loss: 0.0056
Epoch 15/100
197/197 - 0s - loss: 0.0057
Epoch 16/100
197/197 - 0s - loss: 0.0056
Epoch 17/100
197/197 - 0s - loss: 0.0056
Epoch 18/100
197/197 - 0s - loss: 0.0055
Epoch 19/100
197/197 - 0s - loss: 0.0055
Epoch 20/100
197/197 - 0s - loss: 0.0056
Epoch 21/100
197/197 - 0s - loss: 0.0056
Epoch 22/100
197/197 - 0s - loss: 0.0055
Epoch 23/100
197/197 - 0s - loss: 0.0056
Epoch 24/100
197/197 - 0s - loss: 0.0056
Epoch 25/100
197/197 - 0s - loss: 0.0054
Epoch 26/100
197/197 - 0s - loss: 0.0055
Epoch 27/100
197/197 - 0s - loss: 0.0056
Epoch 28/100
197/197 - 0s - loss: 0.0054
Epoch 29/100
197/197 - 0s - loss: 0.0052
Epoch 30/100
197/197 - 0s - loss: 0.0056
Epoch 31/100
197/197 - 0s - loss: 0.0054
Epoch 32/100
197/197 - 0s - loss: 0.0054
Epoch 33/100
197/197 - 0s - loss: 0.0052
Epoch 34/100
197/197 - 0s - loss: 0.0053
Epoch 35/100
197/197 - 0s - loss: 0.0053
Epoch 36/100
197/197 - 0s - loss: 0.0053
Epoch 37/100
197/197 - 0s - loss: 0.0053
Epoch 38/100
197/197 - 0s - loss: 0.0053
Epoch 39/100
197/197 - 0s - loss: 0.0051
Epoch 40/100
197/197 - 0s - loss: 0.0052
Epoch 41/100
197/197 - 0s - loss: 0.0053
Epoch 42/100
197/197 - 0s - loss: 0.0054
Epoch 43/100
197/197 - 0s - loss: 0.0051
Epoch 44/100
197/197 - 0s - loss: 0.0052
Epoch 45/100
197/197 - 0s - loss: 0.0050
Epoch 46/100
197/197 - 0s - loss: 0.0051
Epoch 47/100
197/197 - 0s - loss: 0.0051
Epoch 48/100
197/197 - 0s - loss: 0.0051
Epoch 49/100
197/197 - 0s - loss: 0.0050
Epoch 50/100
197/197 - 0s - loss: 0.0051
Epoch 51/100
197/197 - 0s - loss: 0.0050
Epoch 52/100
197/197 - 0s - loss: 0.0052
Epoch 53/100
197/197 - 0s - loss: 0.0050
Epoch 54/100
197/197 - 0s - loss: 0.0054
Epoch 55/100
197/197 - 0s - loss: 0.0052
Epoch 56/100
197/197 - 0s - loss: 0.0052
Epoch 57/100
197/197 - 0s - loss: 0.0051
Epoch 58/100
197/197 - 0s - loss: 0.0049
Epoch 59/100
197/197 - 0s - loss: 0.0050
Epoch 60/100
197/197 - 0s - loss: 0.0049
Epoch 61/100
197/197 - 0s - loss: 0.0049
Epoch 62/100
197/197 - 0s - loss: 0.0050
Epoch 63/100
197/197 - 0s - loss: 0.0050
Epoch 64/100
197/197 - 0s - loss: 0.0049
Epoch 65/100
197/197 - 0s - loss: 0.0048
Epoch 66/100
197/197 - 0s - loss: 0.0050
Epoch 67/100
197/197 - 0s - loss: 0.0050
Epoch 68/100
197/197 - 0s - loss: 0.0049
Epoch 69/100
197/197 - 0s - loss: 0.0048
Epoch 70/100
197/197 - 0s - loss: 0.0047
Epoch 71/100
197/197 - 0s - loss: 0.0048
Epoch 72/100
197/197 - 0s - loss: 0.0047
Epoch 73/100
197/197 - 0s - loss: 0.0049
Epoch 74/100
197/197 - 0s - loss: 0.0046
Epoch 75/100
197/197 - 0s - loss: 0.0047
Epoch 76/100
197/197 - 0s - loss: 0.0046
Epoch 77/100
197/197 - 0s - loss: 0.0049
Epoch 78/100
197/197 - 0s - loss: 0.0047
Epoch 79/100
197/197 - 0s - loss: 0.0046
Epoch 80/100
197/197 - 0s - loss: 0.0046
Epoch 81/100
197/197 - 0s - loss: 0.0047
Epoch 82/100
197/197 - 0s - loss: 0.0047
Epoch 83/100
197/197 - 0s - loss: 0.0046
Epoch 84/100
197/197 - 0s - loss: 0.0046
Epoch 85/100
197/197 - 0s - loss: 0.0046
Epoch 86/100
197/197 - 0s - loss: 0.0044
Epoch 87/100
197/197 - 0s - loss: 0.0045
Epoch 88/100
197/197 - 0s - loss: 0.0046
Epoch 89/100
197/197 - 0s - loss: 0.0044
Epoch 90/100
197/197 - 0s - loss: 0.0045
Epoch 91/100
197/197 - 0s - loss: 0.0045
Epoch 92/100
197/197 - 0s - loss: 0.0045
Epoch 93/100
197/197 - 0s - loss: 0.0045
Epoch 94/100
197/197 - 0s - loss: 0.0044
Epoch 95/100
197/197 - 0s - loss: 0.0045
Epoch 96/100
197/197 - 0s - loss: 0.0044
Epoch 97/100
197/197 - 0s - loss: 0.0044
Epoch 98/100
197/197 - 0s - loss: 0.0044
Epoch 99/100
197/197 - 0s - loss: 0.0043
Epoch 100/100
197/197 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.154
key_word: bitcoin
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.397260  0.301370  0.630137
2021-07-18  0.534247  0.465753  0.410959  ...  0.657534  0.397260  0.301370
2021-07-25  0.534247  0.534247  0.465753  ...  0.876712  0.657534  0.397260
2021-08-01  0.410959  0.534247  0.534247  ...  0.205479  0.876712  0.657534
2021-08-08  0.534247  0.410959  0.534247  ...  0.273973  0.205479  0.876712

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_115"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_115 (LSTM)              (None, 32)                5760      
_________________________________________________________________
dense_113 (Dense)            (None, 1)                 33        
=================================================================
Total params: 5,793
Trainable params: 5,793
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0259
Epoch 2/100
197/197 - 0s - loss: 0.0069
Epoch 3/100
197/197 - 0s - loss: 0.0066
Epoch 4/100
197/197 - 0s - loss: 0.0066
Epoch 5/100
197/197 - 0s - loss: 0.0066
Epoch 6/100
197/197 - 0s - loss: 0.0063
Epoch 7/100
197/197 - 0s - loss: 0.0062
Epoch 8/100
197/197 - 0s - loss: 0.0059
Epoch 9/100
197/197 - 0s - loss: 0.0064
Epoch 10/100
197/197 - 0s - loss: 0.0059
Epoch 11/100
197/197 - 0s - loss: 0.0058
Epoch 12/100
197/197 - 0s - loss: 0.0060
Epoch 13/100
197/197 - 0s - loss: 0.0057
Epoch 14/100
197/197 - 0s - loss: 0.0061
Epoch 15/100
197/197 - 0s - loss: 0.0059
Epoch 16/100
197/197 - 0s - loss: 0.0059
Epoch 17/100
197/197 - 0s - loss: 0.0058
Epoch 18/100
197/197 - 0s - loss: 0.0060
Epoch 19/100
197/197 - 0s - loss: 0.0057
Epoch 20/100
197/197 - 0s - loss: 0.0056
Epoch 21/100
197/197 - 0s - loss: 0.0056
Epoch 22/100
197/197 - 0s - loss: 0.0058
Epoch 23/100
197/197 - 0s - loss: 0.0054
Epoch 24/100
197/197 - 0s - loss: 0.0057
Epoch 25/100
197/197 - 0s - loss: 0.0054
Epoch 26/100
197/197 - 0s - loss: 0.0054
Epoch 27/100
197/197 - 0s - loss: 0.0054
Epoch 28/100
197/197 - 0s - loss: 0.0054
Epoch 29/100
197/197 - 0s - loss: 0.0055
Epoch 30/100
197/197 - 0s - loss: 0.0056
Epoch 31/100
197/197 - 0s - loss: 0.0051
Epoch 32/100
197/197 - 0s - loss: 0.0054
Epoch 33/100
197/197 - 0s - loss: 0.0053
Epoch 34/100
197/197 - 0s - loss: 0.0055
Epoch 35/100
197/197 - 0s - loss: 0.0054
Epoch 36/100
197/197 - 0s - loss: 0.0052
Epoch 37/100
197/197 - 0s - loss: 0.0053
Epoch 38/100
197/197 - 0s - loss: 0.0055
Epoch 39/100
197/197 - 0s - loss: 0.0050
Epoch 40/100
197/197 - 0s - loss: 0.0054
Epoch 41/100
197/197 - 0s - loss: 0.0054
Epoch 42/100
197/197 - 0s - loss: 0.0054
Epoch 43/100
197/197 - 0s - loss: 0.0054
Epoch 44/100
197/197 - 0s - loss: 0.0051
Epoch 45/100
197/197 - 0s - loss: 0.0054
Epoch 46/100
197/197 - 0s - loss: 0.0053
Epoch 47/100
197/197 - 0s - loss: 0.0053
Epoch 48/100
197/197 - 0s - loss: 0.0051
Epoch 49/100
197/197 - 0s - loss: 0.0053
Epoch 50/100
197/197 - 0s - loss: 0.0054
Epoch 51/100
197/197 - 0s - loss: 0.0052
Epoch 52/100
197/197 - 0s - loss: 0.0051
Epoch 53/100
197/197 - 0s - loss: 0.0052
Epoch 54/100
197/197 - 0s - loss: 0.0050
Epoch 55/100
197/197 - 0s - loss: 0.0050
Epoch 56/100
197/197 - 0s - loss: 0.0051
Epoch 57/100
197/197 - 0s - loss: 0.0053
Epoch 58/100
197/197 - 0s - loss: 0.0051
Epoch 59/100
197/197 - 0s - loss: 0.0051
Epoch 60/100
197/197 - 0s - loss: 0.0053
Epoch 61/100
197/197 - 0s - loss: 0.0053
Epoch 62/100
197/197 - 0s - loss: 0.0049
Epoch 63/100
197/197 - 0s - loss: 0.0050
Epoch 64/100
197/197 - 0s - loss: 0.0052
Epoch 65/100
197/197 - 0s - loss: 0.0051
Epoch 66/100
197/197 - 0s - loss: 0.0049
Epoch 67/100
197/197 - 0s - loss: 0.0051
Epoch 68/100
197/197 - 0s - loss: 0.0049
Epoch 69/100
197/197 - 0s - loss: 0.0053
Epoch 70/100
197/197 - 0s - loss: 0.0053
Epoch 71/100
197/197 - 0s - loss: 0.0048
Epoch 72/100
197/197 - 0s - loss: 0.0051
Epoch 73/100
197/197 - 0s - loss: 0.0050
Epoch 74/100
197/197 - 0s - loss: 0.0049
Epoch 75/100
197/197 - 0s - loss: 0.0052
Epoch 76/100
197/197 - 0s - loss: 0.0051
Epoch 77/100
197/197 - 0s - loss: 0.0049
Epoch 78/100
197/197 - 0s - loss: 0.0049
Epoch 79/100
197/197 - 0s - loss: 0.0049
Epoch 80/100
197/197 - 0s - loss: 0.0047
Epoch 81/100
197/197 - 0s - loss: 0.0047
Epoch 82/100
197/197 - 0s - loss: 0.0049
Epoch 83/100
197/197 - 0s - loss: 0.0051
Epoch 84/100
197/197 - 0s - loss: 0.0049
Epoch 85/100
197/197 - 0s - loss: 0.0046
Epoch 86/100
197/197 - 0s - loss: 0.0049
Epoch 87/100
197/197 - 0s - loss: 0.0050
Epoch 88/100
197/197 - 0s - loss: 0.0046
Epoch 89/100
197/197 - 0s - loss: 0.0045
Epoch 90/100
197/197 - 0s - loss: 0.0046
Epoch 91/100
197/197 - 0s - loss: 0.0046
Epoch 92/100
197/197 - 0s - loss: 0.0046
Epoch 93/100
197/197 - 0s - loss: 0.0047
Epoch 94/100
197/197 - 0s - loss: 0.0047
Epoch 95/100
197/197 - 0s - loss: 0.0046
Epoch 96/100
197/197 - 0s - loss: 0.0047
Epoch 97/100
197/197 - 0s - loss: 0.0048
Epoch 98/100
197/197 - 0s - loss: 0.0047
Epoch 99/100
197/197 - 0s - loss: 0.0046
Epoch 100/100
197/197 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.152
key_word: bitcoin
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.397260  0.301370  0.630137
2021-07-18  0.534247  0.465753  0.410959  ...  0.657534  0.397260  0.301370
2021-07-25  0.534247  0.534247  0.465753  ...  0.876712  0.657534  0.397260
2021-08-01  0.410959  0.534247  0.534247  ...  0.205479  0.876712  0.657534
2021-08-08  0.534247  0.410959  0.534247  ...  0.273973  0.205479  0.876712

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_116"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_116 (LSTM)              (None, 60)                17520     
_________________________________________________________________
dense_114 (Dense)            (None, 1)                 61        
=================================================================
Total params: 17,581
Trainable params: 17,581
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0133
Epoch 2/100
197/197 - 0s - loss: 0.0064
Epoch 3/100
197/197 - 0s - loss: 0.0075
Epoch 4/100
197/197 - 0s - loss: 0.0063
Epoch 5/100
197/197 - 0s - loss: 0.0064
Epoch 6/100
197/197 - 0s - loss: 0.0064
Epoch 7/100
197/197 - 0s - loss: 0.0062
Epoch 8/100
197/197 - 0s - loss: 0.0060
Epoch 9/100
197/197 - 0s - loss: 0.0064
Epoch 10/100
197/197 - 0s - loss: 0.0060
Epoch 11/100
197/197 - 0s - loss: 0.0062
Epoch 12/100
197/197 - 0s - loss: 0.0060
Epoch 13/100
197/197 - 0s - loss: 0.0059
Epoch 14/100
197/197 - 0s - loss: 0.0056
Epoch 15/100
197/197 - 0s - loss: 0.0055
Epoch 16/100
197/197 - 0s - loss: 0.0060
Epoch 17/100
197/197 - 0s - loss: 0.0055
Epoch 18/100
197/197 - 0s - loss: 0.0060
Epoch 19/100
197/197 - 0s - loss: 0.0055
Epoch 20/100
197/197 - 0s - loss: 0.0060
Epoch 21/100
197/197 - 0s - loss: 0.0059
Epoch 22/100
197/197 - 0s - loss: 0.0054
Epoch 23/100
197/197 - 0s - loss: 0.0056
Epoch 24/100
197/197 - 0s - loss: 0.0055
Epoch 25/100
197/197 - 0s - loss: 0.0053
Epoch 26/100
197/197 - 0s - loss: 0.0055
Epoch 27/100
197/197 - 0s - loss: 0.0053
Epoch 28/100
197/197 - 0s - loss: 0.0061
Epoch 29/100
197/197 - 0s - loss: 0.0056
Epoch 30/100
197/197 - 0s - loss: 0.0055
Epoch 31/100
197/197 - 0s - loss: 0.0054
Epoch 32/100
197/197 - 0s - loss: 0.0056
Epoch 33/100
197/197 - 0s - loss: 0.0055
Epoch 34/100
197/197 - 0s - loss: 0.0056
Epoch 35/100
197/197 - 0s - loss: 0.0053
Epoch 36/100
197/197 - 0s - loss: 0.0055
Epoch 37/100
197/197 - 0s - loss: 0.0056
Epoch 38/100
197/197 - 0s - loss: 0.0055
Epoch 39/100
197/197 - 0s - loss: 0.0055
Epoch 40/100
197/197 - 0s - loss: 0.0053
Epoch 41/100
197/197 - 0s - loss: 0.0053
Epoch 42/100
197/197 - 0s - loss: 0.0056
Epoch 43/100
197/197 - 0s - loss: 0.0053
Epoch 44/100
197/197 - 0s - loss: 0.0053
Epoch 45/100
197/197 - 0s - loss: 0.0056
Epoch 46/100
197/197 - 0s - loss: 0.0052
Epoch 47/100
197/197 - 0s - loss: 0.0054
Epoch 48/100
197/197 - 0s - loss: 0.0053
Epoch 49/100
197/197 - 0s - loss: 0.0052
Epoch 50/100
197/197 - 0s - loss: 0.0054
Epoch 51/100
197/197 - 0s - loss: 0.0053
Epoch 52/100
197/197 - 0s - loss: 0.0054
Epoch 53/100
197/197 - 0s - loss: 0.0052
Epoch 54/100
197/197 - 0s - loss: 0.0051
Epoch 55/100
197/197 - 0s - loss: 0.0051
Epoch 56/100
197/197 - 0s - loss: 0.0051
Epoch 57/100
197/197 - 0s - loss: 0.0056
Epoch 58/100
197/197 - 0s - loss: 0.0052
Epoch 59/100
197/197 - 0s - loss: 0.0050
Epoch 60/100
197/197 - 0s - loss: 0.0054
Epoch 61/100
197/197 - 0s - loss: 0.0051
Epoch 62/100
197/197 - 0s - loss: 0.0052
Epoch 63/100
197/197 - 0s - loss: 0.0052
Epoch 64/100
197/197 - 0s - loss: 0.0050
Epoch 65/100
197/197 - 0s - loss: 0.0049
Epoch 66/100
197/197 - 0s - loss: 0.0051
Epoch 67/100
197/197 - 0s - loss: 0.0051
Epoch 68/100
197/197 - 0s - loss: 0.0051
Epoch 69/100
197/197 - 0s - loss: 0.0053
Epoch 70/100
197/197 - 0s - loss: 0.0054
Epoch 71/100
197/197 - 0s - loss: 0.0049
Epoch 72/100
197/197 - 0s - loss: 0.0049
Epoch 73/100
197/197 - 0s - loss: 0.0051
Epoch 74/100
197/197 - 0s - loss: 0.0051
Epoch 75/100
197/197 - 0s - loss: 0.0047
Epoch 76/100
197/197 - 0s - loss: 0.0049
Epoch 77/100
197/197 - 0s - loss: 0.0048
Epoch 78/100
197/197 - 0s - loss: 0.0050
Epoch 79/100
197/197 - 0s - loss: 0.0050
Epoch 80/100
197/197 - 0s - loss: 0.0050
Epoch 81/100
197/197 - 0s - loss: 0.0048
Epoch 82/100
197/197 - 0s - loss: 0.0049
Epoch 83/100
197/197 - 0s - loss: 0.0049
Epoch 84/100
197/197 - 0s - loss: 0.0050
Epoch 85/100
197/197 - 0s - loss: 0.0050
Epoch 86/100
197/197 - 0s - loss: 0.0048
Epoch 87/100
197/197 - 0s - loss: 0.0050
Epoch 88/100
197/197 - 0s - loss: 0.0048
Epoch 89/100
197/197 - 0s - loss: 0.0049
Epoch 90/100
197/197 - 0s - loss: 0.0047
Epoch 91/100
197/197 - 0s - loss: 0.0047
Epoch 92/100
197/197 - 0s - loss: 0.0046
Epoch 93/100
197/197 - 0s - loss: 0.0046
Epoch 94/100
197/197 - 0s - loss: 0.0046
Epoch 95/100
197/197 - 0s - loss: 0.0043
Epoch 96/100
197/197 - 0s - loss: 0.0047
Epoch 97/100
197/197 - 0s - loss: 0.0044
Epoch 98/100
197/197 - 0s - loss: 0.0044
Epoch 99/100
197/197 - 0s - loss: 0.0043
Epoch 100/100
197/197 - 0s - loss: 0.0045

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.156
key_word: bitcoin
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.835616  0.410959  0.424658
2021-07-18  0.534247  0.465753  0.410959  ...  0.438356  0.835616  0.410959
2021-07-25  0.534247  0.534247  0.465753  ...  0.561644  0.438356  0.835616
2021-08-01  0.410959  0.534247  0.534247  ...  0.178082  0.561644  0.438356
2021-08-08  0.534247  0.410959  0.534247  ...  0.493151  0.178082  0.561644

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_117"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_117 (LSTM)              (None, 4)                 464       
_________________________________________________________________
dense_115 (Dense)            (None, 1)                 5         
=================================================================
Total params: 469
Trainable params: 469
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0261
Epoch 2/100
188/188 - 0s - loss: 0.0060
Epoch 3/100
188/188 - 0s - loss: 0.0060
Epoch 4/100
188/188 - 0s - loss: 0.0061
Epoch 5/100
188/188 - 0s - loss: 0.0061
Epoch 6/100
188/188 - 0s - loss: 0.0060
Epoch 7/100
188/188 - 0s - loss: 0.0058
Epoch 8/100
188/188 - 0s - loss: 0.0062
Epoch 9/100
188/188 - 0s - loss: 0.0059
Epoch 10/100
188/188 - 0s - loss: 0.0060
Epoch 11/100
188/188 - 0s - loss: 0.0060
Epoch 12/100
188/188 - 0s - loss: 0.0061
Epoch 13/100
188/188 - 0s - loss: 0.0060
Epoch 14/100
188/188 - 0s - loss: 0.0059
Epoch 15/100
188/188 - 0s - loss: 0.0062
Epoch 16/100
188/188 - 0s - loss: 0.0059
Epoch 17/100
188/188 - 0s - loss: 0.0058
Epoch 18/100
188/188 - 0s - loss: 0.0060
Epoch 19/100
188/188 - 0s - loss: 0.0058
Epoch 20/100
188/188 - 0s - loss: 0.0057
Epoch 21/100
188/188 - 0s - loss: 0.0058
Epoch 22/100
188/188 - 0s - loss: 0.0057
Epoch 23/100
188/188 - 0s - loss: 0.0058
Epoch 24/100
188/188 - 0s - loss: 0.0058
Epoch 25/100
188/188 - 0s - loss: 0.0058
Epoch 26/100
188/188 - 0s - loss: 0.0056
Epoch 27/100
188/188 - 0s - loss: 0.0056
Epoch 28/100
188/188 - 0s - loss: 0.0057
Epoch 29/100
188/188 - 0s - loss: 0.0056
Epoch 30/100
188/188 - 0s - loss: 0.0057
Epoch 31/100
188/188 - 0s - loss: 0.0056
Epoch 32/100
188/188 - 0s - loss: 0.0058
Epoch 33/100
188/188 - 0s - loss: 0.0055
Epoch 34/100
188/188 - 0s - loss: 0.0058
Epoch 35/100
188/188 - 0s - loss: 0.0056
Epoch 36/100
188/188 - 0s - loss: 0.0055
Epoch 37/100
188/188 - 0s - loss: 0.0055
Epoch 38/100
188/188 - 0s - loss: 0.0057
Epoch 39/100
188/188 - 0s - loss: 0.0056
Epoch 40/100
188/188 - 0s - loss: 0.0056
Epoch 41/100
188/188 - 0s - loss: 0.0055
Epoch 42/100
188/188 - 0s - loss: 0.0055
Epoch 43/100
188/188 - 0s - loss: 0.0055
Epoch 44/100
188/188 - 0s - loss: 0.0055
Epoch 45/100
188/188 - 0s - loss: 0.0056
Epoch 46/100
188/188 - 0s - loss: 0.0053
Epoch 47/100
188/188 - 0s - loss: 0.0054
Epoch 48/100
188/188 - 0s - loss: 0.0055
Epoch 49/100
188/188 - 0s - loss: 0.0055
Epoch 50/100
188/188 - 0s - loss: 0.0053
Epoch 51/100
188/188 - 0s - loss: 0.0055
Epoch 52/100
188/188 - 0s - loss: 0.0055
Epoch 53/100
188/188 - 0s - loss: 0.0053
Epoch 54/100
188/188 - 0s - loss: 0.0054
Epoch 55/100
188/188 - 0s - loss: 0.0053
Epoch 56/100
188/188 - 0s - loss: 0.0052
Epoch 57/100
188/188 - 0s - loss: 0.0055
Epoch 58/100
188/188 - 0s - loss: 0.0054
Epoch 59/100
188/188 - 0s - loss: 0.0053
Epoch 60/100
188/188 - 0s - loss: 0.0052
Epoch 61/100
188/188 - 0s - loss: 0.0053
Epoch 62/100
188/188 - 0s - loss: 0.0051
Epoch 63/100
188/188 - 0s - loss: 0.0050
Epoch 64/100
188/188 - 0s - loss: 0.0052
Epoch 65/100
188/188 - 0s - loss: 0.0053
Epoch 66/100
188/188 - 0s - loss: 0.0052
Epoch 67/100
188/188 - 0s - loss: 0.0051
Epoch 68/100
188/188 - 0s - loss: 0.0053
Epoch 69/100
188/188 - 0s - loss: 0.0052
Epoch 70/100
188/188 - 0s - loss: 0.0055
Epoch 71/100
188/188 - 0s - loss: 0.0053
Epoch 72/100
188/188 - 0s - loss: 0.0051
Epoch 73/100
188/188 - 0s - loss: 0.0053
Epoch 74/100
188/188 - 0s - loss: 0.0050
Epoch 75/100
188/188 - 0s - loss: 0.0051
Epoch 76/100
188/188 - 0s - loss: 0.0051
Epoch 77/100
188/188 - 0s - loss: 0.0051
Epoch 78/100
188/188 - 0s - loss: 0.0052
Epoch 79/100
188/188 - 0s - loss: 0.0051
Epoch 80/100
188/188 - 0s - loss: 0.0049
Epoch 81/100
188/188 - 0s - loss: 0.0051
Epoch 82/100
188/188 - 0s - loss: 0.0051
Epoch 83/100
188/188 - 0s - loss: 0.0051
Epoch 84/100
188/188 - 0s - loss: 0.0050
Epoch 85/100
188/188 - 0s - loss: 0.0050
Epoch 86/100
188/188 - 0s - loss: 0.0049
Epoch 87/100
188/188 - 0s - loss: 0.0050
Epoch 88/100
188/188 - 0s - loss: 0.0053
Epoch 89/100
188/188 - 0s - loss: 0.0049
Epoch 90/100
188/188 - 0s - loss: 0.0047
Epoch 91/100
188/188 - 0s - loss: 0.0050
Epoch 92/100
188/188 - 0s - loss: 0.0048
Epoch 93/100
188/188 - 0s - loss: 0.0048
Epoch 94/100
188/188 - 0s - loss: 0.0049
Epoch 95/100
188/188 - 0s - loss: 0.0049
Epoch 96/100
188/188 - 0s - loss: 0.0047
Epoch 97/100
188/188 - 0s - loss: 0.0048
Epoch 98/100
188/188 - 0s - loss: 0.0047
Epoch 99/100
188/188 - 0s - loss: 0.0049
Epoch 100/100
188/188 - 0s - loss: 0.0046

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.068
Train RMSE: 0.163
key_word: bitcoin
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.835616  0.410959  0.424658
2021-07-18  0.534247  0.465753  0.410959  ...  0.438356  0.835616  0.410959
2021-07-25  0.534247  0.534247  0.465753  ...  0.561644  0.438356  0.835616
2021-08-01  0.410959  0.534247  0.534247  ...  0.178082  0.561644  0.438356
2021-08-08  0.534247  0.410959  0.534247  ...  0.493151  0.178082  0.561644

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_118"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_118 (LSTM)              (None, 8)                 1056      
_________________________________________________________________
dense_116 (Dense)            (None, 1)                 9         
=================================================================
Total params: 1,065
Trainable params: 1,065
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0165
Epoch 2/100
188/188 - 0s - loss: 0.0070
Epoch 3/100
188/188 - 0s - loss: 0.0070
Epoch 4/100
188/188 - 0s - loss: 0.0064
Epoch 5/100
188/188 - 0s - loss: 0.0066
Epoch 6/100
188/188 - 0s - loss: 0.0065
Epoch 7/100
188/188 - 0s - loss: 0.0067
Epoch 8/100
188/188 - 0s - loss: 0.0064
Epoch 9/100
188/188 - 0s - loss: 0.0064
Epoch 10/100
188/188 - 0s - loss: 0.0061
Epoch 11/100
188/188 - 0s - loss: 0.0065
Epoch 12/100
188/188 - 0s - loss: 0.0062
Epoch 13/100
188/188 - 0s - loss: 0.0061
Epoch 14/100
188/188 - 0s - loss: 0.0062
Epoch 15/100
188/188 - 0s - loss: 0.0063
Epoch 16/100
188/188 - 0s - loss: 0.0062
Epoch 17/100
188/188 - 0s - loss: 0.0062
Epoch 18/100
188/188 - 0s - loss: 0.0062
Epoch 19/100
188/188 - 0s - loss: 0.0060
Epoch 20/100
188/188 - 0s - loss: 0.0061
Epoch 21/100
188/188 - 0s - loss: 0.0059
Epoch 22/100
188/188 - 0s - loss: 0.0062
Epoch 23/100
188/188 - 0s - loss: 0.0059
Epoch 24/100
188/188 - 0s - loss: 0.0058
Epoch 25/100
188/188 - 0s - loss: 0.0059
Epoch 26/100
188/188 - 0s - loss: 0.0059
Epoch 27/100
188/188 - 0s - loss: 0.0060
Epoch 28/100
188/188 - 0s - loss: 0.0057
Epoch 29/100
188/188 - 0s - loss: 0.0059
Epoch 30/100
188/188 - 0s - loss: 0.0058
Epoch 31/100
188/188 - 0s - loss: 0.0058
Epoch 32/100
188/188 - 0s - loss: 0.0057
Epoch 33/100
188/188 - 0s - loss: 0.0059
Epoch 34/100
188/188 - 0s - loss: 0.0059
Epoch 35/100
188/188 - 0s - loss: 0.0058
Epoch 36/100
188/188 - 0s - loss: 0.0061
Epoch 37/100
188/188 - 0s - loss: 0.0058
Epoch 38/100
188/188 - 0s - loss: 0.0058
Epoch 39/100
188/188 - 0s - loss: 0.0057
Epoch 40/100
188/188 - 0s - loss: 0.0056
Epoch 41/100
188/188 - 0s - loss: 0.0057
Epoch 42/100
188/188 - 0s - loss: 0.0056
Epoch 43/100
188/188 - 0s - loss: 0.0059
Epoch 44/100
188/188 - 0s - loss: 0.0058
Epoch 45/100
188/188 - 0s - loss: 0.0057
Epoch 46/100
188/188 - 0s - loss: 0.0056
Epoch 47/100
188/188 - 0s - loss: 0.0059
Epoch 48/100
188/188 - 0s - loss: 0.0055
Epoch 49/100
188/188 - 0s - loss: 0.0057
Epoch 50/100
188/188 - 0s - loss: 0.0057
Epoch 51/100
188/188 - 0s - loss: 0.0055
Epoch 52/100
188/188 - 0s - loss: 0.0053
Epoch 53/100
188/188 - 0s - loss: 0.0055
Epoch 54/100
188/188 - 0s - loss: 0.0055
Epoch 55/100
188/188 - 0s - loss: 0.0054
Epoch 56/100
188/188 - 0s - loss: 0.0057
Epoch 57/100
188/188 - 0s - loss: 0.0058
Epoch 58/100
188/188 - 0s - loss: 0.0055
Epoch 59/100
188/188 - 0s - loss: 0.0058
Epoch 60/100
188/188 - 0s - loss: 0.0055
Epoch 61/100
188/188 - 0s - loss: 0.0056
Epoch 62/100
188/188 - 0s - loss: 0.0053
Epoch 63/100
188/188 - 0s - loss: 0.0057
Epoch 64/100
188/188 - 0s - loss: 0.0054
Epoch 65/100
188/188 - 0s - loss: 0.0054
Epoch 66/100
188/188 - 0s - loss: 0.0056
Epoch 67/100
188/188 - 0s - loss: 0.0053
Epoch 68/100
188/188 - 0s - loss: 0.0053
Epoch 69/100
188/188 - 0s - loss: 0.0054
Epoch 70/100
188/188 - 0s - loss: 0.0056
Epoch 71/100
188/188 - 0s - loss: 0.0053
Epoch 72/100
188/188 - 0s - loss: 0.0055
Epoch 73/100
188/188 - 0s - loss: 0.0054
Epoch 74/100
188/188 - 0s - loss: 0.0056
Epoch 75/100
188/188 - 0s - loss: 0.0055
Epoch 76/100
188/188 - 0s - loss: 0.0053
Epoch 77/100
188/188 - 0s - loss: 0.0054
Epoch 78/100
188/188 - 0s - loss: 0.0055
Epoch 79/100
188/188 - 0s - loss: 0.0054
Epoch 80/100
188/188 - 0s - loss: 0.0052
Epoch 81/100
188/188 - 0s - loss: 0.0054
Epoch 82/100
188/188 - 0s - loss: 0.0053
Epoch 83/100
188/188 - 0s - loss: 0.0057
Epoch 84/100
188/188 - 0s - loss: 0.0053
Epoch 85/100
188/188 - 0s - loss: 0.0053
Epoch 86/100
188/188 - 0s - loss: 0.0053
Epoch 87/100
188/188 - 0s - loss: 0.0052
Epoch 88/100
188/188 - 0s - loss: 0.0052
Epoch 89/100
188/188 - 0s - loss: 0.0055
Epoch 90/100
188/188 - 0s - loss: 0.0055
Epoch 91/100
188/188 - 0s - loss: 0.0053
Epoch 92/100
188/188 - 0s - loss: 0.0052
Epoch 93/100
188/188 - 0s - loss: 0.0052
Epoch 94/100
188/188 - 0s - loss: 0.0050
Epoch 95/100
188/188 - 0s - loss: 0.0055
Epoch 96/100
188/188 - 0s - loss: 0.0052
Epoch 97/100
188/188 - 0s - loss: 0.0052
Epoch 98/100
188/188 - 0s - loss: 0.0053
Epoch 99/100
188/188 - 0s - loss: 0.0053
Epoch 100/100
188/188 - 0s - loss: 0.0051

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.071
Train RMSE: 0.156
key_word: bitcoin
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.835616  0.410959  0.424658
2021-07-18  0.534247  0.465753  0.410959  ...  0.438356  0.835616  0.410959
2021-07-25  0.534247  0.534247  0.465753  ...  0.561644  0.438356  0.835616
2021-08-01  0.410959  0.534247  0.534247  ...  0.178082  0.561644  0.438356
2021-08-08  0.534247  0.410959  0.534247  ...  0.493151  0.178082  0.561644

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_119"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_119 (LSTM)              (None, 16)                2624      
_________________________________________________________________
dense_117 (Dense)            (None, 1)                 17        
=================================================================
Total params: 2,641
Trainable params: 2,641
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0451
Epoch 2/100
188/188 - 0s - loss: 0.0065
Epoch 3/100
188/188 - 0s - loss: 0.0062
Epoch 4/100
188/188 - 0s - loss: 0.0064
Epoch 5/100
188/188 - 0s - loss: 0.0063
Epoch 6/100
188/188 - 0s - loss: 0.0064
Epoch 7/100
188/188 - 0s - loss: 0.0062
Epoch 8/100
188/188 - 0s - loss: 0.0064
Epoch 9/100
188/188 - 0s - loss: 0.0060
Epoch 10/100
188/188 - 0s - loss: 0.0063
Epoch 11/100
188/188 - 0s - loss: 0.0063
Epoch 12/100
188/188 - 0s - loss: 0.0060
Epoch 13/100
188/188 - 0s - loss: 0.0062
Epoch 14/100
188/188 - 0s - loss: 0.0059
Epoch 15/100
188/188 - 0s - loss: 0.0062
Epoch 16/100
188/188 - 0s - loss: 0.0059
Epoch 17/100
188/188 - 0s - loss: 0.0060
Epoch 18/100
188/188 - 0s - loss: 0.0061
Epoch 19/100
188/188 - 0s - loss: 0.0057
Epoch 20/100
188/188 - 0s - loss: 0.0058
Epoch 21/100
188/188 - 0s - loss: 0.0058
Epoch 22/100
188/188 - 0s - loss: 0.0061
Epoch 23/100
188/188 - 0s - loss: 0.0057
Epoch 24/100
188/188 - 0s - loss: 0.0059
Epoch 25/100
188/188 - 0s - loss: 0.0062
Epoch 26/100
188/188 - 0s - loss: 0.0057
Epoch 27/100
188/188 - 0s - loss: 0.0056
Epoch 28/100
188/188 - 0s - loss: 0.0057
Epoch 29/100
188/188 - 0s - loss: 0.0057
Epoch 30/100
188/188 - 0s - loss: 0.0056
Epoch 31/100
188/188 - 0s - loss: 0.0060
Epoch 32/100
188/188 - 0s - loss: 0.0059
Epoch 33/100
188/188 - 0s - loss: 0.0055
Epoch 34/100
188/188 - 0s - loss: 0.0057
Epoch 35/100
188/188 - 0s - loss: 0.0057
Epoch 36/100
188/188 - 0s - loss: 0.0056
Epoch 37/100
188/188 - 0s - loss: 0.0057
Epoch 38/100
188/188 - 0s - loss: 0.0055
Epoch 39/100
188/188 - 0s - loss: 0.0053
Epoch 40/100
188/188 - 0s - loss: 0.0059
Epoch 41/100
188/188 - 0s - loss: 0.0056
Epoch 42/100
188/188 - 0s - loss: 0.0056
Epoch 43/100
188/188 - 0s - loss: 0.0056
Epoch 44/100
188/188 - 0s - loss: 0.0054
Epoch 45/100
188/188 - 0s - loss: 0.0057
Epoch 46/100
188/188 - 0s - loss: 0.0057
Epoch 47/100
188/188 - 0s - loss: 0.0054
Epoch 48/100
188/188 - 0s - loss: 0.0054
Epoch 49/100
188/188 - 0s - loss: 0.0055
Epoch 50/100
188/188 - 0s - loss: 0.0054
Epoch 51/100
188/188 - 0s - loss: 0.0053
Epoch 52/100
188/188 - 0s - loss: 0.0054
Epoch 53/100
188/188 - 0s - loss: 0.0055
Epoch 54/100
188/188 - 0s - loss: 0.0055
Epoch 55/100
188/188 - 0s - loss: 0.0052
Epoch 56/100
188/188 - 0s - loss: 0.0052
Epoch 57/100
188/188 - 0s - loss: 0.0055
Epoch 58/100
188/188 - 0s - loss: 0.0053
Epoch 59/100
188/188 - 0s - loss: 0.0053
Epoch 60/100
188/188 - 0s - loss: 0.0055
Epoch 61/100
188/188 - 0s - loss: 0.0053
Epoch 62/100
188/188 - 0s - loss: 0.0053
Epoch 63/100
188/188 - 0s - loss: 0.0054
Epoch 64/100
188/188 - 0s - loss: 0.0053
Epoch 65/100
188/188 - 0s - loss: 0.0053
Epoch 66/100
188/188 - 0s - loss: 0.0052
Epoch 67/100
188/188 - 0s - loss: 0.0052
Epoch 68/100
188/188 - 0s - loss: 0.0057
Epoch 69/100
188/188 - 0s - loss: 0.0052
Epoch 70/100
188/188 - 0s - loss: 0.0053
Epoch 71/100
188/188 - 0s - loss: 0.0052
Epoch 72/100
188/188 - 0s - loss: 0.0052
Epoch 73/100
188/188 - 0s - loss: 0.0054
Epoch 74/100
188/188 - 0s - loss: 0.0053
Epoch 75/100
188/188 - 0s - loss: 0.0054
Epoch 76/100
188/188 - 0s - loss: 0.0052
Epoch 77/100
188/188 - 0s - loss: 0.0054
Epoch 78/100
188/188 - 0s - loss: 0.0051
Epoch 79/100
188/188 - 0s - loss: 0.0053
Epoch 80/100
188/188 - 0s - loss: 0.0052
Epoch 81/100
188/188 - 0s - loss: 0.0051
Epoch 82/100
188/188 - 0s - loss: 0.0053
Epoch 83/100
188/188 - 0s - loss: 0.0051
Epoch 84/100
188/188 - 0s - loss: 0.0050
Epoch 85/100
188/188 - 0s - loss: 0.0051
Epoch 86/100
188/188 - 0s - loss: 0.0052
Epoch 87/100
188/188 - 0s - loss: 0.0050
Epoch 88/100
188/188 - 0s - loss: 0.0050
Epoch 89/100
188/188 - 0s - loss: 0.0052
Epoch 90/100
188/188 - 0s - loss: 0.0051
Epoch 91/100
188/188 - 0s - loss: 0.0051
Epoch 92/100
188/188 - 0s - loss: 0.0052
Epoch 93/100
188/188 - 0s - loss: 0.0050
Epoch 94/100
188/188 - 0s - loss: 0.0052
Epoch 95/100
188/188 - 0s - loss: 0.0050
Epoch 96/100
188/188 - 0s - loss: 0.0049
Epoch 97/100
188/188 - 0s - loss: 0.0050
Epoch 98/100
188/188 - 0s - loss: 0.0051
Epoch 99/100
188/188 - 0s - loss: 0.0049
Epoch 100/100
188/188 - 0s - loss: 0.0049

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.077
Train RMSE: 0.163
key_word: bitcoin
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.835616  0.410959  0.424658
2021-07-18  0.534247  0.465753  0.410959  ...  0.438356  0.835616  0.410959
2021-07-25  0.534247  0.534247  0.465753  ...  0.561644  0.438356  0.835616
2021-08-01  0.410959  0.534247  0.534247  ...  0.178082  0.561644  0.438356
2021-08-08  0.534247  0.410959  0.534247  ...  0.493151  0.178082  0.561644

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_120 (LSTM)              (None, 32)                7296      
_________________________________________________________________
dense_118 (Dense)            (None, 1)                 33        
=================================================================
Total params: 7,329
Trainable params: 7,329
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0328
Epoch 2/100
188/188 - 0s - loss: 0.0072
Epoch 3/100
188/188 - 0s - loss: 0.0068
Epoch 4/100
188/188 - 0s - loss: 0.0068
Epoch 5/100
188/188 - 0s - loss: 0.0066
Epoch 6/100
188/188 - 0s - loss: 0.0062
Epoch 7/100
188/188 - 0s - loss: 0.0066
Epoch 8/100
188/188 - 0s - loss: 0.0063
Epoch 9/100
188/188 - 0s - loss: 0.0064
Epoch 10/100
188/188 - 0s - loss: 0.0065
Epoch 11/100
188/188 - 0s - loss: 0.0068
Epoch 12/100
188/188 - 0s - loss: 0.0060
Epoch 13/100
188/188 - 0s - loss: 0.0061
Epoch 14/100
188/188 - 0s - loss: 0.0060
Epoch 15/100
188/188 - 0s - loss: 0.0060
Epoch 16/100
188/188 - 0s - loss: 0.0061
Epoch 17/100
188/188 - 0s - loss: 0.0063
Epoch 18/100
188/188 - 0s - loss: 0.0062
Epoch 19/100
188/188 - 0s - loss: 0.0059
Epoch 20/100
188/188 - 0s - loss: 0.0058
Epoch 21/100
188/188 - 0s - loss: 0.0059
Epoch 22/100
188/188 - 0s - loss: 0.0058
Epoch 23/100
188/188 - 0s - loss: 0.0055
Epoch 24/100
188/188 - 0s - loss: 0.0060
Epoch 25/100
188/188 - 0s - loss: 0.0061
Epoch 26/100
188/188 - 0s - loss: 0.0058
Epoch 27/100
188/188 - 0s - loss: 0.0059
Epoch 28/100
188/188 - 0s - loss: 0.0058
Epoch 29/100
188/188 - 0s - loss: 0.0059
Epoch 30/100
188/188 - 0s - loss: 0.0058
Epoch 31/100
188/188 - 0s - loss: 0.0053
Epoch 32/100
188/188 - 0s - loss: 0.0058
Epoch 33/100
188/188 - 0s - loss: 0.0056
Epoch 34/100
188/188 - 0s - loss: 0.0057
Epoch 35/100
188/188 - 0s - loss: 0.0059
Epoch 36/100
188/188 - 0s - loss: 0.0057
Epoch 37/100
188/188 - 0s - loss: 0.0054
Epoch 38/100
188/188 - 0s - loss: 0.0060
Epoch 39/100
188/188 - 0s - loss: 0.0054
Epoch 40/100
188/188 - 0s - loss: 0.0055
Epoch 41/100
188/188 - 0s - loss: 0.0057
Epoch 42/100
188/188 - 0s - loss: 0.0057
Epoch 43/100
188/188 - 0s - loss: 0.0055
Epoch 44/100
188/188 - 0s - loss: 0.0056
Epoch 45/100
188/188 - 0s - loss: 0.0054
Epoch 46/100
188/188 - 0s - loss: 0.0058
Epoch 47/100
188/188 - 0s - loss: 0.0054
Epoch 48/100
188/188 - 0s - loss: 0.0051
Epoch 49/100
188/188 - 0s - loss: 0.0053
Epoch 50/100
188/188 - 0s - loss: 0.0057
Epoch 51/100
188/188 - 0s - loss: 0.0055
Epoch 52/100
188/188 - 0s - loss: 0.0055
Epoch 53/100
188/188 - 0s - loss: 0.0051
Epoch 54/100
188/188 - 0s - loss: 0.0053
Epoch 55/100
188/188 - 0s - loss: 0.0053
Epoch 56/100
188/188 - 0s - loss: 0.0053
Epoch 57/100
188/188 - 0s - loss: 0.0053
Epoch 58/100
188/188 - 0s - loss: 0.0054
Epoch 59/100
188/188 - 0s - loss: 0.0054
Epoch 60/100
188/188 - 0s - loss: 0.0057
Epoch 61/100
188/188 - 0s - loss: 0.0052
Epoch 62/100
188/188 - 0s - loss: 0.0053
Epoch 63/100
188/188 - 0s - loss: 0.0052
Epoch 64/100
188/188 - 0s - loss: 0.0054
Epoch 65/100
188/188 - 0s - loss: 0.0053
Epoch 66/100
188/188 - 0s - loss: 0.0054
Epoch 67/100
188/188 - 0s - loss: 0.0054
Epoch 68/100
188/188 - 0s - loss: 0.0052
Epoch 69/100
188/188 - 0s - loss: 0.0051
Epoch 70/100
188/188 - 0s - loss: 0.0053
Epoch 71/100
188/188 - 0s - loss: 0.0053
Epoch 72/100
188/188 - 0s - loss: 0.0051
Epoch 73/100
188/188 - 0s - loss: 0.0051
Epoch 74/100
188/188 - 0s - loss: 0.0053
Epoch 75/100
188/188 - 0s - loss: 0.0051
Epoch 76/100
188/188 - 0s - loss: 0.0050
Epoch 77/100
188/188 - 0s - loss: 0.0053
Epoch 78/100
188/188 - 0s - loss: 0.0052
Epoch 79/100
188/188 - 0s - loss: 0.0052
Epoch 80/100
188/188 - 0s - loss: 0.0050
Epoch 81/100
188/188 - 0s - loss: 0.0051
Epoch 82/100
188/188 - 0s - loss: 0.0049
Epoch 83/100
188/188 - 0s - loss: 0.0049
Epoch 84/100
188/188 - 0s - loss: 0.0048
Epoch 85/100
188/188 - 0s - loss: 0.0050
Epoch 86/100
188/188 - 0s - loss: 0.0047
Epoch 87/100
188/188 - 0s - loss: 0.0052
Epoch 88/100
188/188 - 0s - loss: 0.0047
Epoch 89/100
188/188 - 0s - loss: 0.0048
Epoch 90/100
188/188 - 0s - loss: 0.0048
Epoch 91/100
188/188 - 0s - loss: 0.0048
Epoch 92/100
188/188 - 0s - loss: 0.0046
Epoch 93/100
188/188 - 0s - loss: 0.0053
Epoch 94/100
188/188 - 0s - loss: 0.0046
Epoch 95/100
188/188 - 0s - loss: 0.0047
Epoch 96/100
188/188 - 0s - loss: 0.0046
Epoch 97/100
188/188 - 0s - loss: 0.0044
Epoch 98/100
188/188 - 0s - loss: 0.0047
Epoch 99/100
188/188 - 0s - loss: 0.0045
Epoch 100/100
188/188 - 0s - loss: 0.0044

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.161
key_word: bitcoin
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.465753  0.410959  0.301370  ...  0.835616  0.410959  0.424658
2021-07-18  0.534247  0.465753  0.410959  ...  0.438356  0.835616  0.410959
2021-07-25  0.534247  0.534247  0.465753  ...  0.561644  0.438356  0.835616
2021-08-01  0.410959  0.534247  0.534247  ...  0.178082  0.561644  0.438356
2021-08-08  0.534247  0.410959  0.534247  ...  0.493151  0.178082  0.561644

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_121 (LSTM)              (None, 60)                20400     
_________________________________________________________________
dense_119 (Dense)            (None, 1)                 61        
=================================================================
Total params: 20,461
Trainable params: 20,461
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0146
Epoch 2/100
188/188 - 0s - loss: 0.0070
Epoch 3/100
188/188 - 0s - loss: 0.0069
Epoch 4/100
188/188 - 0s - loss: 0.0069
Epoch 5/100
188/188 - 0s - loss: 0.0064
Epoch 6/100
188/188 - 0s - loss: 0.0066
Epoch 7/100
188/188 - 0s - loss: 0.0062
Epoch 8/100
188/188 - 0s - loss: 0.0070
Epoch 9/100
188/188 - 0s - loss: 0.0067
Epoch 10/100
188/188 - 0s - loss: 0.0065
Epoch 11/100
188/188 - 0s - loss: 0.0060
Epoch 12/100
188/188 - 0s - loss: 0.0064
Epoch 13/100
188/188 - 0s - loss: 0.0061
Epoch 14/100
188/188 - 0s - loss: 0.0059
Epoch 15/100
188/188 - 0s - loss: 0.0066
Epoch 16/100
188/188 - 0s - loss: 0.0061
Epoch 17/100
188/188 - 0s - loss: 0.0059
Epoch 18/100
188/188 - 0s - loss: 0.0060
Epoch 19/100
188/188 - 0s - loss: 0.0061
Epoch 20/100
188/188 - 0s - loss: 0.0059
Epoch 21/100
188/188 - 0s - loss: 0.0059
Epoch 22/100
188/188 - 0s - loss: 0.0060
Epoch 23/100
188/188 - 0s - loss: 0.0059
Epoch 24/100
188/188 - 0s - loss: 0.0059
Epoch 25/100
188/188 - 0s - loss: 0.0061
Epoch 26/100
188/188 - 0s - loss: 0.0058
Epoch 27/100
188/188 - 0s - loss: 0.0058
Epoch 28/100
188/188 - 0s - loss: 0.0060
Epoch 29/100
188/188 - 0s - loss: 0.0056
Epoch 30/100
188/188 - 0s - loss: 0.0056
Epoch 31/100
188/188 - 0s - loss: 0.0055
Epoch 32/100
188/188 - 0s - loss: 0.0056
Epoch 33/100
188/188 - 0s - loss: 0.0057
Epoch 34/100
188/188 - 0s - loss: 0.0057
Epoch 35/100
188/188 - 0s - loss: 0.0056
Epoch 36/100
188/188 - 0s - loss: 0.0057
Epoch 37/100
188/188 - 0s - loss: 0.0057
Epoch 38/100
188/188 - 0s - loss: 0.0059
Epoch 39/100
188/188 - 0s - loss: 0.0056
Epoch 40/100
188/188 - 0s - loss: 0.0059
Epoch 41/100
188/188 - 0s - loss: 0.0056
Epoch 42/100
188/188 - 0s - loss: 0.0054
Epoch 43/100
188/188 - 0s - loss: 0.0058
Epoch 44/100
188/188 - 0s - loss: 0.0055
Epoch 45/100
188/188 - 0s - loss: 0.0052
Epoch 46/100
188/188 - 0s - loss: 0.0055
Epoch 47/100
188/188 - 0s - loss: 0.0054
Epoch 48/100
188/188 - 0s - loss: 0.0056
Epoch 49/100
188/188 - 0s - loss: 0.0058
Epoch 50/100
188/188 - 0s - loss: 0.0054
Epoch 51/100
188/188 - 0s - loss: 0.0057
Epoch 52/100
188/188 - 0s - loss: 0.0056
Epoch 53/100
188/188 - 0s - loss: 0.0056
Epoch 54/100
188/188 - 0s - loss: 0.0056
Epoch 55/100
188/188 - 0s - loss: 0.0059
Epoch 56/100
188/188 - 0s - loss: 0.0053
Epoch 57/100
188/188 - 0s - loss: 0.0054
Epoch 58/100
188/188 - 0s - loss: 0.0055
Epoch 59/100
188/188 - 0s - loss: 0.0054
Epoch 60/100
188/188 - 0s - loss: 0.0057
Epoch 61/100
188/188 - 0s - loss: 0.0055
Epoch 62/100
188/188 - 0s - loss: 0.0054
Epoch 63/100
188/188 - 0s - loss: 0.0055
Epoch 64/100
188/188 - 0s - loss: 0.0057
Epoch 65/100
188/188 - 0s - loss: 0.0056
Epoch 66/100
188/188 - 0s - loss: 0.0053
Epoch 67/100
188/188 - 0s - loss: 0.0057
Epoch 68/100
188/188 - 0s - loss: 0.0051
Epoch 69/100
188/188 - 0s - loss: 0.0056
Epoch 70/100
188/188 - 0s - loss: 0.0053
Epoch 71/100
188/188 - 0s - loss: 0.0051
Epoch 72/100
188/188 - 0s - loss: 0.0056
Epoch 73/100
188/188 - 0s - loss: 0.0052
Epoch 74/100
188/188 - 0s - loss: 0.0054
Epoch 75/100
188/188 - 0s - loss: 0.0052
Epoch 76/100
188/188 - 0s - loss: 0.0050
Epoch 77/100
188/188 - 0s - loss: 0.0052
Epoch 78/100
188/188 - 0s - loss: 0.0053
Epoch 79/100
188/188 - 0s - loss: 0.0052
Epoch 80/100
188/188 - 0s - loss: 0.0051
Epoch 81/100
188/188 - 0s - loss: 0.0051
Epoch 82/100
188/188 - 0s - loss: 0.0051
Epoch 83/100
188/188 - 0s - loss: 0.0052
Epoch 84/100
188/188 - 0s - loss: 0.0053
Epoch 85/100
188/188 - 0s - loss: 0.0053
Epoch 86/100
188/188 - 0s - loss: 0.0052
Epoch 87/100
188/188 - 0s - loss: 0.0050
Epoch 88/100
188/188 - 0s - loss: 0.0050
Epoch 89/100
188/188 - 0s - loss: 0.0050
Epoch 90/100
188/188 - 0s - loss: 0.0052
Epoch 91/100
188/188 - 0s - loss: 0.0053
Epoch 92/100
188/188 - 0s - loss: 0.0052
Epoch 93/100
188/188 - 0s - loss: 0.0051
Epoch 94/100
188/188 - 0s - loss: 0.0052
Epoch 95/100
188/188 - 0s - loss: 0.0048
Epoch 96/100
188/188 - 0s - loss: 0.0052
Epoch 97/100
188/188 - 0s - loss: 0.0050
Epoch 98/100
188/188 - 0s - loss: 0.0049
Epoch 99/100
188/188 - 0s - loss: 0.0049
Epoch 100/100
188/188 - 0s - loss: 0.0046

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.067
Train RMSE: 0.155
key_word: bitcoin
window size: 24
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.504505  0.513514  0.522523
2021-07-18  0.522523  0.522523  0.513514  ...  0.621622  0.504505  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.396396  0.621622  0.504505
2021-08-01  0.621622  0.513514  0.522523  ...  0.504505  0.396396  0.621622
2021-08-08  0.405405  0.621622  0.513514  ...  0.504505  0.504505  0.396396

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_122 (LSTM)              (None, 4)                 272       
_________________________________________________________________
dense_120 (Dense)            (None, 1)                 5         
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0836
Epoch 2/100
197/197 - 0s - loss: 0.0037
Epoch 3/100
197/197 - 0s - loss: 0.0037
Epoch 4/100
197/197 - 0s - loss: 0.0038
Epoch 5/100
197/197 - 0s - loss: 0.0037
Epoch 6/100
197/197 - 0s - loss: 0.0038
Epoch 7/100
197/197 - 0s - loss: 0.0038
Epoch 8/100
197/197 - 0s - loss: 0.0036
Epoch 9/100
197/197 - 0s - loss: 0.0037
Epoch 10/100
197/197 - 0s - loss: 0.0037
Epoch 11/100
197/197 - 0s - loss: 0.0036
Epoch 12/100
197/197 - 0s - loss: 0.0037
Epoch 13/100
197/197 - 0s - loss: 0.0038
Epoch 14/100
197/197 - 0s - loss: 0.0038
Epoch 15/100
197/197 - 0s - loss: 0.0036
Epoch 16/100
197/197 - 0s - loss: 0.0037
Epoch 17/100
197/197 - 0s - loss: 0.0036
Epoch 18/100
197/197 - 0s - loss: 0.0036
Epoch 19/100
197/197 - 0s - loss: 0.0037
Epoch 20/100
197/197 - 0s - loss: 0.0037
Epoch 21/100
197/197 - 0s - loss: 0.0037
Epoch 22/100
197/197 - 0s - loss: 0.0037
Epoch 23/100
197/197 - 0s - loss: 0.0036
Epoch 24/100
197/197 - 0s - loss: 0.0037
Epoch 25/100
197/197 - 0s - loss: 0.0036
Epoch 26/100
197/197 - 0s - loss: 0.0037
Epoch 27/100
197/197 - 0s - loss: 0.0036
Epoch 28/100
197/197 - 0s - loss: 0.0037
Epoch 29/100
197/197 - 0s - loss: 0.0035
Epoch 30/100
197/197 - 0s - loss: 0.0038
Epoch 31/100
197/197 - 0s - loss: 0.0035
Epoch 32/100
197/197 - 0s - loss: 0.0036
Epoch 33/100
197/197 - 0s - loss: 0.0036
Epoch 34/100
197/197 - 0s - loss: 0.0036
Epoch 35/100
197/197 - 0s - loss: 0.0036
Epoch 36/100
197/197 - 0s - loss: 0.0035
Epoch 37/100
197/197 - 0s - loss: 0.0034
Epoch 38/100
197/197 - 0s - loss: 0.0035
Epoch 39/100
197/197 - 0s - loss: 0.0035
Epoch 40/100
197/197 - 0s - loss: 0.0035
Epoch 41/100
197/197 - 0s - loss: 0.0035
Epoch 42/100
197/197 - 0s - loss: 0.0035
Epoch 43/100
197/197 - 0s - loss: 0.0035
Epoch 44/100
197/197 - 0s - loss: 0.0036
Epoch 45/100
197/197 - 0s - loss: 0.0035
Epoch 46/100
197/197 - 0s - loss: 0.0034
Epoch 47/100
197/197 - 0s - loss: 0.0035
Epoch 48/100
197/197 - 0s - loss: 0.0036
Epoch 49/100
197/197 - 0s - loss: 0.0035
Epoch 50/100
197/197 - 0s - loss: 0.0035
Epoch 51/100
197/197 - 0s - loss: 0.0035
Epoch 52/100
197/197 - 0s - loss: 0.0034
Epoch 53/100
197/197 - 0s - loss: 0.0034
Epoch 54/100
197/197 - 0s - loss: 0.0035
Epoch 55/100
197/197 - 0s - loss: 0.0035
Epoch 56/100
197/197 - 0s - loss: 0.0034
Epoch 57/100
197/197 - 0s - loss: 0.0034
Epoch 58/100
197/197 - 0s - loss: 0.0035
Epoch 59/100
197/197 - 0s - loss: 0.0034
Epoch 60/100
197/197 - 0s - loss: 0.0035
Epoch 61/100
197/197 - 0s - loss: 0.0035
Epoch 62/100
197/197 - 0s - loss: 0.0034
Epoch 63/100
197/197 - 0s - loss: 0.0034
Epoch 64/100
197/197 - 0s - loss: 0.0035
Epoch 65/100
197/197 - 0s - loss: 0.0034
Epoch 66/100
197/197 - 0s - loss: 0.0035
Epoch 67/100
197/197 - 0s - loss: 0.0035
Epoch 68/100
197/197 - 0s - loss: 0.0036
Epoch 69/100
197/197 - 0s - loss: 0.0034
Epoch 70/100
197/197 - 0s - loss: 0.0034
Epoch 71/100
197/197 - 0s - loss: 0.0034
Epoch 72/100
197/197 - 0s - loss: 0.0033
Epoch 73/100
197/197 - 0s - loss: 0.0035
Epoch 74/100
197/197 - 0s - loss: 0.0035
Epoch 75/100
197/197 - 0s - loss: 0.0034
Epoch 76/100
197/197 - 0s - loss: 0.0035
Epoch 77/100
197/197 - 0s - loss: 0.0035
Epoch 78/100
197/197 - 0s - loss: 0.0034
Epoch 79/100
197/197 - 0s - loss: 0.0034
Epoch 80/100
197/197 - 0s - loss: 0.0034
Epoch 81/100
197/197 - 0s - loss: 0.0034
Epoch 82/100
197/197 - 0s - loss: 0.0034
Epoch 83/100
197/197 - 0s - loss: 0.0034
Epoch 84/100
197/197 - 0s - loss: 0.0034
Epoch 85/100
197/197 - 0s - loss: 0.0034
Epoch 86/100
197/197 - 0s - loss: 0.0034
Epoch 87/100
197/197 - 0s - loss: 0.0033
Epoch 88/100
197/197 - 0s - loss: 0.0034
Epoch 89/100
197/197 - 0s - loss: 0.0035
Epoch 90/100
197/197 - 0s - loss: 0.0033
Epoch 91/100
197/197 - 0s - loss: 0.0034
Epoch 92/100
197/197 - 0s - loss: 0.0034
Epoch 93/100
197/197 - 0s - loss: 0.0034
Epoch 94/100
197/197 - 0s - loss: 0.0034
Epoch 95/100
197/197 - 0s - loss: 0.0034
Epoch 96/100
197/197 - 0s - loss: 0.0033
Epoch 97/100
197/197 - 0s - loss: 0.0034
Epoch 98/100
197/197 - 0s - loss: 0.0034
Epoch 99/100
197/197 - 0s - loss: 0.0034
Epoch 100/100
197/197 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.057
Train RMSE: 0.083
key_word: COVID-19
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.504505  0.513514  0.522523
2021-07-18  0.522523  0.522523  0.513514  ...  0.621622  0.504505  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.396396  0.621622  0.504505
2021-08-01  0.621622  0.513514  0.522523  ...  0.504505  0.396396  0.621622
2021-08-08  0.405405  0.621622  0.513514  ...  0.504505  0.504505  0.396396

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_123 (LSTM)              (None, 8)                 672       
_________________________________________________________________
dense_121 (Dense)            (None, 1)                 9         
=================================================================
Total params: 681
Trainable params: 681
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0197
Epoch 2/100
197/197 - 0s - loss: 0.0041
Epoch 3/100
197/197 - 0s - loss: 0.0042
Epoch 4/100
197/197 - 0s - loss: 0.0042
Epoch 5/100
197/197 - 0s - loss: 0.0040
Epoch 6/100
197/197 - 0s - loss: 0.0040
Epoch 7/100
197/197 - 0s - loss: 0.0041
Epoch 8/100
197/197 - 0s - loss: 0.0041
Epoch 9/100
197/197 - 0s - loss: 0.0039
Epoch 10/100
197/197 - 0s - loss: 0.0040
Epoch 11/100
197/197 - 0s - loss: 0.0040
Epoch 12/100
197/197 - 0s - loss: 0.0039
Epoch 13/100
197/197 - 0s - loss: 0.0040
Epoch 14/100
197/197 - 0s - loss: 0.0038
Epoch 15/100
197/197 - 0s - loss: 0.0040
Epoch 16/100
197/197 - 0s - loss: 0.0039
Epoch 17/100
197/197 - 0s - loss: 0.0038
Epoch 18/100
197/197 - 0s - loss: 0.0038
Epoch 19/100
197/197 - 0s - loss: 0.0038
Epoch 20/100
197/197 - 0s - loss: 0.0036
Epoch 21/100
197/197 - 0s - loss: 0.0037
Epoch 22/100
197/197 - 0s - loss: 0.0039
Epoch 23/100
197/197 - 0s - loss: 0.0038
Epoch 24/100
197/197 - 0s - loss: 0.0037
Epoch 25/100
197/197 - 0s - loss: 0.0038
Epoch 26/100
197/197 - 0s - loss: 0.0037
Epoch 27/100
197/197 - 0s - loss: 0.0038
Epoch 28/100
197/197 - 0s - loss: 0.0037
Epoch 29/100
197/197 - 0s - loss: 0.0038
Epoch 30/100
197/197 - 0s - loss: 0.0037
Epoch 31/100
197/197 - 0s - loss: 0.0036
Epoch 32/100
197/197 - 0s - loss: 0.0037
Epoch 33/100
197/197 - 0s - loss: 0.0037
Epoch 34/100
197/197 - 0s - loss: 0.0037
Epoch 35/100
197/197 - 0s - loss: 0.0037
Epoch 36/100
197/197 - 0s - loss: 0.0037
Epoch 37/100
197/197 - 0s - loss: 0.0037
Epoch 38/100
197/197 - 0s - loss: 0.0038
Epoch 39/100
197/197 - 0s - loss: 0.0035
Epoch 40/100
197/197 - 0s - loss: 0.0037
Epoch 41/100
197/197 - 0s - loss: 0.0037
Epoch 42/100
197/197 - 0s - loss: 0.0036
Epoch 43/100
197/197 - 0s - loss: 0.0036
Epoch 44/100
197/197 - 0s - loss: 0.0035
Epoch 45/100
197/197 - 0s - loss: 0.0037
Epoch 46/100
197/197 - 0s - loss: 0.0036
Epoch 47/100
197/197 - 0s - loss: 0.0036
Epoch 48/100
197/197 - 0s - loss: 0.0036
Epoch 49/100
197/197 - 0s - loss: 0.0036
Epoch 50/100
197/197 - 0s - loss: 0.0035
Epoch 51/100
197/197 - 0s - loss: 0.0036
Epoch 52/100
197/197 - 0s - loss: 0.0034
Epoch 53/100
197/197 - 0s - loss: 0.0035
Epoch 54/100
197/197 - 0s - loss: 0.0036
Epoch 55/100
197/197 - 0s - loss: 0.0035
Epoch 56/100
197/197 - 0s - loss: 0.0036
Epoch 57/100
197/197 - 0s - loss: 0.0034
Epoch 58/100
197/197 - 0s - loss: 0.0037
Epoch 59/100
197/197 - 0s - loss: 0.0037
Epoch 60/100
197/197 - 0s - loss: 0.0035
Epoch 61/100
197/197 - 0s - loss: 0.0035
Epoch 62/100
197/197 - 0s - loss: 0.0037
Epoch 63/100
197/197 - 0s - loss: 0.0036
Epoch 64/100
197/197 - 0s - loss: 0.0035
Epoch 65/100
197/197 - 0s - loss: 0.0035
Epoch 66/100
197/197 - 0s - loss: 0.0035
Epoch 67/100
197/197 - 0s - loss: 0.0034
Epoch 68/100
197/197 - 0s - loss: 0.0036
Epoch 69/100
197/197 - 0s - loss: 0.0034
Epoch 70/100
197/197 - 0s - loss: 0.0035
Epoch 71/100
197/197 - 0s - loss: 0.0035
Epoch 72/100
197/197 - 0s - loss: 0.0035
Epoch 73/100
197/197 - 0s - loss: 0.0036
Epoch 74/100
197/197 - 0s - loss: 0.0035
Epoch 75/100
197/197 - 0s - loss: 0.0035
Epoch 76/100
197/197 - 0s - loss: 0.0034
Epoch 77/100
197/197 - 0s - loss: 0.0035
Epoch 78/100
197/197 - 0s - loss: 0.0035
Epoch 79/100
197/197 - 0s - loss: 0.0036
Epoch 80/100
197/197 - 0s - loss: 0.0035
Epoch 81/100
197/197 - 0s - loss: 0.0035
Epoch 82/100
197/197 - 0s - loss: 0.0036
Epoch 83/100
197/197 - 0s - loss: 0.0034
Epoch 84/100
197/197 - 0s - loss: 0.0034
Epoch 85/100
197/197 - 0s - loss: 0.0035
Epoch 86/100
197/197 - 0s - loss: 0.0035
Epoch 87/100
197/197 - 0s - loss: 0.0035
Epoch 88/100
197/197 - 0s - loss: 0.0035
Epoch 89/100
197/197 - 0s - loss: 0.0035
Epoch 90/100
197/197 - 0s - loss: 0.0034
Epoch 91/100
197/197 - 0s - loss: 0.0034
Epoch 92/100
197/197 - 0s - loss: 0.0035
Epoch 93/100
197/197 - 0s - loss: 0.0034
Epoch 94/100
197/197 - 0s - loss: 0.0033
Epoch 95/100
197/197 - 0s - loss: 0.0036
Epoch 96/100
197/197 - 0s - loss: 0.0035
Epoch 97/100
197/197 - 0s - loss: 0.0034
Epoch 98/100
197/197 - 0s - loss: 0.0034
Epoch 99/100
197/197 - 0s - loss: 0.0034
Epoch 100/100
197/197 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.060
Train RMSE: 0.083
key_word: COVID-19
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.504505  0.513514  0.522523
2021-07-18  0.522523  0.522523  0.513514  ...  0.621622  0.504505  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.396396  0.621622  0.504505
2021-08-01  0.621622  0.513514  0.522523  ...  0.504505  0.396396  0.621622
2021-08-08  0.405405  0.621622  0.513514  ...  0.504505  0.504505  0.396396

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_124 (LSTM)              (None, 16)                1856      
_________________________________________________________________
dense_122 (Dense)            (None, 1)                 17        
=================================================================
Total params: 1,873
Trainable params: 1,873
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0332
Epoch 2/100
197/197 - 0s - loss: 0.0038
Epoch 3/100
197/197 - 0s - loss: 0.0039
Epoch 4/100
197/197 - 0s - loss: 0.0040
Epoch 5/100
197/197 - 0s - loss: 0.0040
Epoch 6/100
197/197 - 0s - loss: 0.0041
Epoch 7/100
197/197 - 0s - loss: 0.0039
Epoch 8/100
197/197 - 0s - loss: 0.0039
Epoch 9/100
197/197 - 0s - loss: 0.0039
Epoch 10/100
197/197 - 0s - loss: 0.0038
Epoch 11/100
197/197 - 0s - loss: 0.0037
Epoch 12/100
197/197 - 0s - loss: 0.0038
Epoch 13/100
197/197 - 0s - loss: 0.0039
Epoch 14/100
197/197 - 0s - loss: 0.0039
Epoch 15/100
197/197 - 0s - loss: 0.0038
Epoch 16/100
197/197 - 0s - loss: 0.0038
Epoch 17/100
197/197 - 0s - loss: 0.0038
Epoch 18/100
197/197 - 0s - loss: 0.0039
Epoch 19/100
197/197 - 0s - loss: 0.0038
Epoch 20/100
197/197 - 0s - loss: 0.0038
Epoch 21/100
197/197 - 0s - loss: 0.0037
Epoch 22/100
197/197 - 0s - loss: 0.0039
Epoch 23/100
197/197 - 0s - loss: 0.0037
Epoch 24/100
197/197 - 0s - loss: 0.0039
Epoch 25/100
197/197 - 0s - loss: 0.0037
Epoch 26/100
197/197 - 0s - loss: 0.0036
Epoch 27/100
197/197 - 0s - loss: 0.0036
Epoch 28/100
197/197 - 0s - loss: 0.0037
Epoch 29/100
197/197 - 0s - loss: 0.0037
Epoch 30/100
197/197 - 0s - loss: 0.0036
Epoch 31/100
197/197 - 0s - loss: 0.0036
Epoch 32/100
197/197 - 0s - loss: 0.0035
Epoch 33/100
197/197 - 0s - loss: 0.0036
Epoch 34/100
197/197 - 0s - loss: 0.0036
Epoch 35/100
197/197 - 0s - loss: 0.0036
Epoch 36/100
197/197 - 0s - loss: 0.0037
Epoch 37/100
197/197 - 0s - loss: 0.0036
Epoch 38/100
197/197 - 0s - loss: 0.0036
Epoch 39/100
197/197 - 0s - loss: 0.0036
Epoch 40/100
197/197 - 0s - loss: 0.0037
Epoch 41/100
197/197 - 0s - loss: 0.0035
Epoch 42/100
197/197 - 0s - loss: 0.0036
Epoch 43/100
197/197 - 0s - loss: 0.0036
Epoch 44/100
197/197 - 0s - loss: 0.0036
Epoch 45/100
197/197 - 0s - loss: 0.0036
Epoch 46/100
197/197 - 0s - loss: 0.0036
Epoch 47/100
197/197 - 0s - loss: 0.0036
Epoch 48/100
197/197 - 0s - loss: 0.0037
Epoch 49/100
197/197 - 0s - loss: 0.0034
Epoch 50/100
197/197 - 0s - loss: 0.0035
Epoch 51/100
197/197 - 0s - loss: 0.0035
Epoch 52/100
197/197 - 0s - loss: 0.0035
Epoch 53/100
197/197 - 0s - loss: 0.0036
Epoch 54/100
197/197 - 0s - loss: 0.0035
Epoch 55/100
197/197 - 0s - loss: 0.0035
Epoch 56/100
197/197 - 0s - loss: 0.0036
Epoch 57/100
197/197 - 0s - loss: 0.0035
Epoch 58/100
197/197 - 0s - loss: 0.0035
Epoch 59/100
197/197 - 0s - loss: 0.0036
Epoch 60/100
197/197 - 0s - loss: 0.0034
Epoch 61/100
197/197 - 0s - loss: 0.0035
Epoch 62/100
197/197 - 0s - loss: 0.0035
Epoch 63/100
197/197 - 0s - loss: 0.0035
Epoch 64/100
197/197 - 0s - loss: 0.0036
Epoch 65/100
197/197 - 0s - loss: 0.0035
Epoch 66/100
197/197 - 0s - loss: 0.0034
Epoch 67/100
197/197 - 0s - loss: 0.0035
Epoch 68/100
197/197 - 0s - loss: 0.0035
Epoch 69/100
197/197 - 0s - loss: 0.0035
Epoch 70/100
197/197 - 0s - loss: 0.0035
Epoch 71/100
197/197 - 0s - loss: 0.0034
Epoch 72/100
197/197 - 0s - loss: 0.0035
Epoch 73/100
197/197 - 0s - loss: 0.0035
Epoch 74/100
197/197 - 0s - loss: 0.0034
Epoch 75/100
197/197 - 0s - loss: 0.0034
Epoch 76/100
197/197 - 0s - loss: 0.0035
Epoch 77/100
197/197 - 0s - loss: 0.0035
Epoch 78/100
197/197 - 0s - loss: 0.0035
Epoch 79/100
197/197 - 0s - loss: 0.0034
Epoch 80/100
197/197 - 0s - loss: 0.0034
Epoch 81/100
197/197 - 0s - loss: 0.0034
Epoch 82/100
197/197 - 0s - loss: 0.0034
Epoch 83/100
197/197 - 0s - loss: 0.0034
Epoch 84/100
197/197 - 0s - loss: 0.0034
Epoch 85/100
197/197 - 0s - loss: 0.0034
Epoch 86/100
197/197 - 0s - loss: 0.0034
Epoch 87/100
197/197 - 0s - loss: 0.0033
Epoch 88/100
197/197 - 0s - loss: 0.0035
Epoch 89/100
197/197 - 0s - loss: 0.0033
Epoch 90/100
197/197 - 0s - loss: 0.0034
Epoch 91/100
197/197 - 0s - loss: 0.0034
Epoch 92/100
197/197 - 0s - loss: 0.0033
Epoch 93/100
197/197 - 0s - loss: 0.0035
Epoch 94/100
197/197 - 0s - loss: 0.0034
Epoch 95/100
197/197 - 0s - loss: 0.0034
Epoch 96/100
197/197 - 0s - loss: 0.0035
Epoch 97/100
197/197 - 0s - loss: 0.0034
Epoch 98/100
197/197 - 0s - loss: 0.0034
Epoch 99/100
197/197 - 0s - loss: 0.0035
Epoch 100/100
197/197 - 0s - loss: 0.0034

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.057
Train RMSE: 0.082
key_word: COVID-19
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.504505  0.513514  0.522523
2021-07-18  0.522523  0.522523  0.513514  ...  0.621622  0.504505  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.396396  0.621622  0.504505
2021-08-01  0.621622  0.513514  0.522523  ...  0.504505  0.396396  0.621622
2021-08-08  0.405405  0.621622  0.513514  ...  0.504505  0.504505  0.396396

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_125 (LSTM)              (None, 32)                5760      
_________________________________________________________________
dense_123 (Dense)            (None, 1)                 33        
=================================================================
Total params: 5,793
Trainable params: 5,793
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0159
Epoch 2/100
197/197 - 0s - loss: 0.0042
Epoch 3/100
197/197 - 0s - loss: 0.0042
Epoch 4/100
197/197 - 0s - loss: 0.0040
Epoch 5/100
197/197 - 0s - loss: 0.0042
Epoch 6/100
197/197 - 0s - loss: 0.0041
Epoch 7/100
197/197 - 0s - loss: 0.0040
Epoch 8/100
197/197 - 0s - loss: 0.0040
Epoch 9/100
197/197 - 0s - loss: 0.0041
Epoch 10/100
197/197 - 0s - loss: 0.0039
Epoch 11/100
197/197 - 0s - loss: 0.0039
Epoch 12/100
197/197 - 0s - loss: 0.0038
Epoch 13/100
197/197 - 0s - loss: 0.0038
Epoch 14/100
197/197 - 0s - loss: 0.0040
Epoch 15/100
197/197 - 0s - loss: 0.0039
Epoch 16/100
197/197 - 0s - loss: 0.0040
Epoch 17/100
197/197 - 0s - loss: 0.0040
Epoch 18/100
197/197 - 0s - loss: 0.0038
Epoch 19/100
197/197 - 0s - loss: 0.0037
Epoch 20/100
197/197 - 0s - loss: 0.0038
Epoch 21/100
197/197 - 0s - loss: 0.0037
Epoch 22/100
197/197 - 0s - loss: 0.0038
Epoch 23/100
197/197 - 0s - loss: 0.0039
Epoch 24/100
197/197 - 0s - loss: 0.0037
Epoch 25/100
197/197 - 0s - loss: 0.0039
Epoch 26/100
197/197 - 0s - loss: 0.0038
Epoch 27/100
197/197 - 0s - loss: 0.0036
Epoch 28/100
197/197 - 0s - loss: 0.0039
Epoch 29/100
197/197 - 0s - loss: 0.0038
Epoch 30/100
197/197 - 0s - loss: 0.0037
Epoch 31/100
197/197 - 0s - loss: 0.0041
Epoch 32/100
197/197 - 0s - loss: 0.0038
Epoch 33/100
197/197 - 0s - loss: 0.0036
Epoch 34/100
197/197 - 0s - loss: 0.0036
Epoch 35/100
197/197 - 0s - loss: 0.0039
Epoch 36/100
197/197 - 0s - loss: 0.0037
Epoch 37/100
197/197 - 0s - loss: 0.0038
Epoch 38/100
197/197 - 0s - loss: 0.0037
Epoch 39/100
197/197 - 0s - loss: 0.0036
Epoch 40/100
197/197 - 0s - loss: 0.0037
Epoch 41/100
197/197 - 0s - loss: 0.0038
Epoch 42/100
197/197 - 0s - loss: 0.0036
Epoch 43/100
197/197 - 0s - loss: 0.0035
Epoch 44/100
197/197 - 0s - loss: 0.0036
Epoch 45/100
197/197 - 0s - loss: 0.0038
Epoch 46/100
197/197 - 0s - loss: 0.0036
Epoch 47/100
197/197 - 0s - loss: 0.0036
Epoch 48/100
197/197 - 0s - loss: 0.0035
Epoch 49/100
197/197 - 0s - loss: 0.0036
Epoch 50/100
197/197 - 0s - loss: 0.0036
Epoch 51/100
197/197 - 0s - loss: 0.0037
Epoch 52/100
197/197 - 0s - loss: 0.0037
Epoch 53/100
197/197 - 0s - loss: 0.0035
Epoch 54/100
197/197 - 0s - loss: 0.0036
Epoch 55/100
197/197 - 0s - loss: 0.0036
Epoch 56/100
197/197 - 0s - loss: 0.0036
Epoch 57/100
197/197 - 0s - loss: 0.0035
Epoch 58/100
197/197 - 0s - loss: 0.0035
Epoch 59/100
197/197 - 0s - loss: 0.0036
Epoch 60/100
197/197 - 0s - loss: 0.0034
Epoch 61/100
197/197 - 0s - loss: 0.0035
Epoch 62/100
197/197 - 0s - loss: 0.0035
Epoch 63/100
197/197 - 0s - loss: 0.0036
Epoch 64/100
197/197 - 0s - loss: 0.0035
Epoch 65/100
197/197 - 0s - loss: 0.0035
Epoch 66/100
197/197 - 0s - loss: 0.0034
Epoch 67/100
197/197 - 0s - loss: 0.0035
Epoch 68/100
197/197 - 0s - loss: 0.0036
Epoch 69/100
197/197 - 0s - loss: 0.0034
Epoch 70/100
197/197 - 0s - loss: 0.0034
Epoch 71/100
197/197 - 0s - loss: 0.0034
Epoch 72/100
197/197 - 0s - loss: 0.0034
Epoch 73/100
197/197 - 0s - loss: 0.0035
Epoch 74/100
197/197 - 0s - loss: 0.0035
Epoch 75/100
197/197 - 0s - loss: 0.0034
Epoch 76/100
197/197 - 0s - loss: 0.0035
Epoch 77/100
197/197 - 0s - loss: 0.0033
Epoch 78/100
197/197 - 0s - loss: 0.0034
Epoch 79/100
197/197 - 0s - loss: 0.0034
Epoch 80/100
197/197 - 0s - loss: 0.0035
Epoch 81/100
197/197 - 0s - loss: 0.0034
Epoch 82/100
197/197 - 0s - loss: 0.0034
Epoch 83/100
197/197 - 0s - loss: 0.0033
Epoch 84/100
197/197 - 0s - loss: 0.0036
Epoch 85/100
197/197 - 0s - loss: 0.0034
Epoch 86/100
197/197 - 0s - loss: 0.0035
Epoch 87/100
197/197 - 0s - loss: 0.0036
Epoch 88/100
197/197 - 0s - loss: 0.0035
Epoch 89/100
197/197 - 0s - loss: 0.0033
Epoch 90/100
197/197 - 0s - loss: 0.0036
Epoch 91/100
197/197 - 0s - loss: 0.0034
Epoch 92/100
197/197 - 0s - loss: 0.0035
Epoch 93/100
197/197 - 0s - loss: 0.0035
Epoch 94/100
197/197 - 0s - loss: 0.0034
Epoch 95/100
197/197 - 0s - loss: 0.0034
Epoch 96/100
197/197 - 0s - loss: 0.0035
Epoch 97/100
197/197 - 0s - loss: 0.0033
Epoch 98/100
197/197 - 0s - loss: 0.0034
Epoch 99/100
197/197 - 0s - loss: 0.0033
Epoch 100/100
197/197 - 0s - loss: 0.0035

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.057
Train RMSE: 0.081
key_word: COVID-19
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.504505  0.513514  0.522523
2021-07-18  0.522523  0.522523  0.513514  ...  0.621622  0.504505  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.396396  0.621622  0.504505
2021-08-01  0.621622  0.513514  0.522523  ...  0.504505  0.396396  0.621622
2021-08-08  0.405405  0.621622  0.513514  ...  0.504505  0.504505  0.396396

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_126 (LSTM)              (None, 60)                17520     
_________________________________________________________________
dense_124 (Dense)            (None, 1)                 61        
=================================================================
Total params: 17,581
Trainable params: 17,581
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0148
Epoch 2/100
197/197 - 0s - loss: 0.0040
Epoch 3/100
197/197 - 0s - loss: 0.0041
Epoch 4/100
197/197 - 0s - loss: 0.0043
Epoch 5/100
197/197 - 0s - loss: 0.0045
Epoch 6/100
197/197 - 0s - loss: 0.0042
Epoch 7/100
197/197 - 0s - loss: 0.0043
Epoch 8/100
197/197 - 0s - loss: 0.0041
Epoch 9/100
197/197 - 0s - loss: 0.0041
Epoch 10/100
197/197 - 0s - loss: 0.0040
Epoch 11/100
197/197 - 0s - loss: 0.0039
Epoch 12/100
197/197 - 0s - loss: 0.0038
Epoch 13/100
197/197 - 0s - loss: 0.0039
Epoch 14/100
197/197 - 0s - loss: 0.0040
Epoch 15/100
197/197 - 0s - loss: 0.0041
Epoch 16/100
197/197 - 0s - loss: 0.0039
Epoch 17/100
197/197 - 0s - loss: 0.0038
Epoch 18/100
197/197 - 0s - loss: 0.0039
Epoch 19/100
197/197 - 0s - loss: 0.0039
Epoch 20/100
197/197 - 0s - loss: 0.0037
Epoch 21/100
197/197 - 0s - loss: 0.0041
Epoch 22/100
197/197 - 0s - loss: 0.0038
Epoch 23/100
197/197 - 0s - loss: 0.0037
Epoch 24/100
197/197 - 0s - loss: 0.0039
Epoch 25/100
197/197 - 0s - loss: 0.0039
Epoch 26/100
197/197 - 0s - loss: 0.0036
Epoch 27/100
197/197 - 0s - loss: 0.0036
Epoch 28/100
197/197 - 0s - loss: 0.0038
Epoch 29/100
197/197 - 0s - loss: 0.0038
Epoch 30/100
197/197 - 0s - loss: 0.0037
Epoch 31/100
197/197 - 0s - loss: 0.0040
Epoch 32/100
197/197 - 0s - loss: 0.0038
Epoch 33/100
197/197 - 0s - loss: 0.0036
Epoch 34/100
197/197 - 0s - loss: 0.0041
Epoch 35/100
197/197 - 0s - loss: 0.0037
Epoch 36/100
197/197 - 0s - loss: 0.0038
Epoch 37/100
197/197 - 0s - loss: 0.0036
Epoch 38/100
197/197 - 0s - loss: 0.0037
Epoch 39/100
197/197 - 0s - loss: 0.0036
Epoch 40/100
197/197 - 0s - loss: 0.0035
Epoch 41/100
197/197 - 0s - loss: 0.0037
Epoch 42/100
197/197 - 0s - loss: 0.0036
Epoch 43/100
197/197 - 0s - loss: 0.0036
Epoch 44/100
197/197 - 0s - loss: 0.0036
Epoch 45/100
197/197 - 0s - loss: 0.0036
Epoch 46/100
197/197 - 0s - loss: 0.0037
Epoch 47/100
197/197 - 0s - loss: 0.0036
Epoch 48/100
197/197 - 0s - loss: 0.0037
Epoch 49/100
197/197 - 0s - loss: 0.0037
Epoch 50/100
197/197 - 0s - loss: 0.0038
Epoch 51/100
197/197 - 0s - loss: 0.0035
Epoch 52/100
197/197 - 0s - loss: 0.0037
Epoch 53/100
197/197 - 0s - loss: 0.0035
Epoch 54/100
197/197 - 0s - loss: 0.0036
Epoch 55/100
197/197 - 0s - loss: 0.0039
Epoch 56/100
197/197 - 0s - loss: 0.0034
Epoch 57/100
197/197 - 0s - loss: 0.0036
Epoch 58/100
197/197 - 0s - loss: 0.0036
Epoch 59/100
197/197 - 0s - loss: 0.0034
Epoch 60/100
197/197 - 0s - loss: 0.0036
Epoch 61/100
197/197 - 0s - loss: 0.0035
Epoch 62/100
197/197 - 0s - loss: 0.0036
Epoch 63/100
197/197 - 0s - loss: 0.0035
Epoch 64/100
197/197 - 0s - loss: 0.0036
Epoch 65/100
197/197 - 0s - loss: 0.0035
Epoch 66/100
197/197 - 0s - loss: 0.0035
Epoch 67/100
197/197 - 0s - loss: 0.0034
Epoch 68/100
197/197 - 0s - loss: 0.0037
Epoch 69/100
197/197 - 0s - loss: 0.0035
Epoch 70/100
197/197 - 0s - loss: 0.0034
Epoch 71/100
197/197 - 0s - loss: 0.0036
Epoch 72/100
197/197 - 0s - loss: 0.0034
Epoch 73/100
197/197 - 0s - loss: 0.0034
Epoch 74/100
197/197 - 0s - loss: 0.0038
Epoch 75/100
197/197 - 0s - loss: 0.0034
Epoch 76/100
197/197 - 0s - loss: 0.0035
Epoch 77/100
197/197 - 0s - loss: 0.0034
Epoch 78/100
197/197 - 0s - loss: 0.0036
Epoch 79/100
197/197 - 0s - loss: 0.0035
Epoch 80/100
197/197 - 0s - loss: 0.0035
Epoch 81/100
197/197 - 0s - loss: 0.0034
Epoch 82/100
197/197 - 0s - loss: 0.0034
Epoch 83/100
197/197 - 0s - loss: 0.0035
Epoch 84/100
197/197 - 0s - loss: 0.0035
Epoch 85/100
197/197 - 0s - loss: 0.0034
Epoch 86/100
197/197 - 0s - loss: 0.0034
Epoch 87/100
197/197 - 0s - loss: 0.0034
Epoch 88/100
197/197 - 0s - loss: 0.0035
Epoch 89/100
197/197 - 0s - loss: 0.0035
Epoch 90/100
197/197 - 0s - loss: 0.0033
Epoch 91/100
197/197 - 0s - loss: 0.0036
Epoch 92/100
197/197 - 0s - loss: 0.0034
Epoch 93/100
197/197 - 0s - loss: 0.0035
Epoch 94/100
197/197 - 0s - loss: 0.0035
Epoch 95/100
197/197 - 0s - loss: 0.0034
Epoch 96/100
197/197 - 0s - loss: 0.0034
Epoch 97/100
197/197 - 0s - loss: 0.0035
Epoch 98/100
197/197 - 0s - loss: 0.0033
Epoch 99/100
197/197 - 0s - loss: 0.0034
Epoch 100/100
197/197 - 0s - loss: 0.0035

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.064
Train RMSE: 0.085
key_word: COVID-19
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.513514  0.513514  0.513514
2021-07-18  0.522523  0.522523  0.513514  ...  0.504505  0.513514  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.522523  0.504505  0.513514
2021-08-01  0.621622  0.513514  0.522523  ...  0.522523  0.522523  0.504505
2021-08-08  0.405405  0.621622  0.513514  ...  0.522523  0.522523  0.522523

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_127 (LSTM)              (None, 4)                 464       
_________________________________________________________________
dense_125 (Dense)            (None, 1)                 5         
=================================================================
Total params: 469
Trainable params: 469
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0520
Epoch 2/100
188/188 - 0s - loss: 0.0039
Epoch 3/100
188/188 - 0s - loss: 0.0040
Epoch 4/100
188/188 - 0s - loss: 0.0038
Epoch 5/100
188/188 - 0s - loss: 0.0039
Epoch 6/100
188/188 - 0s - loss: 0.0040
Epoch 7/100
188/188 - 0s - loss: 0.0040
Epoch 8/100
188/188 - 0s - loss: 0.0040
Epoch 9/100
188/188 - 0s - loss: 0.0039
Epoch 10/100
188/188 - 0s - loss: 0.0039
Epoch 11/100
188/188 - 0s - loss: 0.0039
Epoch 12/100
188/188 - 0s - loss: 0.0040
Epoch 13/100
188/188 - 0s - loss: 0.0039
Epoch 14/100
188/188 - 0s - loss: 0.0042
Epoch 15/100
188/188 - 0s - loss: 0.0038
Epoch 16/100
188/188 - 0s - loss: 0.0037
Epoch 17/100
188/188 - 0s - loss: 0.0037
Epoch 18/100
188/188 - 0s - loss: 0.0039
Epoch 19/100
188/188 - 0s - loss: 0.0037
Epoch 20/100
188/188 - 0s - loss: 0.0038
Epoch 21/100
188/188 - 0s - loss: 0.0038
Epoch 22/100
188/188 - 0s - loss: 0.0038
Epoch 23/100
188/188 - 0s - loss: 0.0038
Epoch 24/100
188/188 - 0s - loss: 0.0037
Epoch 25/100
188/188 - 0s - loss: 0.0039
Epoch 26/100
188/188 - 0s - loss: 0.0037
Epoch 27/100
188/188 - 0s - loss: 0.0038
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0038
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0036
Epoch 32/100
188/188 - 0s - loss: 0.0038
Epoch 33/100
188/188 - 0s - loss: 0.0035
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0037
Epoch 36/100
188/188 - 0s - loss: 0.0037
Epoch 37/100
188/188 - 0s - loss: 0.0037
Epoch 38/100
188/188 - 0s - loss: 0.0036
Epoch 39/100
188/188 - 0s - loss: 0.0036
Epoch 40/100
188/188 - 0s - loss: 0.0036
Epoch 41/100
188/188 - 0s - loss: 0.0036
Epoch 42/100
188/188 - 0s - loss: 0.0036
Epoch 43/100
188/188 - 0s - loss: 0.0035
Epoch 44/100
188/188 - 0s - loss: 0.0035
Epoch 45/100
188/188 - 0s - loss: 0.0034
Epoch 46/100
188/188 - 0s - loss: 0.0039
Epoch 47/100
188/188 - 0s - loss: 0.0035
Epoch 48/100
188/188 - 0s - loss: 0.0034
Epoch 49/100
188/188 - 0s - loss: 0.0035
Epoch 50/100
188/188 - 0s - loss: 0.0034
Epoch 51/100
188/188 - 0s - loss: 0.0035
Epoch 52/100
188/188 - 0s - loss: 0.0037
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0034
Epoch 55/100
188/188 - 0s - loss: 0.0036
Epoch 56/100
188/188 - 0s - loss: 0.0034
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0034
Epoch 59/100
188/188 - 0s - loss: 0.0036
Epoch 60/100
188/188 - 0s - loss: 0.0035
Epoch 61/100
188/188 - 0s - loss: 0.0034
Epoch 62/100
188/188 - 0s - loss: 0.0035
Epoch 63/100
188/188 - 0s - loss: 0.0035
Epoch 64/100
188/188 - 0s - loss: 0.0033
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0034
Epoch 67/100
188/188 - 0s - loss: 0.0033
Epoch 68/100
188/188 - 0s - loss: 0.0034
Epoch 69/100
188/188 - 0s - loss: 0.0034
Epoch 70/100
188/188 - 0s - loss: 0.0034
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0034
Epoch 73/100
188/188 - 0s - loss: 0.0033
Epoch 74/100
188/188 - 0s - loss: 0.0034
Epoch 75/100
188/188 - 0s - loss: 0.0034
Epoch 76/100
188/188 - 0s - loss: 0.0034
Epoch 77/100
188/188 - 0s - loss: 0.0033
Epoch 78/100
188/188 - 0s - loss: 0.0032
Epoch 79/100
188/188 - 0s - loss: 0.0033
Epoch 80/100
188/188 - 0s - loss: 0.0033
Epoch 81/100
188/188 - 0s - loss: 0.0034
Epoch 82/100
188/188 - 0s - loss: 0.0034
Epoch 83/100
188/188 - 0s - loss: 0.0033
Epoch 84/100
188/188 - 0s - loss: 0.0033
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0032
Epoch 87/100
188/188 - 0s - loss: 0.0034
Epoch 88/100
188/188 - 0s - loss: 0.0033
Epoch 89/100
188/188 - 0s - loss: 0.0033
Epoch 90/100
188/188 - 0s - loss: 0.0033
Epoch 91/100
188/188 - 0s - loss: 0.0033
Epoch 92/100
188/188 - 0s - loss: 0.0032
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0032
Epoch 95/100
188/188 - 0s - loss: 0.0032
Epoch 96/100
188/188 - 0s - loss: 0.0033
Epoch 97/100
188/188 - 0s - loss: 0.0031
Epoch 98/100
188/188 - 0s - loss: 0.0032
Epoch 99/100
188/188 - 0s - loss: 0.0031
Epoch 100/100
188/188 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.054
Train RMSE: 0.088
key_word: COVID-19
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.513514  0.513514  0.513514
2021-07-18  0.522523  0.522523  0.513514  ...  0.504505  0.513514  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.522523  0.504505  0.513514
2021-08-01  0.621622  0.513514  0.522523  ...  0.522523  0.522523  0.504505
2021-08-08  0.405405  0.621622  0.513514  ...  0.522523  0.522523  0.522523

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_128 (LSTM)              (None, 8)                 1056      
_________________________________________________________________
dense_126 (Dense)            (None, 1)                 9         
=================================================================
Total params: 1,065
Trainable params: 1,065
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0145
Epoch 2/100
188/188 - 0s - loss: 0.0045
Epoch 3/100
188/188 - 0s - loss: 0.0044
Epoch 4/100
188/188 - 0s - loss: 0.0046
Epoch 5/100
188/188 - 0s - loss: 0.0042
Epoch 6/100
188/188 - 0s - loss: 0.0045
Epoch 7/100
188/188 - 0s - loss: 0.0042
Epoch 8/100
188/188 - 0s - loss: 0.0042
Epoch 9/100
188/188 - 0s - loss: 0.0041
Epoch 10/100
188/188 - 0s - loss: 0.0043
Epoch 11/100
188/188 - 0s - loss: 0.0043
Epoch 12/100
188/188 - 0s - loss: 0.0041
Epoch 13/100
188/188 - 0s - loss: 0.0040
Epoch 14/100
188/188 - 0s - loss: 0.0040
Epoch 15/100
188/188 - 0s - loss: 0.0040
Epoch 16/100
188/188 - 0s - loss: 0.0039
Epoch 17/100
188/188 - 0s - loss: 0.0039
Epoch 18/100
188/188 - 0s - loss: 0.0039
Epoch 19/100
188/188 - 0s - loss: 0.0043
Epoch 20/100
188/188 - 0s - loss: 0.0039
Epoch 21/100
188/188 - 0s - loss: 0.0038
Epoch 22/100
188/188 - 0s - loss: 0.0039
Epoch 23/100
188/188 - 0s - loss: 0.0038
Epoch 24/100
188/188 - 0s - loss: 0.0039
Epoch 25/100
188/188 - 0s - loss: 0.0037
Epoch 26/100
188/188 - 0s - loss: 0.0038
Epoch 27/100
188/188 - 0s - loss: 0.0038
Epoch 28/100
188/188 - 0s - loss: 0.0039
Epoch 29/100
188/188 - 0s - loss: 0.0038
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0039
Epoch 32/100
188/188 - 0s - loss: 0.0037
Epoch 33/100
188/188 - 0s - loss: 0.0037
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0037
Epoch 36/100
188/188 - 0s - loss: 0.0037
Epoch 37/100
188/188 - 0s - loss: 0.0036
Epoch 38/100
188/188 - 0s - loss: 0.0037
Epoch 39/100
188/188 - 0s - loss: 0.0037
Epoch 40/100
188/188 - 0s - loss: 0.0036
Epoch 41/100
188/188 - 0s - loss: 0.0037
Epoch 42/100
188/188 - 0s - loss: 0.0037
Epoch 43/100
188/188 - 0s - loss: 0.0036
Epoch 44/100
188/188 - 0s - loss: 0.0036
Epoch 45/100
188/188 - 0s - loss: 0.0034
Epoch 46/100
188/188 - 0s - loss: 0.0034
Epoch 47/100
188/188 - 0s - loss: 0.0034
Epoch 48/100
188/188 - 0s - loss: 0.0036
Epoch 49/100
188/188 - 0s - loss: 0.0035
Epoch 50/100
188/188 - 0s - loss: 0.0037
Epoch 51/100
188/188 - 0s - loss: 0.0036
Epoch 52/100
188/188 - 0s - loss: 0.0036
Epoch 53/100
188/188 - 0s - loss: 0.0036
Epoch 54/100
188/188 - 0s - loss: 0.0035
Epoch 55/100
188/188 - 0s - loss: 0.0035
Epoch 56/100
188/188 - 0s - loss: 0.0036
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0036
Epoch 59/100
188/188 - 0s - loss: 0.0036
Epoch 60/100
188/188 - 0s - loss: 0.0035
Epoch 61/100
188/188 - 0s - loss: 0.0036
Epoch 62/100
188/188 - 0s - loss: 0.0035
Epoch 63/100
188/188 - 0s - loss: 0.0033
Epoch 64/100
188/188 - 0s - loss: 0.0035
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0035
Epoch 67/100
188/188 - 0s - loss: 0.0034
Epoch 68/100
188/188 - 0s - loss: 0.0035
Epoch 69/100
188/188 - 0s - loss: 0.0035
Epoch 70/100
188/188 - 0s - loss: 0.0034
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0033
Epoch 73/100
188/188 - 0s - loss: 0.0035
Epoch 74/100
188/188 - 0s - loss: 0.0033
Epoch 75/100
188/188 - 0s - loss: 0.0034
Epoch 76/100
188/188 - 0s - loss: 0.0034
Epoch 77/100
188/188 - 0s - loss: 0.0037
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0036
Epoch 80/100
188/188 - 0s - loss: 0.0036
Epoch 81/100
188/188 - 0s - loss: 0.0034
Epoch 82/100
188/188 - 0s - loss: 0.0035
Epoch 83/100
188/188 - 0s - loss: 0.0035
Epoch 84/100
188/188 - 0s - loss: 0.0033
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0033
Epoch 87/100
188/188 - 0s - loss: 0.0033
Epoch 88/100
188/188 - 0s - loss: 0.0033
Epoch 89/100
188/188 - 0s - loss: 0.0033
Epoch 90/100
188/188 - 0s - loss: 0.0034
Epoch 91/100
188/188 - 0s - loss: 0.0034
Epoch 92/100
188/188 - 0s - loss: 0.0033
Epoch 93/100
188/188 - 0s - loss: 0.0035
Epoch 94/100
188/188 - 0s - loss: 0.0033
Epoch 95/100
188/188 - 0s - loss: 0.0033
Epoch 96/100
188/188 - 0s - loss: 0.0032
Epoch 97/100
188/188 - 0s - loss: 0.0034
Epoch 98/100
188/188 - 0s - loss: 0.0032
Epoch 99/100
188/188 - 0s - loss: 0.0032
Epoch 100/100
188/188 - 0s - loss: 0.0033

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.058
Train RMSE: 0.086
key_word: COVID-19
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.513514  0.513514  0.513514
2021-07-18  0.522523  0.522523  0.513514  ...  0.504505  0.513514  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.522523  0.504505  0.513514
2021-08-01  0.621622  0.513514  0.522523  ...  0.522523  0.522523  0.504505
2021-08-08  0.405405  0.621622  0.513514  ...  0.522523  0.522523  0.522523

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_129 (LSTM)              (None, 16)                2624      
_________________________________________________________________
dense_127 (Dense)            (None, 1)                 17        
=================================================================
Total params: 2,641
Trainable params: 2,641
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0226
Epoch 2/100
188/188 - 0s - loss: 0.0046
Epoch 3/100
188/188 - 0s - loss: 0.0045
Epoch 4/100
188/188 - 0s - loss: 0.0046
Epoch 5/100
188/188 - 0s - loss: 0.0045
Epoch 6/100
188/188 - 0s - loss: 0.0050
Epoch 7/100
188/188 - 0s - loss: 0.0048
Epoch 8/100
188/188 - 0s - loss: 0.0044
Epoch 9/100
188/188 - 0s - loss: 0.0043
Epoch 10/100
188/188 - 0s - loss: 0.0042
Epoch 11/100
188/188 - 0s - loss: 0.0043
Epoch 12/100
188/188 - 0s - loss: 0.0040
Epoch 13/100
188/188 - 0s - loss: 0.0043
Epoch 14/100
188/188 - 0s - loss: 0.0039
Epoch 15/100
188/188 - 0s - loss: 0.0041
Epoch 16/100
188/188 - 0s - loss: 0.0041
Epoch 17/100
188/188 - 0s - loss: 0.0042
Epoch 18/100
188/188 - 0s - loss: 0.0044
Epoch 19/100
188/188 - 0s - loss: 0.0040
Epoch 20/100
188/188 - 0s - loss: 0.0040
Epoch 21/100
188/188 - 0s - loss: 0.0039
Epoch 22/100
188/188 - 0s - loss: 0.0039
Epoch 23/100
188/188 - 0s - loss: 0.0040
Epoch 24/100
188/188 - 0s - loss: 0.0039
Epoch 25/100
188/188 - 0s - loss: 0.0037
Epoch 26/100
188/188 - 0s - loss: 0.0040
Epoch 27/100
188/188 - 0s - loss: 0.0038
Epoch 28/100
188/188 - 0s - loss: 0.0036
Epoch 29/100
188/188 - 0s - loss: 0.0038
Epoch 30/100
188/188 - 0s - loss: 0.0036
Epoch 31/100
188/188 - 0s - loss: 0.0037
Epoch 32/100
188/188 - 0s - loss: 0.0037
Epoch 33/100
188/188 - 0s - loss: 0.0039
Epoch 34/100
188/188 - 0s - loss: 0.0037
Epoch 35/100
188/188 - 0s - loss: 0.0037
Epoch 36/100
188/188 - 0s - loss: 0.0037
Epoch 37/100
188/188 - 0s - loss: 0.0038
Epoch 38/100
188/188 - 0s - loss: 0.0037
Epoch 39/100
188/188 - 0s - loss: 0.0036
Epoch 40/100
188/188 - 0s - loss: 0.0037
Epoch 41/100
188/188 - 0s - loss: 0.0035
Epoch 42/100
188/188 - 0s - loss: 0.0036
Epoch 43/100
188/188 - 0s - loss: 0.0035
Epoch 44/100
188/188 - 0s - loss: 0.0035
Epoch 45/100
188/188 - 0s - loss: 0.0036
Epoch 46/100
188/188 - 0s - loss: 0.0036
Epoch 47/100
188/188 - 0s - loss: 0.0032
Epoch 48/100
188/188 - 0s - loss: 0.0035
Epoch 49/100
188/188 - 0s - loss: 0.0035
Epoch 50/100
188/188 - 0s - loss: 0.0034
Epoch 51/100
188/188 - 0s - loss: 0.0034
Epoch 52/100
188/188 - 0s - loss: 0.0036
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0035
Epoch 55/100
188/188 - 0s - loss: 0.0035
Epoch 56/100
188/188 - 0s - loss: 0.0035
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0034
Epoch 59/100
188/188 - 0s - loss: 0.0036
Epoch 60/100
188/188 - 0s - loss: 0.0032
Epoch 61/100
188/188 - 0s - loss: 0.0035
Epoch 62/100
188/188 - 0s - loss: 0.0033
Epoch 63/100
188/188 - 0s - loss: 0.0032
Epoch 64/100
188/188 - 0s - loss: 0.0032
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0033
Epoch 67/100
188/188 - 0s - loss: 0.0033
Epoch 68/100
188/188 - 0s - loss: 0.0034
Epoch 69/100
188/188 - 0s - loss: 0.0031
Epoch 70/100
188/188 - 0s - loss: 0.0031
Epoch 71/100
188/188 - 0s - loss: 0.0033
Epoch 72/100
188/188 - 0s - loss: 0.0033
Epoch 73/100
188/188 - 0s - loss: 0.0031
Epoch 74/100
188/188 - 0s - loss: 0.0032
Epoch 75/100
188/188 - 0s - loss: 0.0034
Epoch 76/100
188/188 - 0s - loss: 0.0030
Epoch 77/100
188/188 - 0s - loss: 0.0035
Epoch 78/100
188/188 - 0s - loss: 0.0036
Epoch 79/100
188/188 - 0s - loss: 0.0033
Epoch 80/100
188/188 - 0s - loss: 0.0031
Epoch 81/100
188/188 - 0s - loss: 0.0031
Epoch 82/100
188/188 - 0s - loss: 0.0031
Epoch 83/100
188/188 - 0s - loss: 0.0034
Epoch 84/100
188/188 - 0s - loss: 0.0031
Epoch 85/100
188/188 - 0s - loss: 0.0032
Epoch 86/100
188/188 - 0s - loss: 0.0031
Epoch 87/100
188/188 - 0s - loss: 0.0032
Epoch 88/100
188/188 - 0s - loss: 0.0031
Epoch 89/100
188/188 - 0s - loss: 0.0031
Epoch 90/100
188/188 - 0s - loss: 0.0032
Epoch 91/100
188/188 - 0s - loss: 0.0030
Epoch 92/100
188/188 - 0s - loss: 0.0032
Epoch 93/100
188/188 - 0s - loss: 0.0030
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0029
Epoch 96/100
188/188 - 0s - loss: 0.0030
Epoch 97/100
188/188 - 0s - loss: 0.0030
Epoch 98/100
188/188 - 0s - loss: 0.0031
Epoch 99/100
188/188 - 0s - loss: 0.0032
Epoch 100/100
188/188 - 0s - loss: 0.0030

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.052
Train RMSE: 0.088
key_word: COVID-19
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.513514  0.513514  0.513514
2021-07-18  0.522523  0.522523  0.513514  ...  0.504505  0.513514  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.522523  0.504505  0.513514
2021-08-01  0.621622  0.513514  0.522523  ...  0.522523  0.522523  0.504505
2021-08-08  0.405405  0.621622  0.513514  ...  0.522523  0.522523  0.522523

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_130 (LSTM)              (None, 32)                7296      
_________________________________________________________________
dense_128 (Dense)            (None, 1)                 33        
=================================================================
Total params: 7,329
Trainable params: 7,329
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0127
Epoch 2/100
188/188 - 0s - loss: 0.0044
Epoch 3/100
188/188 - 0s - loss: 0.0045
Epoch 4/100
188/188 - 0s - loss: 0.0041
Epoch 5/100
188/188 - 0s - loss: 0.0042
Epoch 6/100
188/188 - 0s - loss: 0.0042
Epoch 7/100
188/188 - 0s - loss: 0.0045
Epoch 8/100
188/188 - 0s - loss: 0.0043
Epoch 9/100
188/188 - 0s - loss: 0.0045
Epoch 10/100
188/188 - 0s - loss: 0.0045
Epoch 11/100
188/188 - 0s - loss: 0.0044
Epoch 12/100
188/188 - 0s - loss: 0.0038
Epoch 13/100
188/188 - 0s - loss: 0.0043
Epoch 14/100
188/188 - 0s - loss: 0.0040
Epoch 15/100
188/188 - 0s - loss: 0.0041
Epoch 16/100
188/188 - 0s - loss: 0.0039
Epoch 17/100
188/188 - 0s - loss: 0.0042
Epoch 18/100
188/188 - 0s - loss: 0.0037
Epoch 19/100
188/188 - 0s - loss: 0.0040
Epoch 20/100
188/188 - 0s - loss: 0.0039
Epoch 21/100
188/188 - 0s - loss: 0.0038
Epoch 22/100
188/188 - 0s - loss: 0.0037
Epoch 23/100
188/188 - 0s - loss: 0.0037
Epoch 24/100
188/188 - 0s - loss: 0.0036
Epoch 25/100
188/188 - 0s - loss: 0.0037
Epoch 26/100
188/188 - 0s - loss: 0.0037
Epoch 27/100
188/188 - 0s - loss: 0.0039
Epoch 28/100
188/188 - 0s - loss: 0.0038
Epoch 29/100
188/188 - 0s - loss: 0.0036
Epoch 30/100
188/188 - 0s - loss: 0.0036
Epoch 31/100
188/188 - 0s - loss: 0.0036
Epoch 32/100
188/188 - 0s - loss: 0.0038
Epoch 33/100
188/188 - 0s - loss: 0.0038
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0038
Epoch 36/100
188/188 - 0s - loss: 0.0035
Epoch 37/100
188/188 - 0s - loss: 0.0037
Epoch 38/100
188/188 - 0s - loss: 0.0037
Epoch 39/100
188/188 - 0s - loss: 0.0037
Epoch 40/100
188/188 - 0s - loss: 0.0036
Epoch 41/100
188/188 - 0s - loss: 0.0036
Epoch 42/100
188/188 - 0s - loss: 0.0035
Epoch 43/100
188/188 - 0s - loss: 0.0035
Epoch 44/100
188/188 - 0s - loss: 0.0037
Epoch 45/100
188/188 - 0s - loss: 0.0037
Epoch 46/100
188/188 - 0s - loss: 0.0035
Epoch 47/100
188/188 - 0s - loss: 0.0040
Epoch 48/100
188/188 - 0s - loss: 0.0036
Epoch 49/100
188/188 - 0s - loss: 0.0037
Epoch 50/100
188/188 - 0s - loss: 0.0034
Epoch 51/100
188/188 - 0s - loss: 0.0035
Epoch 52/100
188/188 - 0s - loss: 0.0036
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0036
Epoch 55/100
188/188 - 0s - loss: 0.0034
Epoch 56/100
188/188 - 0s - loss: 0.0034
Epoch 57/100
188/188 - 0s - loss: 0.0035
Epoch 58/100
188/188 - 0s - loss: 0.0036
Epoch 59/100
188/188 - 0s - loss: 0.0034
Epoch 60/100
188/188 - 0s - loss: 0.0034
Epoch 61/100
188/188 - 0s - loss: 0.0034
Epoch 62/100
188/188 - 0s - loss: 0.0033
Epoch 63/100
188/188 - 0s - loss: 0.0034
Epoch 64/100
188/188 - 0s - loss: 0.0034
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0035
Epoch 67/100
188/188 - 0s - loss: 0.0035
Epoch 68/100
188/188 - 0s - loss: 0.0035
Epoch 69/100
188/188 - 0s - loss: 0.0034
Epoch 70/100
188/188 - 0s - loss: 0.0033
Epoch 71/100
188/188 - 0s - loss: 0.0035
Epoch 72/100
188/188 - 0s - loss: 0.0034
Epoch 73/100
188/188 - 0s - loss: 0.0033
Epoch 74/100
188/188 - 0s - loss: 0.0031
Epoch 75/100
188/188 - 0s - loss: 0.0035
Epoch 76/100
188/188 - 0s - loss: 0.0032
Epoch 77/100
188/188 - 0s - loss: 0.0033
Epoch 78/100
188/188 - 0s - loss: 0.0032
Epoch 79/100
188/188 - 0s - loss: 0.0033
Epoch 80/100
188/188 - 0s - loss: 0.0032
Epoch 81/100
188/188 - 0s - loss: 0.0033
Epoch 82/100
188/188 - 0s - loss: 0.0030
Epoch 83/100
188/188 - 0s - loss: 0.0035
Epoch 84/100
188/188 - 0s - loss: 0.0035
Epoch 85/100
188/188 - 0s - loss: 0.0032
Epoch 86/100
188/188 - 0s - loss: 0.0032
Epoch 87/100
188/188 - 0s - loss: 0.0031
Epoch 88/100
188/188 - 0s - loss: 0.0032
Epoch 89/100
188/188 - 0s - loss: 0.0033
Epoch 90/100
188/188 - 0s - loss: 0.0032
Epoch 91/100
188/188 - 0s - loss: 0.0031
Epoch 92/100
188/188 - 0s - loss: 0.0031
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0031
Epoch 95/100
188/188 - 0s - loss: 0.0030
Epoch 96/100
188/188 - 0s - loss: 0.0031
Epoch 97/100
188/188 - 0s - loss: 0.0032
Epoch 98/100
188/188 - 0s - loss: 0.0033
Epoch 99/100
188/188 - 0s - loss: 0.0030
Epoch 100/100
188/188 - 0s - loss: 0.0031

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.053
Train RMSE: 0.087
key_word: COVID-19
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.522523  0.513514  0.459459  ...  0.513514  0.513514  0.513514
2021-07-18  0.522523  0.522523  0.513514  ...  0.504505  0.513514  0.513514
2021-07-25  0.513514  0.522523  0.522523  ...  0.522523  0.504505  0.513514
2021-08-01  0.621622  0.513514  0.522523  ...  0.522523  0.522523  0.504505
2021-08-08  0.405405  0.621622  0.513514  ...  0.522523  0.522523  0.522523

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_131 (LSTM)              (None, 60)                20400     
_________________________________________________________________
dense_129 (Dense)            (None, 1)                 61        
=================================================================
Total params: 20,461
Trainable params: 20,461
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0122
Epoch 2/100
188/188 - 0s - loss: 0.0047
Epoch 3/100
188/188 - 0s - loss: 0.0045
Epoch 4/100
188/188 - 0s - loss: 0.0043
Epoch 5/100
188/188 - 0s - loss: 0.0042
Epoch 6/100
188/188 - 0s - loss: 0.0044
Epoch 7/100
188/188 - 0s - loss: 0.0043
Epoch 8/100
188/188 - 0s - loss: 0.0043
Epoch 9/100
188/188 - 0s - loss: 0.0040
Epoch 10/100
188/188 - 0s - loss: 0.0041
Epoch 11/100
188/188 - 0s - loss: 0.0039
Epoch 12/100
188/188 - 0s - loss: 0.0042
Epoch 13/100
188/188 - 0s - loss: 0.0040
Epoch 14/100
188/188 - 0s - loss: 0.0044
Epoch 15/100
188/188 - 0s - loss: 0.0042
Epoch 16/100
188/188 - 0s - loss: 0.0038
Epoch 17/100
188/188 - 0s - loss: 0.0039
Epoch 18/100
188/188 - 0s - loss: 0.0039
Epoch 19/100
188/188 - 0s - loss: 0.0039
Epoch 20/100
188/188 - 0s - loss: 0.0040
Epoch 21/100
188/188 - 0s - loss: 0.0040
Epoch 22/100
188/188 - 0s - loss: 0.0037
Epoch 23/100
188/188 - 0s - loss: 0.0038
Epoch 24/100
188/188 - 0s - loss: 0.0037
Epoch 25/100
188/188 - 0s - loss: 0.0038
Epoch 26/100
188/188 - 0s - loss: 0.0038
Epoch 27/100
188/188 - 0s - loss: 0.0039
Epoch 28/100
188/188 - 0s - loss: 0.0037
Epoch 29/100
188/188 - 0s - loss: 0.0037
Epoch 30/100
188/188 - 0s - loss: 0.0037
Epoch 31/100
188/188 - 0s - loss: 0.0036
Epoch 32/100
188/188 - 0s - loss: 0.0038
Epoch 33/100
188/188 - 0s - loss: 0.0038
Epoch 34/100
188/188 - 0s - loss: 0.0036
Epoch 35/100
188/188 - 0s - loss: 0.0035
Epoch 36/100
188/188 - 0s - loss: 0.0036
Epoch 37/100
188/188 - 0s - loss: 0.0037
Epoch 38/100
188/188 - 0s - loss: 0.0035
Epoch 39/100
188/188 - 0s - loss: 0.0038
Epoch 40/100
188/188 - 0s - loss: 0.0037
Epoch 41/100
188/188 - 0s - loss: 0.0034
Epoch 42/100
188/188 - 0s - loss: 0.0038
Epoch 43/100
188/188 - 0s - loss: 0.0035
Epoch 44/100
188/188 - 0s - loss: 0.0034
Epoch 45/100
188/188 - 0s - loss: 0.0036
Epoch 46/100
188/188 - 0s - loss: 0.0036
Epoch 47/100
188/188 - 0s - loss: 0.0035
Epoch 48/100
188/188 - 0s - loss: 0.0035
Epoch 49/100
188/188 - 0s - loss: 0.0035
Epoch 50/100
188/188 - 0s - loss: 0.0037
Epoch 51/100
188/188 - 0s - loss: 0.0035
Epoch 52/100
188/188 - 0s - loss: 0.0034
Epoch 53/100
188/188 - 0s - loss: 0.0035
Epoch 54/100
188/188 - 0s - loss: 0.0037
Epoch 55/100
188/188 - 0s - loss: 0.0035
Epoch 56/100
188/188 - 0s - loss: 0.0035
Epoch 57/100
188/188 - 0s - loss: 0.0036
Epoch 58/100
188/188 - 0s - loss: 0.0034
Epoch 59/100
188/188 - 0s - loss: 0.0034
Epoch 60/100
188/188 - 0s - loss: 0.0035
Epoch 61/100
188/188 - 0s - loss: 0.0033
Epoch 62/100
188/188 - 0s - loss: 0.0035
Epoch 63/100
188/188 - 0s - loss: 0.0033
Epoch 64/100
188/188 - 0s - loss: 0.0034
Epoch 65/100
188/188 - 0s - loss: 0.0034
Epoch 66/100
188/188 - 0s - loss: 0.0035
Epoch 67/100
188/188 - 0s - loss: 0.0034
Epoch 68/100
188/188 - 0s - loss: 0.0035
Epoch 69/100
188/188 - 0s - loss: 0.0035
Epoch 70/100
188/188 - 0s - loss: 0.0034
Epoch 71/100
188/188 - 0s - loss: 0.0034
Epoch 72/100
188/188 - 0s - loss: 0.0035
Epoch 73/100
188/188 - 0s - loss: 0.0032
Epoch 74/100
188/188 - 0s - loss: 0.0033
Epoch 75/100
188/188 - 0s - loss: 0.0032
Epoch 76/100
188/188 - 0s - loss: 0.0035
Epoch 77/100
188/188 - 0s - loss: 0.0035
Epoch 78/100
188/188 - 0s - loss: 0.0033
Epoch 79/100
188/188 - 0s - loss: 0.0034
Epoch 80/100
188/188 - 0s - loss: 0.0032
Epoch 81/100
188/188 - 0s - loss: 0.0035
Epoch 82/100
188/188 - 0s - loss: 0.0033
Epoch 83/100
188/188 - 0s - loss: 0.0032
Epoch 84/100
188/188 - 0s - loss: 0.0034
Epoch 85/100
188/188 - 0s - loss: 0.0033
Epoch 86/100
188/188 - 0s - loss: 0.0034
Epoch 87/100
188/188 - 0s - loss: 0.0032
Epoch 88/100
188/188 - 0s - loss: 0.0032
Epoch 89/100
188/188 - 0s - loss: 0.0032
Epoch 90/100
188/188 - 0s - loss: 0.0034
Epoch 91/100
188/188 - 0s - loss: 0.0034
Epoch 92/100
188/188 - 0s - loss: 0.0034
Epoch 93/100
188/188 - 0s - loss: 0.0032
Epoch 94/100
188/188 - 0s - loss: 0.0032
Epoch 95/100
188/188 - 0s - loss: 0.0033
Epoch 96/100
188/188 - 0s - loss: 0.0034
Epoch 97/100
188/188 - 0s - loss: 0.0033
Epoch 98/100
188/188 - 0s - loss: 0.0033
Epoch 99/100
188/188 - 0s - loss: 0.0030
Epoch 100/100
188/188 - 0s - loss: 0.0032

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.054
Train RMSE: 0.085
key_word: COVID-19
window size: 24
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.285714  0.285714  0.214286
2021-07-18  0.357143  0.357143  0.142857  ...  0.357143  0.285714  0.285714
2021-07-25  0.285714  0.357143  0.357143  ...  0.214286  0.357143  0.285714
2021-08-01  0.214286  0.285714  0.357143  ...  0.214286  0.214286  0.357143
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.214286  0.214286

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_132 (LSTM)              (None, 4)                 272       
_________________________________________________________________
dense_130 (Dense)            (None, 1)                 5         
=================================================================
Total params: 277
Trainable params: 277
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0410
Epoch 2/100
197/197 - 0s - loss: 0.0080
Epoch 3/100
197/197 - 0s - loss: 0.0080
Epoch 4/100
197/197 - 0s - loss: 0.0078
Epoch 5/100
197/197 - 0s - loss: 0.0079
Epoch 6/100
197/197 - 0s - loss: 0.0078
Epoch 7/100
197/197 - 0s - loss: 0.0077
Epoch 8/100
197/197 - 0s - loss: 0.0077
Epoch 9/100
197/197 - 0s - loss: 0.0077
Epoch 10/100
197/197 - 0s - loss: 0.0076
Epoch 11/100
197/197 - 0s - loss: 0.0075
Epoch 12/100
197/197 - 0s - loss: 0.0075
Epoch 13/100
197/197 - 0s - loss: 0.0075
Epoch 14/100
197/197 - 0s - loss: 0.0073
Epoch 15/100
197/197 - 0s - loss: 0.0074
Epoch 16/100
197/197 - 0s - loss: 0.0073
Epoch 17/100
197/197 - 0s - loss: 0.0073
Epoch 18/100
197/197 - 0s - loss: 0.0073
Epoch 19/100
197/197 - 0s - loss: 0.0073
Epoch 20/100
197/197 - 0s - loss: 0.0072
Epoch 21/100
197/197 - 0s - loss: 0.0072
Epoch 22/100
197/197 - 0s - loss: 0.0072
Epoch 23/100
197/197 - 0s - loss: 0.0071
Epoch 24/100
197/197 - 0s - loss: 0.0071
Epoch 25/100
197/197 - 0s - loss: 0.0072
Epoch 26/100
197/197 - 0s - loss: 0.0070
Epoch 27/100
197/197 - 0s - loss: 0.0070
Epoch 28/100
197/197 - 0s - loss: 0.0071
Epoch 29/100
197/197 - 0s - loss: 0.0069
Epoch 30/100
197/197 - 0s - loss: 0.0069
Epoch 31/100
197/197 - 0s - loss: 0.0070
Epoch 32/100
197/197 - 0s - loss: 0.0069
Epoch 33/100
197/197 - 0s - loss: 0.0069
Epoch 34/100
197/197 - 0s - loss: 0.0066
Epoch 35/100
197/197 - 0s - loss: 0.0069
Epoch 36/100
197/197 - 0s - loss: 0.0068
Epoch 37/100
197/197 - 0s - loss: 0.0068
Epoch 38/100
197/197 - 0s - loss: 0.0067
Epoch 39/100
197/197 - 0s - loss: 0.0067
Epoch 40/100
197/197 - 0s - loss: 0.0067
Epoch 41/100
197/197 - 0s - loss: 0.0067
Epoch 42/100
197/197 - 0s - loss: 0.0066
Epoch 43/100
197/197 - 0s - loss: 0.0066
Epoch 44/100
197/197 - 0s - loss: 0.0065
Epoch 45/100
197/197 - 0s - loss: 0.0067
Epoch 46/100
197/197 - 0s - loss: 0.0067
Epoch 47/100
197/197 - 0s - loss: 0.0066
Epoch 48/100
197/197 - 0s - loss: 0.0067
Epoch 49/100
197/197 - 0s - loss: 0.0066
Epoch 50/100
197/197 - 0s - loss: 0.0066
Epoch 51/100
197/197 - 0s - loss: 0.0065
Epoch 52/100
197/197 - 0s - loss: 0.0067
Epoch 53/100
197/197 - 0s - loss: 0.0065
Epoch 54/100
197/197 - 0s - loss: 0.0066
Epoch 55/100
197/197 - 0s - loss: 0.0065
Epoch 56/100
197/197 - 0s - loss: 0.0065
Epoch 57/100
197/197 - 0s - loss: 0.0066
Epoch 58/100
197/197 - 0s - loss: 0.0065
Epoch 59/100
197/197 - 0s - loss: 0.0065
Epoch 60/100
197/197 - 0s - loss: 0.0064
Epoch 61/100
197/197 - 0s - loss: 0.0065
Epoch 62/100
197/197 - 0s - loss: 0.0064
Epoch 63/100
197/197 - 0s - loss: 0.0064
Epoch 64/100
197/197 - 0s - loss: 0.0065
Epoch 65/100
197/197 - 0s - loss: 0.0064
Epoch 66/100
197/197 - 0s - loss: 0.0064
Epoch 67/100
197/197 - 0s - loss: 0.0065
Epoch 68/100
197/197 - 0s - loss: 0.0065
Epoch 69/100
197/197 - 0s - loss: 0.0064
Epoch 70/100
197/197 - 0s - loss: 0.0063
Epoch 71/100
197/197 - 0s - loss: 0.0066
Epoch 72/100
197/197 - 0s - loss: 0.0064
Epoch 73/100
197/197 - 0s - loss: 0.0064
Epoch 74/100
197/197 - 0s - loss: 0.0064
Epoch 75/100
197/197 - 0s - loss: 0.0066
Epoch 76/100
197/197 - 0s - loss: 0.0065
Epoch 77/100
197/197 - 0s - loss: 0.0064
Epoch 78/100
197/197 - 0s - loss: 0.0064
Epoch 79/100
197/197 - 0s - loss: 0.0062
Epoch 80/100
197/197 - 0s - loss: 0.0063
Epoch 81/100
197/197 - 0s - loss: 0.0063
Epoch 82/100
197/197 - 0s - loss: 0.0063
Epoch 83/100
197/197 - 0s - loss: 0.0064
Epoch 84/100
197/197 - 0s - loss: 0.0063
Epoch 85/100
197/197 - 0s - loss: 0.0063
Epoch 86/100
197/197 - 0s - loss: 0.0064
Epoch 87/100
197/197 - 0s - loss: 0.0064
Epoch 88/100
197/197 - 0s - loss: 0.0063
Epoch 89/100
197/197 - 0s - loss: 0.0063
Epoch 90/100
197/197 - 0s - loss: 0.0063
Epoch 91/100
197/197 - 0s - loss: 0.0064
Epoch 92/100
197/197 - 0s - loss: 0.0062
Epoch 93/100
197/197 - 0s - loss: 0.0061
Epoch 94/100
197/197 - 0s - loss: 0.0063
Epoch 95/100
197/197 - 0s - loss: 0.0064
Epoch 96/100
197/197 - 0s - loss: 0.0063
Epoch 97/100
197/197 - 0s - loss: 0.0063
Epoch 98/100
197/197 - 0s - loss: 0.0062
Epoch 99/100
197/197 - 0s - loss: 0.0062
Epoch 100/100
197/197 - 0s - loss: 0.0063

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.078
Train RMSE: 0.166
key_word: stock price
window size: 12
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.285714  0.285714  0.214286
2021-07-18  0.357143  0.357143  0.142857  ...  0.357143  0.285714  0.285714
2021-07-25  0.285714  0.357143  0.357143  ...  0.214286  0.357143  0.285714
2021-08-01  0.214286  0.285714  0.357143  ...  0.214286  0.214286  0.357143
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.214286  0.214286

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_133 (LSTM)              (None, 8)                 672       
_________________________________________________________________
dense_131 (Dense)            (None, 1)                 9         
=================================================================
Total params: 681
Trainable params: 681
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0238
Epoch 2/100
197/197 - 0s - loss: 0.0079
Epoch 3/100
197/197 - 0s - loss: 0.0077
Epoch 4/100
197/197 - 0s - loss: 0.0078
Epoch 5/100
197/197 - 0s - loss: 0.0078
Epoch 6/100
197/197 - 0s - loss: 0.0075
Epoch 7/100
197/197 - 0s - loss: 0.0071
Epoch 8/100
197/197 - 0s - loss: 0.0072
Epoch 9/100
197/197 - 0s - loss: 0.0073
Epoch 10/100
197/197 - 0s - loss: 0.0073
Epoch 11/100
197/197 - 0s - loss: 0.0070
Epoch 12/100
197/197 - 0s - loss: 0.0072
Epoch 13/100
197/197 - 0s - loss: 0.0070
Epoch 14/100
197/197 - 0s - loss: 0.0070
Epoch 15/100
197/197 - 0s - loss: 0.0069
Epoch 16/100
197/197 - 0s - loss: 0.0071
Epoch 17/100
197/197 - 0s - loss: 0.0070
Epoch 18/100
197/197 - 0s - loss: 0.0068
Epoch 19/100
197/197 - 0s - loss: 0.0065
Epoch 20/100
197/197 - 0s - loss: 0.0070
Epoch 21/100
197/197 - 0s - loss: 0.0067
Epoch 22/100
197/197 - 0s - loss: 0.0067
Epoch 23/100
197/197 - 0s - loss: 0.0068
Epoch 24/100
197/197 - 0s - loss: 0.0066
Epoch 25/100
197/197 - 0s - loss: 0.0067
Epoch 26/100
197/197 - 0s - loss: 0.0066
Epoch 27/100
197/197 - 0s - loss: 0.0067
Epoch 28/100
197/197 - 0s - loss: 0.0067
Epoch 29/100
197/197 - 0s - loss: 0.0068
Epoch 30/100
197/197 - 0s - loss: 0.0067
Epoch 31/100
197/197 - 0s - loss: 0.0067
Epoch 32/100
197/197 - 0s - loss: 0.0067
Epoch 33/100
197/197 - 0s - loss: 0.0067
Epoch 34/100
197/197 - 0s - loss: 0.0068
Epoch 35/100
197/197 - 0s - loss: 0.0068
Epoch 36/100
197/197 - 0s - loss: 0.0065
Epoch 37/100
197/197 - 0s - loss: 0.0065
Epoch 38/100
197/197 - 0s - loss: 0.0067
Epoch 39/100
197/197 - 0s - loss: 0.0066
Epoch 40/100
197/197 - 0s - loss: 0.0065
Epoch 41/100
197/197 - 0s - loss: 0.0066
Epoch 42/100
197/197 - 0s - loss: 0.0065
Epoch 43/100
197/197 - 0s - loss: 0.0064
Epoch 44/100
197/197 - 0s - loss: 0.0066
Epoch 45/100
197/197 - 0s - loss: 0.0065
Epoch 46/100
197/197 - 0s - loss: 0.0064
Epoch 47/100
197/197 - 0s - loss: 0.0066
Epoch 48/100
197/197 - 0s - loss: 0.0066
Epoch 49/100
197/197 - 0s - loss: 0.0064
Epoch 50/100
197/197 - 0s - loss: 0.0063
Epoch 51/100
197/197 - 0s - loss: 0.0066
Epoch 52/100
197/197 - 0s - loss: 0.0063
Epoch 53/100
197/197 - 0s - loss: 0.0064
Epoch 54/100
197/197 - 0s - loss: 0.0064
Epoch 55/100
197/197 - 0s - loss: 0.0066
Epoch 56/100
197/197 - 0s - loss: 0.0064
Epoch 57/100
197/197 - 0s - loss: 0.0065
Epoch 58/100
197/197 - 0s - loss: 0.0064
Epoch 59/100
197/197 - 0s - loss: 0.0063
Epoch 60/100
197/197 - 0s - loss: 0.0064
Epoch 61/100
197/197 - 0s - loss: 0.0063
Epoch 62/100
197/197 - 0s - loss: 0.0064
Epoch 63/100
197/197 - 0s - loss: 0.0063
Epoch 64/100
197/197 - 0s - loss: 0.0063
Epoch 65/100
197/197 - 0s - loss: 0.0063
Epoch 66/100
197/197 - 0s - loss: 0.0063
Epoch 67/100
197/197 - 0s - loss: 0.0063
Epoch 68/100
197/197 - 0s - loss: 0.0063
Epoch 69/100
197/197 - 0s - loss: 0.0062
Epoch 70/100
197/197 - 0s - loss: 0.0060
Epoch 71/100
197/197 - 0s - loss: 0.0062
Epoch 72/100
197/197 - 0s - loss: 0.0063
Epoch 73/100
197/197 - 0s - loss: 0.0063
Epoch 74/100
197/197 - 0s - loss: 0.0062
Epoch 75/100
197/197 - 0s - loss: 0.0062
Epoch 76/100
197/197 - 0s - loss: 0.0063
Epoch 77/100
197/197 - 0s - loss: 0.0062
Epoch 78/100
197/197 - 0s - loss: 0.0062
Epoch 79/100
197/197 - 0s - loss: 0.0062
Epoch 80/100
197/197 - 0s - loss: 0.0061
Epoch 81/100
197/197 - 0s - loss: 0.0061
Epoch 82/100
197/197 - 0s - loss: 0.0060
Epoch 83/100
197/197 - 0s - loss: 0.0063
Epoch 84/100
197/197 - 0s - loss: 0.0062
Epoch 85/100
197/197 - 0s - loss: 0.0062
Epoch 86/100
197/197 - 0s - loss: 0.0062
Epoch 87/100
197/197 - 0s - loss: 0.0063
Epoch 88/100
197/197 - 0s - loss: 0.0062
Epoch 89/100
197/197 - 0s - loss: 0.0060
Epoch 90/100
197/197 - 0s - loss: 0.0061
Epoch 91/100
197/197 - 0s - loss: 0.0060
Epoch 92/100
197/197 - 0s - loss: 0.0062
Epoch 93/100
197/197 - 0s - loss: 0.0061
Epoch 94/100
197/197 - 0s - loss: 0.0061
Epoch 95/100
197/197 - 0s - loss: 0.0060
Epoch 96/100
197/197 - 0s - loss: 0.0061
Epoch 97/100
197/197 - 0s - loss: 0.0059
Epoch 98/100
197/197 - 0s - loss: 0.0062
Epoch 99/100
197/197 - 0s - loss: 0.0061
Epoch 100/100
197/197 - 0s - loss: 0.0059

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.077
Train RMSE: 0.168
key_word: stock price
window size: 12
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.285714  0.285714  0.214286
2021-07-18  0.357143  0.357143  0.142857  ...  0.357143  0.285714  0.285714
2021-07-25  0.285714  0.357143  0.357143  ...  0.214286  0.357143  0.285714
2021-08-01  0.214286  0.285714  0.357143  ...  0.214286  0.214286  0.357143
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.214286  0.214286

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_134 (LSTM)              (None, 16)                1856      
_________________________________________________________________
dense_132 (Dense)            (None, 1)                 17        
=================================================================
Total params: 1,873
Trainable params: 1,873
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0134
Epoch 2/100
197/197 - 0s - loss: 0.0081
Epoch 3/100
197/197 - 0s - loss: 0.0079
Epoch 4/100
197/197 - 0s - loss: 0.0078
Epoch 5/100
197/197 - 0s - loss: 0.0076
Epoch 6/100
197/197 - 0s - loss: 0.0076
Epoch 7/100
197/197 - 0s - loss: 0.0074
Epoch 8/100
197/197 - 0s - loss: 0.0074
Epoch 9/100
197/197 - 0s - loss: 0.0072
Epoch 10/100
197/197 - 0s - loss: 0.0069
Epoch 11/100
197/197 - 0s - loss: 0.0074
Epoch 12/100
197/197 - 0s - loss: 0.0072
Epoch 13/100
197/197 - 0s - loss: 0.0070
Epoch 14/100
197/197 - 0s - loss: 0.0072
Epoch 15/100
197/197 - 0s - loss: 0.0070
Epoch 16/100
197/197 - 0s - loss: 0.0068
Epoch 17/100
197/197 - 0s - loss: 0.0069
Epoch 18/100
197/197 - 0s - loss: 0.0069
Epoch 19/100
197/197 - 0s - loss: 0.0067
Epoch 20/100
197/197 - 0s - loss: 0.0073
Epoch 21/100
197/197 - 0s - loss: 0.0068
Epoch 22/100
197/197 - 0s - loss: 0.0068
Epoch 23/100
197/197 - 0s - loss: 0.0069
Epoch 24/100
197/197 - 0s - loss: 0.0069
Epoch 25/100
197/197 - 0s - loss: 0.0069
Epoch 26/100
197/197 - 0s - loss: 0.0070
Epoch 27/100
197/197 - 0s - loss: 0.0069
Epoch 28/100
197/197 - 0s - loss: 0.0066
Epoch 29/100
197/197 - 0s - loss: 0.0067
Epoch 30/100
197/197 - 0s - loss: 0.0066
Epoch 31/100
197/197 - 0s - loss: 0.0068
Epoch 32/100
197/197 - 0s - loss: 0.0068
Epoch 33/100
197/197 - 0s - loss: 0.0066
Epoch 34/100
197/197 - 0s - loss: 0.0067
Epoch 35/100
197/197 - 0s - loss: 0.0069
Epoch 36/100
197/197 - 0s - loss: 0.0064
Epoch 37/100
197/197 - 0s - loss: 0.0067
Epoch 38/100
197/197 - 0s - loss: 0.0066
Epoch 39/100
197/197 - 0s - loss: 0.0066
Epoch 40/100
197/197 - 0s - loss: 0.0069
Epoch 41/100
197/197 - 0s - loss: 0.0066
Epoch 42/100
197/197 - 0s - loss: 0.0066
Epoch 43/100
197/197 - 0s - loss: 0.0064
Epoch 44/100
197/197 - 0s - loss: 0.0066
Epoch 45/100
197/197 - 0s - loss: 0.0065
Epoch 46/100
197/197 - 0s - loss: 0.0065
Epoch 47/100
197/197 - 0s - loss: 0.0068
Epoch 48/100
197/197 - 0s - loss: 0.0066
Epoch 49/100
197/197 - 0s - loss: 0.0064
Epoch 50/100
197/197 - 0s - loss: 0.0064
Epoch 51/100
197/197 - 0s - loss: 0.0066
Epoch 52/100
197/197 - 0s - loss: 0.0065
Epoch 53/100
197/197 - 0s - loss: 0.0063
Epoch 54/100
197/197 - 0s - loss: 0.0063
Epoch 55/100
197/197 - 0s - loss: 0.0064
Epoch 56/100
197/197 - 0s - loss: 0.0065
Epoch 57/100
197/197 - 0s - loss: 0.0064
Epoch 58/100
197/197 - 0s - loss: 0.0067
Epoch 59/100
197/197 - 0s - loss: 0.0065
Epoch 60/100
197/197 - 0s - loss: 0.0063
Epoch 61/100
197/197 - 0s - loss: 0.0062
Epoch 62/100
197/197 - 0s - loss: 0.0065
Epoch 63/100
197/197 - 0s - loss: 0.0064
Epoch 64/100
197/197 - 0s - loss: 0.0063
Epoch 65/100
197/197 - 0s - loss: 0.0064
Epoch 66/100
197/197 - 0s - loss: 0.0064
Epoch 67/100
197/197 - 0s - loss: 0.0063
Epoch 68/100
197/197 - 0s - loss: 0.0062
Epoch 69/100
197/197 - 0s - loss: 0.0064
Epoch 70/100
197/197 - 0s - loss: 0.0063
Epoch 71/100
197/197 - 0s - loss: 0.0063
Epoch 72/100
197/197 - 0s - loss: 0.0063
Epoch 73/100
197/197 - 0s - loss: 0.0063
Epoch 74/100
197/197 - 0s - loss: 0.0063
Epoch 75/100
197/197 - 0s - loss: 0.0062
Epoch 76/100
197/197 - 0s - loss: 0.0064
Epoch 77/100
197/197 - 0s - loss: 0.0062
Epoch 78/100
197/197 - 0s - loss: 0.0062
Epoch 79/100
197/197 - 0s - loss: 0.0064
Epoch 80/100
197/197 - 0s - loss: 0.0061
Epoch 81/100
197/197 - 0s - loss: 0.0062
Epoch 82/100
197/197 - 0s - loss: 0.0063
Epoch 83/100
197/197 - 0s - loss: 0.0062
Epoch 84/100
197/197 - 0s - loss: 0.0061
Epoch 85/100
197/197 - 0s - loss: 0.0060
Epoch 86/100
197/197 - 0s - loss: 0.0061
Epoch 87/100
197/197 - 0s - loss: 0.0062
Epoch 88/100
197/197 - 0s - loss: 0.0060
Epoch 89/100
197/197 - 0s - loss: 0.0061
Epoch 90/100
197/197 - 0s - loss: 0.0060
Epoch 91/100
197/197 - 0s - loss: 0.0062
Epoch 92/100
197/197 - 0s - loss: 0.0061
Epoch 93/100
197/197 - 0s - loss: 0.0061
Epoch 94/100
197/197 - 0s - loss: 0.0061
Epoch 95/100
197/197 - 0s - loss: 0.0061
Epoch 96/100
197/197 - 0s - loss: 0.0061
Epoch 97/100
197/197 - 0s - loss: 0.0061
Epoch 98/100
197/197 - 0s - loss: 0.0059
Epoch 99/100
197/197 - 0s - loss: 0.0062
Epoch 100/100
197/197 - 0s - loss: 0.0062

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.076
Train RMSE: 0.167
key_word: stock price
window size: 12
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.285714  0.285714  0.214286
2021-07-18  0.357143  0.357143  0.142857  ...  0.357143  0.285714  0.285714
2021-07-25  0.285714  0.357143  0.357143  ...  0.214286  0.357143  0.285714
2021-08-01  0.214286  0.285714  0.357143  ...  0.214286  0.214286  0.357143
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.214286  0.214286

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_135 (LSTM)              (None, 32)                5760      
_________________________________________________________________
dense_133 (Dense)            (None, 1)                 33        
=================================================================
Total params: 5,793
Trainable params: 5,793
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0150
Epoch 2/100
197/197 - 0s - loss: 0.0080
Epoch 3/100
197/197 - 0s - loss: 0.0077
Epoch 4/100
197/197 - 0s - loss: 0.0079
Epoch 5/100
197/197 - 0s - loss: 0.0075
Epoch 6/100
197/197 - 0s - loss: 0.0075
Epoch 7/100
197/197 - 0s - loss: 0.0075
Epoch 8/100
197/197 - 0s - loss: 0.0073
Epoch 9/100
197/197 - 0s - loss: 0.0074
Epoch 10/100
197/197 - 0s - loss: 0.0071
Epoch 11/100
197/197 - 0s - loss: 0.0071
Epoch 12/100
197/197 - 0s - loss: 0.0073
Epoch 13/100
197/197 - 0s - loss: 0.0071
Epoch 14/100
197/197 - 0s - loss: 0.0070
Epoch 15/100
197/197 - 0s - loss: 0.0075
Epoch 16/100
197/197 - 0s - loss: 0.0069
Epoch 17/100
197/197 - 0s - loss: 0.0069
Epoch 18/100
197/197 - 0s - loss: 0.0069
Epoch 19/100
197/197 - 0s - loss: 0.0071
Epoch 20/100
197/197 - 0s - loss: 0.0070
Epoch 21/100
197/197 - 0s - loss: 0.0069
Epoch 22/100
197/197 - 0s - loss: 0.0069
Epoch 23/100
197/197 - 0s - loss: 0.0070
Epoch 24/100
197/197 - 0s - loss: 0.0068
Epoch 25/100
197/197 - 0s - loss: 0.0069
Epoch 26/100
197/197 - 0s - loss: 0.0068
Epoch 27/100
197/197 - 0s - loss: 0.0070
Epoch 28/100
197/197 - 0s - loss: 0.0067
Epoch 29/100
197/197 - 0s - loss: 0.0068
Epoch 30/100
197/197 - 0s - loss: 0.0069
Epoch 31/100
197/197 - 0s - loss: 0.0067
Epoch 32/100
197/197 - 0s - loss: 0.0066
Epoch 33/100
197/197 - 0s - loss: 0.0067
Epoch 34/100
197/197 - 0s - loss: 0.0066
Epoch 35/100
197/197 - 0s - loss: 0.0070
Epoch 36/100
197/197 - 0s - loss: 0.0069
Epoch 37/100
197/197 - 0s - loss: 0.0068
Epoch 38/100
197/197 - 0s - loss: 0.0067
Epoch 39/100
197/197 - 0s - loss: 0.0065
Epoch 40/100
197/197 - 0s - loss: 0.0066
Epoch 41/100
197/197 - 0s - loss: 0.0066
Epoch 42/100
197/197 - 0s - loss: 0.0067
Epoch 43/100
197/197 - 0s - loss: 0.0067
Epoch 44/100
197/197 - 0s - loss: 0.0068
Epoch 45/100
197/197 - 0s - loss: 0.0066
Epoch 46/100
197/197 - 0s - loss: 0.0066
Epoch 47/100
197/197 - 0s - loss: 0.0065
Epoch 48/100
197/197 - 0s - loss: 0.0064
Epoch 49/100
197/197 - 0s - loss: 0.0066
Epoch 50/100
197/197 - 0s - loss: 0.0064
Epoch 51/100
197/197 - 0s - loss: 0.0067
Epoch 52/100
197/197 - 0s - loss: 0.0068
Epoch 53/100
197/197 - 0s - loss: 0.0064
Epoch 54/100
197/197 - 0s - loss: 0.0066
Epoch 55/100
197/197 - 0s - loss: 0.0066
Epoch 56/100
197/197 - 0s - loss: 0.0064
Epoch 57/100
197/197 - 0s - loss: 0.0065
Epoch 58/100
197/197 - 0s - loss: 0.0066
Epoch 59/100
197/197 - 0s - loss: 0.0064
Epoch 60/100
197/197 - 0s - loss: 0.0064
Epoch 61/100
197/197 - 0s - loss: 0.0065
Epoch 62/100
197/197 - 0s - loss: 0.0067
Epoch 63/100
197/197 - 0s - loss: 0.0064
Epoch 64/100
197/197 - 0s - loss: 0.0064
Epoch 65/100
197/197 - 0s - loss: 0.0063
Epoch 66/100
197/197 - 0s - loss: 0.0063
Epoch 67/100
197/197 - 0s - loss: 0.0064
Epoch 68/100
197/197 - 0s - loss: 0.0064
Epoch 69/100
197/197 - 0s - loss: 0.0063
Epoch 70/100
197/197 - 0s - loss: 0.0063
Epoch 71/100
197/197 - 0s - loss: 0.0063
Epoch 72/100
197/197 - 0s - loss: 0.0062
Epoch 73/100
197/197 - 0s - loss: 0.0061
Epoch 74/100
197/197 - 0s - loss: 0.0063
Epoch 75/100
197/197 - 0s - loss: 0.0061
Epoch 76/100
197/197 - 0s - loss: 0.0063
Epoch 77/100
197/197 - 0s - loss: 0.0062
Epoch 78/100
197/197 - 0s - loss: 0.0061
Epoch 79/100
197/197 - 0s - loss: 0.0064
Epoch 80/100
197/197 - 0s - loss: 0.0062
Epoch 81/100
197/197 - 0s - loss: 0.0063
Epoch 82/100
197/197 - 0s - loss: 0.0062
Epoch 83/100
197/197 - 0s - loss: 0.0061
Epoch 84/100
197/197 - 0s - loss: 0.0061
Epoch 85/100
197/197 - 0s - loss: 0.0062
Epoch 86/100
197/197 - 0s - loss: 0.0062
Epoch 87/100
197/197 - 0s - loss: 0.0059
Epoch 88/100
197/197 - 0s - loss: 0.0061
Epoch 89/100
197/197 - 0s - loss: 0.0061
Epoch 90/100
197/197 - 0s - loss: 0.0060
Epoch 91/100
197/197 - 0s - loss: 0.0061
Epoch 92/100
197/197 - 0s - loss: 0.0059
Epoch 93/100
197/197 - 0s - loss: 0.0060
Epoch 94/100
197/197 - 0s - loss: 0.0060
Epoch 95/100
197/197 - 0s - loss: 0.0062
Epoch 96/100
197/197 - 0s - loss: 0.0060
Epoch 97/100
197/197 - 0s - loss: 0.0059
Epoch 98/100
197/197 - 0s - loss: 0.0057
Epoch 99/100
197/197 - 0s - loss: 0.0058
Epoch 100/100
197/197 - 0s - loss: 0.0060

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.075
Train RMSE: 0.163
key_word: stock price
window size: 12
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-10      t-11      t-12
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.285714  0.285714  0.214286
2021-07-18  0.357143  0.357143  0.142857  ...  0.357143  0.285714  0.285714
2021-07-25  0.285714  0.357143  0.357143  ...  0.214286  0.357143  0.285714
2021-08-01  0.214286  0.285714  0.357143  ...  0.214286  0.214286  0.357143
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.214286  0.214286

[5 rows x 13 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_136 (LSTM)              (None, 60)                17520     
_________________________________________________________________
dense_134 (Dense)            (None, 1)                 61        
=================================================================
Total params: 17,581
Trainable params: 17,581
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
197/197 - 2s - loss: 0.0105
Epoch 2/100
197/197 - 0s - loss: 0.0081
Epoch 3/100
197/197 - 0s - loss: 0.0077
Epoch 4/100
197/197 - 0s - loss: 0.0077
Epoch 5/100
197/197 - 0s - loss: 0.0077
Epoch 6/100
197/197 - 0s - loss: 0.0074
Epoch 7/100
197/197 - 0s - loss: 0.0075
Epoch 8/100
197/197 - 0s - loss: 0.0075
Epoch 9/100
197/197 - 0s - loss: 0.0073
Epoch 10/100
197/197 - 0s - loss: 0.0071
Epoch 11/100
197/197 - 0s - loss: 0.0073
Epoch 12/100
197/197 - 0s - loss: 0.0074
Epoch 13/100
197/197 - 0s - loss: 0.0073
Epoch 14/100
197/197 - 0s - loss: 0.0076
Epoch 15/100
197/197 - 0s - loss: 0.0072
Epoch 16/100
197/197 - 0s - loss: 0.0070
Epoch 17/100
197/197 - 0s - loss: 0.0072
Epoch 18/100
197/197 - 0s - loss: 0.0070
Epoch 19/100
197/197 - 0s - loss: 0.0069
Epoch 20/100
197/197 - 0s - loss: 0.0072
Epoch 21/100
197/197 - 0s - loss: 0.0071
Epoch 22/100
197/197 - 0s - loss: 0.0070
Epoch 23/100
197/197 - 0s - loss: 0.0070
Epoch 24/100
197/197 - 0s - loss: 0.0068
Epoch 25/100
197/197 - 0s - loss: 0.0070
Epoch 26/100
197/197 - 0s - loss: 0.0070
Epoch 27/100
197/197 - 0s - loss: 0.0066
Epoch 28/100
197/197 - 0s - loss: 0.0070
Epoch 29/100
197/197 - 0s - loss: 0.0066
Epoch 30/100
197/197 - 0s - loss: 0.0070
Epoch 31/100
197/197 - 0s - loss: 0.0068
Epoch 32/100
197/197 - 0s - loss: 0.0068
Epoch 33/100
197/197 - 0s - loss: 0.0068
Epoch 34/100
197/197 - 0s - loss: 0.0068
Epoch 35/100
197/197 - 0s - loss: 0.0068
Epoch 36/100
197/197 - 0s - loss: 0.0068
Epoch 37/100
197/197 - 0s - loss: 0.0067
Epoch 38/100
197/197 - 0s - loss: 0.0067
Epoch 39/100
197/197 - 0s - loss: 0.0067
Epoch 40/100
197/197 - 0s - loss: 0.0070
Epoch 41/100
197/197 - 0s - loss: 0.0065
Epoch 42/100
197/197 - 0s - loss: 0.0067
Epoch 43/100
197/197 - 0s - loss: 0.0068
Epoch 44/100
197/197 - 0s - loss: 0.0066
Epoch 45/100
197/197 - 0s - loss: 0.0067
Epoch 46/100
197/197 - 0s - loss: 0.0067
Epoch 47/100
197/197 - 0s - loss: 0.0064
Epoch 48/100
197/197 - 0s - loss: 0.0066
Epoch 49/100
197/197 - 0s - loss: 0.0066
Epoch 50/100
197/197 - 0s - loss: 0.0065
Epoch 51/100
197/197 - 0s - loss: 0.0066
Epoch 52/100
197/197 - 0s - loss: 0.0064
Epoch 53/100
197/197 - 0s - loss: 0.0064
Epoch 54/100
197/197 - 0s - loss: 0.0062
Epoch 55/100
197/197 - 0s - loss: 0.0065
Epoch 56/100
197/197 - 0s - loss: 0.0064
Epoch 57/100
197/197 - 0s - loss: 0.0063
Epoch 58/100
197/197 - 0s - loss: 0.0065
Epoch 59/100
197/197 - 0s - loss: 0.0065
Epoch 60/100
197/197 - 0s - loss: 0.0063
Epoch 61/100
197/197 - 0s - loss: 0.0064
Epoch 62/100
197/197 - 0s - loss: 0.0065
Epoch 63/100
197/197 - 0s - loss: 0.0064
Epoch 64/100
197/197 - 0s - loss: 0.0065
Epoch 65/100
197/197 - 0s - loss: 0.0065
Epoch 66/100
197/197 - 0s - loss: 0.0064
Epoch 67/100
197/197 - 0s - loss: 0.0066
Epoch 68/100
197/197 - 0s - loss: 0.0063
Epoch 69/100
197/197 - 0s - loss: 0.0062
Epoch 70/100
197/197 - 0s - loss: 0.0063
Epoch 71/100
197/197 - 0s - loss: 0.0064
Epoch 72/100
197/197 - 0s - loss: 0.0063
Epoch 73/100
197/197 - 0s - loss: 0.0062
Epoch 74/100
197/197 - 0s - loss: 0.0061
Epoch 75/100
197/197 - 0s - loss: 0.0064
Epoch 76/100
197/197 - 0s - loss: 0.0062
Epoch 77/100
197/197 - 0s - loss: 0.0062
Epoch 78/100
197/197 - 0s - loss: 0.0062
Epoch 79/100
197/197 - 0s - loss: 0.0060
Epoch 80/100
197/197 - 0s - loss: 0.0061
Epoch 81/100
197/197 - 0s - loss: 0.0062
Epoch 82/100
197/197 - 0s - loss: 0.0058
Epoch 83/100
197/197 - 0s - loss: 0.0061
Epoch 84/100
197/197 - 0s - loss: 0.0063
Epoch 85/100
197/197 - 0s - loss: 0.0060
Epoch 86/100
197/197 - 0s - loss: 0.0061
Epoch 87/100
197/197 - 0s - loss: 0.0060
Epoch 88/100
197/197 - 0s - loss: 0.0062
Epoch 89/100
197/197 - 0s - loss: 0.0060
Epoch 90/100
197/197 - 0s - loss: 0.0060
Epoch 91/100
197/197 - 0s - loss: 0.0060
Epoch 92/100
197/197 - 0s - loss: 0.0060
Epoch 93/100
197/197 - 0s - loss: 0.0061
Epoch 94/100
197/197 - 0s - loss: 0.0059
Epoch 95/100
197/197 - 0s - loss: 0.0059
Epoch 96/100
197/197 - 0s - loss: 0.0060
Epoch 97/100
197/197 - 0s - loss: 0.0060
Epoch 98/100
197/197 - 0s - loss: 0.0058
Epoch 99/100
197/197 - 0s - loss: 0.0057
Epoch 100/100
197/197 - 0s - loss: 0.0060

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.078
Train RMSE: 0.168
key_word: stock price
window size: 12
N neurons: 60

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.000000  0.214286  1.000000
2021-07-18  0.357143  0.357143  0.142857  ...  0.000000  0.000000  0.214286
2021-07-25  0.285714  0.357143  0.357143  ...  0.500000  0.000000  0.000000
2021-08-01  0.214286  0.285714  0.357143  ...  0.142857  0.500000  0.000000
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.142857  0.500000

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_137 (LSTM)              (None, 4)                 464       
_________________________________________________________________
dense_135 (Dense)            (None, 1)                 5         
=================================================================
Total params: 469
Trainable params: 469
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0143
Epoch 2/100
188/188 - 0s - loss: 0.0083
Epoch 3/100
188/188 - 0s - loss: 0.0081
Epoch 4/100
188/188 - 0s - loss: 0.0079
Epoch 5/100
188/188 - 0s - loss: 0.0078
Epoch 6/100
188/188 - 0s - loss: 0.0078
Epoch 7/100
188/188 - 0s - loss: 0.0076
Epoch 8/100
188/188 - 0s - loss: 0.0076
Epoch 9/100
188/188 - 0s - loss: 0.0074
Epoch 10/100
188/188 - 0s - loss: 0.0074
Epoch 11/100
188/188 - 0s - loss: 0.0073
Epoch 12/100
188/188 - 0s - loss: 0.0073
Epoch 13/100
188/188 - 0s - loss: 0.0074
Epoch 14/100
188/188 - 0s - loss: 0.0072
Epoch 15/100
188/188 - 0s - loss: 0.0073
Epoch 16/100
188/188 - 0s - loss: 0.0072
Epoch 17/100
188/188 - 0s - loss: 0.0073
Epoch 18/100
188/188 - 0s - loss: 0.0072
Epoch 19/100
188/188 - 0s - loss: 0.0073
Epoch 20/100
188/188 - 0s - loss: 0.0071
Epoch 21/100
188/188 - 0s - loss: 0.0072
Epoch 22/100
188/188 - 0s - loss: 0.0071
Epoch 23/100
188/188 - 0s - loss: 0.0071
Epoch 24/100
188/188 - 0s - loss: 0.0069
Epoch 25/100
188/188 - 0s - loss: 0.0070
Epoch 26/100
188/188 - 0s - loss: 0.0069
Epoch 27/100
188/188 - 0s - loss: 0.0070
Epoch 28/100
188/188 - 0s - loss: 0.0070
Epoch 29/100
188/188 - 0s - loss: 0.0071
Epoch 30/100
188/188 - 0s - loss: 0.0069
Epoch 31/100
188/188 - 0s - loss: 0.0069
Epoch 32/100
188/188 - 0s - loss: 0.0070
Epoch 33/100
188/188 - 0s - loss: 0.0068
Epoch 34/100
188/188 - 0s - loss: 0.0068
Epoch 35/100
188/188 - 0s - loss: 0.0070
Epoch 36/100
188/188 - 0s - loss: 0.0069
Epoch 37/100
188/188 - 0s - loss: 0.0067
Epoch 38/100
188/188 - 0s - loss: 0.0069
Epoch 39/100
188/188 - 0s - loss: 0.0068
Epoch 40/100
188/188 - 0s - loss: 0.0068
Epoch 41/100
188/188 - 0s - loss: 0.0067
Epoch 42/100
188/188 - 0s - loss: 0.0068
Epoch 43/100
188/188 - 0s - loss: 0.0068
Epoch 44/100
188/188 - 0s - loss: 0.0066
Epoch 45/100
188/188 - 0s - loss: 0.0068
Epoch 46/100
188/188 - 0s - loss: 0.0066
Epoch 47/100
188/188 - 0s - loss: 0.0069
Epoch 48/100
188/188 - 0s - loss: 0.0064
Epoch 49/100
188/188 - 0s - loss: 0.0066
Epoch 50/100
188/188 - 0s - loss: 0.0068
Epoch 51/100
188/188 - 0s - loss: 0.0066
Epoch 52/100
188/188 - 0s - loss: 0.0066
Epoch 53/100
188/188 - 0s - loss: 0.0067
Epoch 54/100
188/188 - 0s - loss: 0.0067
Epoch 55/100
188/188 - 0s - loss: 0.0066
Epoch 56/100
188/188 - 0s - loss: 0.0068
Epoch 57/100
188/188 - 0s - loss: 0.0065
Epoch 58/100
188/188 - 0s - loss: 0.0067
Epoch 59/100
188/188 - 0s - loss: 0.0064
Epoch 60/100
188/188 - 0s - loss: 0.0066
Epoch 61/100
188/188 - 0s - loss: 0.0065
Epoch 62/100
188/188 - 0s - loss: 0.0064
Epoch 63/100
188/188 - 0s - loss: 0.0065
Epoch 64/100
188/188 - 0s - loss: 0.0064
Epoch 65/100
188/188 - 0s - loss: 0.0065
Epoch 66/100
188/188 - 0s - loss: 0.0065
Epoch 67/100
188/188 - 0s - loss: 0.0064
Epoch 68/100
188/188 - 0s - loss: 0.0064
Epoch 69/100
188/188 - 0s - loss: 0.0064
Epoch 70/100
188/188 - 0s - loss: 0.0064
Epoch 71/100
188/188 - 0s - loss: 0.0062
Epoch 72/100
188/188 - 0s - loss: 0.0064
Epoch 73/100
188/188 - 0s - loss: 0.0067
Epoch 74/100
188/188 - 0s - loss: 0.0065
Epoch 75/100
188/188 - 0s - loss: 0.0063
Epoch 76/100
188/188 - 0s - loss: 0.0065
Epoch 77/100
188/188 - 0s - loss: 0.0063
Epoch 78/100
188/188 - 0s - loss: 0.0064
Epoch 79/100
188/188 - 0s - loss: 0.0065
Epoch 80/100
188/188 - 0s - loss: 0.0064
Epoch 81/100
188/188 - 0s - loss: 0.0062
Epoch 82/100
188/188 - 0s - loss: 0.0061
Epoch 83/100
188/188 - 0s - loss: 0.0063
Epoch 84/100
188/188 - 0s - loss: 0.0062
Epoch 85/100
188/188 - 0s - loss: 0.0062
Epoch 86/100
188/188 - 0s - loss: 0.0061
Epoch 87/100
188/188 - 0s - loss: 0.0062
Epoch 88/100
188/188 - 0s - loss: 0.0061
Epoch 89/100
188/188 - 0s - loss: 0.0061
Epoch 90/100
188/188 - 0s - loss: 0.0062
Epoch 91/100
188/188 - 0s - loss: 0.0064
Epoch 92/100
188/188 - 0s - loss: 0.0062
Epoch 93/100
188/188 - 0s - loss: 0.0060
Epoch 94/100
188/188 - 0s - loss: 0.0060
Epoch 95/100
188/188 - 0s - loss: 0.0060
Epoch 96/100
188/188 - 0s - loss: 0.0061
Epoch 97/100
188/188 - 0s - loss: 0.0060
Epoch 98/100
188/188 - 0s - loss: 0.0060
Epoch 99/100
188/188 - 0s - loss: 0.0059
Epoch 100/100
188/188 - 0s - loss: 0.0059

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.076
Train RMSE: 0.169
key_word: stock price
window size: 24
N neurons: 4

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.000000  0.214286  1.000000
2021-07-18  0.357143  0.357143  0.142857  ...  0.000000  0.000000  0.214286
2021-07-25  0.285714  0.357143  0.357143  ...  0.500000  0.000000  0.000000
2021-08-01  0.214286  0.285714  0.357143  ...  0.142857  0.500000  0.000000
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.142857  0.500000

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_138 (LSTM)              (None, 8)                 1056      
_________________________________________________________________
dense_136 (Dense)            (None, 1)                 9         
=================================================================
Total params: 1,065
Trainable params: 1,065
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0136
Epoch 2/100
188/188 - 0s - loss: 0.0079
Epoch 3/100
188/188 - 0s - loss: 0.0077
Epoch 4/100
188/188 - 0s - loss: 0.0076
Epoch 5/100
188/188 - 0s - loss: 0.0074
Epoch 6/100
188/188 - 0s - loss: 0.0075
Epoch 7/100
188/188 - 0s - loss: 0.0074
Epoch 8/100
188/188 - 0s - loss: 0.0073
Epoch 9/100
188/188 - 0s - loss: 0.0074
Epoch 10/100
188/188 - 0s - loss: 0.0072
Epoch 11/100
188/188 - 0s - loss: 0.0071
Epoch 12/100
188/188 - 0s - loss: 0.0072
Epoch 13/100
188/188 - 0s - loss: 0.0070
Epoch 14/100
188/188 - 0s - loss: 0.0072
Epoch 15/100
188/188 - 0s - loss: 0.0070
Epoch 16/100
188/188 - 0s - loss: 0.0068
Epoch 17/100
188/188 - 0s - loss: 0.0070
Epoch 18/100
188/188 - 0s - loss: 0.0070
Epoch 19/100
188/188 - 0s - loss: 0.0069
Epoch 20/100
188/188 - 0s - loss: 0.0072
Epoch 21/100
188/188 - 0s - loss: 0.0070
Epoch 22/100
188/188 - 0s - loss: 0.0067
Epoch 23/100
188/188 - 0s - loss: 0.0071
Epoch 24/100
188/188 - 0s - loss: 0.0069
Epoch 25/100
188/188 - 0s - loss: 0.0068
Epoch 26/100
188/188 - 0s - loss: 0.0069
Epoch 27/100
188/188 - 0s - loss: 0.0068
Epoch 28/100
188/188 - 0s - loss: 0.0068
Epoch 29/100
188/188 - 0s - loss: 0.0066
Epoch 30/100
188/188 - 0s - loss: 0.0068
Epoch 31/100
188/188 - 0s - loss: 0.0070
Epoch 32/100
188/188 - 0s - loss: 0.0068
Epoch 33/100
188/188 - 0s - loss: 0.0068
Epoch 34/100
188/188 - 0s - loss: 0.0068
Epoch 35/100
188/188 - 0s - loss: 0.0066
Epoch 36/100
188/188 - 0s - loss: 0.0067
Epoch 37/100
188/188 - 0s - loss: 0.0067
Epoch 38/100
188/188 - 0s - loss: 0.0069
Epoch 39/100
188/188 - 0s - loss: 0.0067
Epoch 40/100
188/188 - 0s - loss: 0.0067
Epoch 41/100
188/188 - 0s - loss: 0.0066
Epoch 42/100
188/188 - 0s - loss: 0.0065
Epoch 43/100
188/188 - 0s - loss: 0.0066
Epoch 44/100
188/188 - 0s - loss: 0.0066
Epoch 45/100
188/188 - 0s - loss: 0.0065
Epoch 46/100
188/188 - 0s - loss: 0.0065
Epoch 47/100
188/188 - 0s - loss: 0.0066
Epoch 48/100
188/188 - 0s - loss: 0.0067
Epoch 49/100
188/188 - 0s - loss: 0.0067
Epoch 50/100
188/188 - 0s - loss: 0.0066
Epoch 51/100
188/188 - 0s - loss: 0.0065
Epoch 52/100
188/188 - 0s - loss: 0.0068
Epoch 53/100
188/188 - 0s - loss: 0.0065
Epoch 54/100
188/188 - 0s - loss: 0.0068
Epoch 55/100
188/188 - 0s - loss: 0.0064
Epoch 56/100
188/188 - 0s - loss: 0.0067
Epoch 57/100
188/188 - 0s - loss: 0.0066
Epoch 58/100
188/188 - 0s - loss: 0.0065
Epoch 59/100
188/188 - 0s - loss: 0.0065
Epoch 60/100
188/188 - 0s - loss: 0.0065
Epoch 61/100
188/188 - 0s - loss: 0.0066
Epoch 62/100
188/188 - 0s - loss: 0.0066
Epoch 63/100
188/188 - 0s - loss: 0.0065
Epoch 64/100
188/188 - 0s - loss: 0.0063
Epoch 65/100
188/188 - 0s - loss: 0.0064
Epoch 66/100
188/188 - 0s - loss: 0.0065
Epoch 67/100
188/188 - 0s - loss: 0.0065
Epoch 68/100
188/188 - 0s - loss: 0.0066
Epoch 69/100
188/188 - 0s - loss: 0.0065
Epoch 70/100
188/188 - 0s - loss: 0.0064
Epoch 71/100
188/188 - 0s - loss: 0.0063
Epoch 72/100
188/188 - 0s - loss: 0.0063
Epoch 73/100
188/188 - 0s - loss: 0.0064
Epoch 74/100
188/188 - 0s - loss: 0.0063
Epoch 75/100
188/188 - 0s - loss: 0.0064
Epoch 76/100
188/188 - 0s - loss: 0.0064
Epoch 77/100
188/188 - 0s - loss: 0.0063
Epoch 78/100
188/188 - 0s - loss: 0.0066
Epoch 79/100
188/188 - 0s - loss: 0.0062
Epoch 80/100
188/188 - 0s - loss: 0.0063
Epoch 81/100
188/188 - 0s - loss: 0.0065
Epoch 82/100
188/188 - 0s - loss: 0.0063
Epoch 83/100
188/188 - 0s - loss: 0.0062
Epoch 84/100
188/188 - 0s - loss: 0.0063
Epoch 85/100
188/188 - 0s - loss: 0.0063
Epoch 86/100
188/188 - 0s - loss: 0.0064
Epoch 87/100
188/188 - 0s - loss: 0.0061
Epoch 88/100
188/188 - 0s - loss: 0.0063
Epoch 89/100
188/188 - 0s - loss: 0.0062
Epoch 90/100
188/188 - 0s - loss: 0.0063
Epoch 91/100
188/188 - 0s - loss: 0.0060
Epoch 92/100
188/188 - 0s - loss: 0.0062
Epoch 93/100
188/188 - 0s - loss: 0.0062
Epoch 94/100
188/188 - 0s - loss: 0.0063
Epoch 95/100
188/188 - 0s - loss: 0.0063
Epoch 96/100
188/188 - 0s - loss: 0.0062
Epoch 97/100
188/188 - 0s - loss: 0.0062
Epoch 98/100
188/188 - 0s - loss: 0.0061
Epoch 99/100
188/188 - 0s - loss: 0.0062
Epoch 100/100
188/188 - 0s - loss: 0.0061

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.077
Train RMSE: 0.168
key_word: stock price
window size: 24
N neurons: 8

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.000000  0.214286  1.000000
2021-07-18  0.357143  0.357143  0.142857  ...  0.000000  0.000000  0.214286
2021-07-25  0.285714  0.357143  0.357143  ...  0.500000  0.000000  0.000000
2021-08-01  0.214286  0.285714  0.357143  ...  0.142857  0.500000  0.000000
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.142857  0.500000

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_139 (LSTM)              (None, 16)                2624      
_________________________________________________________________
dense_137 (Dense)            (None, 1)                 17        
=================================================================
Total params: 2,641
Trainable params: 2,641
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0127
Epoch 2/100
188/188 - 0s - loss: 0.0083
Epoch 3/100
188/188 - 0s - loss: 0.0084
Epoch 4/100
188/188 - 0s - loss: 0.0079
Epoch 5/100
188/188 - 0s - loss: 0.0079
Epoch 6/100
188/188 - 0s - loss: 0.0075
Epoch 7/100
188/188 - 0s - loss: 0.0075
Epoch 8/100
188/188 - 0s - loss: 0.0076
Epoch 9/100
188/188 - 0s - loss: 0.0074
Epoch 10/100
188/188 - 0s - loss: 0.0073
Epoch 11/100
188/188 - 0s - loss: 0.0074
Epoch 12/100
188/188 - 0s - loss: 0.0073
Epoch 13/100
188/188 - 0s - loss: 0.0072
Epoch 14/100
188/188 - 0s - loss: 0.0073
Epoch 15/100
188/188 - 0s - loss: 0.0071
Epoch 16/100
188/188 - 0s - loss: 0.0072
Epoch 17/100
188/188 - 0s - loss: 0.0072
Epoch 18/100
188/188 - 0s - loss: 0.0071
Epoch 19/100
188/188 - 0s - loss: 0.0068
Epoch 20/100
188/188 - 0s - loss: 0.0069
Epoch 21/100
188/188 - 0s - loss: 0.0069
Epoch 22/100
188/188 - 0s - loss: 0.0071
Epoch 23/100
188/188 - 0s - loss: 0.0069
Epoch 24/100
188/188 - 0s - loss: 0.0070
Epoch 25/100
188/188 - 0s - loss: 0.0069
Epoch 26/100
188/188 - 0s - loss: 0.0069
Epoch 27/100
188/188 - 0s - loss: 0.0069
Epoch 28/100
188/188 - 0s - loss: 0.0067
Epoch 29/100
188/188 - 0s - loss: 0.0071
Epoch 30/100
188/188 - 0s - loss: 0.0069
Epoch 31/100
188/188 - 0s - loss: 0.0068
Epoch 32/100
188/188 - 0s - loss: 0.0066
Epoch 33/100
188/188 - 0s - loss: 0.0068
Epoch 34/100
188/188 - 0s - loss: 0.0067
Epoch 35/100
188/188 - 0s - loss: 0.0069
Epoch 36/100
188/188 - 0s - loss: 0.0069
Epoch 37/100
188/188 - 0s - loss: 0.0072
Epoch 38/100
188/188 - 0s - loss: 0.0065
Epoch 39/100
188/188 - 0s - loss: 0.0068
Epoch 40/100
188/188 - 0s - loss: 0.0068
Epoch 41/100
188/188 - 0s - loss: 0.0066
Epoch 42/100
188/188 - 0s - loss: 0.0067
Epoch 43/100
188/188 - 0s - loss: 0.0067
Epoch 44/100
188/188 - 0s - loss: 0.0066
Epoch 45/100
188/188 - 0s - loss: 0.0066
Epoch 46/100
188/188 - 0s - loss: 0.0066
Epoch 47/100
188/188 - 0s - loss: 0.0070
Epoch 48/100
188/188 - 0s - loss: 0.0066
Epoch 49/100
188/188 - 0s - loss: 0.0066
Epoch 50/100
188/188 - 0s - loss: 0.0066
Epoch 51/100
188/188 - 0s - loss: 0.0065
Epoch 52/100
188/188 - 0s - loss: 0.0068
Epoch 53/100
188/188 - 0s - loss: 0.0065
Epoch 54/100
188/188 - 0s - loss: 0.0067
Epoch 55/100
188/188 - 0s - loss: 0.0066
Epoch 56/100
188/188 - 0s - loss: 0.0066
Epoch 57/100
188/188 - 0s - loss: 0.0064
Epoch 58/100
188/188 - 0s - loss: 0.0067
Epoch 59/100
188/188 - 0s - loss: 0.0064
Epoch 60/100
188/188 - 0s - loss: 0.0065
Epoch 61/100
188/188 - 0s - loss: 0.0064
Epoch 62/100
188/188 - 0s - loss: 0.0065
Epoch 63/100
188/188 - 0s - loss: 0.0064
Epoch 64/100
188/188 - 0s - loss: 0.0064
Epoch 65/100
188/188 - 0s - loss: 0.0064
Epoch 66/100
188/188 - 0s - loss: 0.0063
Epoch 67/100
188/188 - 0s - loss: 0.0064
Epoch 68/100
188/188 - 0s - loss: 0.0064
Epoch 69/100
188/188 - 0s - loss: 0.0063
Epoch 70/100
188/188 - 0s - loss: 0.0064
Epoch 71/100
188/188 - 0s - loss: 0.0065
Epoch 72/100
188/188 - 0s - loss: 0.0063
Epoch 73/100
188/188 - 0s - loss: 0.0063
Epoch 74/100
188/188 - 0s - loss: 0.0063
Epoch 75/100
188/188 - 0s - loss: 0.0063
Epoch 76/100
188/188 - 0s - loss: 0.0060
Epoch 77/100
188/188 - 0s - loss: 0.0063
Epoch 78/100
188/188 - 0s - loss: 0.0061
Epoch 79/100
188/188 - 0s - loss: 0.0061
Epoch 80/100
188/188 - 0s - loss: 0.0061
Epoch 81/100
188/188 - 0s - loss: 0.0062
Epoch 82/100
188/188 - 0s - loss: 0.0063
Epoch 83/100
188/188 - 0s - loss: 0.0061
Epoch 84/100
188/188 - 0s - loss: 0.0061
Epoch 85/100
188/188 - 0s - loss: 0.0061
Epoch 86/100
188/188 - 0s - loss: 0.0060
Epoch 87/100
188/188 - 0s - loss: 0.0060
Epoch 88/100
188/188 - 0s - loss: 0.0060
Epoch 89/100
188/188 - 0s - loss: 0.0059
Epoch 90/100
188/188 - 0s - loss: 0.0058
Epoch 91/100
188/188 - 0s - loss: 0.0063
Epoch 92/100
188/188 - 0s - loss: 0.0061
Epoch 93/100
188/188 - 0s - loss: 0.0061
Epoch 94/100
188/188 - 0s - loss: 0.0058
Epoch 95/100
188/188 - 0s - loss: 0.0060
Epoch 96/100
188/188 - 0s - loss: 0.0059
Epoch 97/100
188/188 - 0s - loss: 0.0058
Epoch 98/100
188/188 - 0s - loss: 0.0060
Epoch 99/100
188/188 - 0s - loss: 0.0059
Epoch 100/100
188/188 - 0s - loss: 0.0058

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.079
Train RMSE: 0.178
key_word: stock price
window size: 24
N neurons: 16

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.000000  0.214286  1.000000
2021-07-18  0.357143  0.357143  0.142857  ...  0.000000  0.000000  0.214286
2021-07-25  0.285714  0.357143  0.357143  ...  0.500000  0.000000  0.000000
2021-08-01  0.214286  0.285714  0.357143  ...  0.142857  0.500000  0.000000
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.142857  0.500000

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_140"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_140 (LSTM)              (None, 32)                7296      
_________________________________________________________________
dense_138 (Dense)            (None, 1)                 33        
=================================================================
Total params: 7,329
Trainable params: 7,329
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0116
Epoch 2/100
188/188 - 0s - loss: 0.0082
Epoch 3/100
188/188 - 0s - loss: 0.0077
Epoch 4/100
188/188 - 0s - loss: 0.0074
Epoch 5/100
188/188 - 0s - loss: 0.0079
Epoch 6/100
188/188 - 0s - loss: 0.0080
Epoch 7/100
188/188 - 0s - loss: 0.0079
Epoch 8/100
188/188 - 0s - loss: 0.0072
Epoch 9/100
188/188 - 0s - loss: 0.0073
Epoch 10/100
188/188 - 0s - loss: 0.0071
Epoch 11/100
188/188 - 0s - loss: 0.0070
Epoch 12/100
188/188 - 0s - loss: 0.0073
Epoch 13/100
188/188 - 0s - loss: 0.0072
Epoch 14/100
188/188 - 0s - loss: 0.0069
Epoch 15/100
188/188 - 0s - loss: 0.0071
Epoch 16/100
188/188 - 0s - loss: 0.0072
Epoch 17/100
188/188 - 0s - loss: 0.0072
Epoch 18/100
188/188 - 0s - loss: 0.0070
Epoch 19/100
188/188 - 0s - loss: 0.0070
Epoch 20/100
188/188 - 0s - loss: 0.0071
Epoch 21/100
188/188 - 0s - loss: 0.0067
Epoch 22/100
188/188 - 0s - loss: 0.0071
Epoch 23/100
188/188 - 0s - loss: 0.0070
Epoch 24/100
188/188 - 0s - loss: 0.0070
Epoch 25/100
188/188 - 0s - loss: 0.0069
Epoch 26/100
188/188 - 0s - loss: 0.0069
Epoch 27/100
188/188 - 0s - loss: 0.0070
Epoch 28/100
188/188 - 0s - loss: 0.0069
Epoch 29/100
188/188 - 0s - loss: 0.0068
Epoch 30/100
188/188 - 0s - loss: 0.0066
Epoch 31/100
188/188 - 0s - loss: 0.0069
Epoch 32/100
188/188 - 0s - loss: 0.0065
Epoch 33/100
188/188 - 0s - loss: 0.0069
Epoch 34/100
188/188 - 0s - loss: 0.0069
Epoch 35/100
188/188 - 0s - loss: 0.0068
Epoch 36/100
188/188 - 0s - loss: 0.0068
Epoch 37/100
188/188 - 0s - loss: 0.0066
Epoch 38/100
188/188 - 0s - loss: 0.0067
Epoch 39/100
188/188 - 0s - loss: 0.0068
Epoch 40/100
188/188 - 0s - loss: 0.0068
Epoch 41/100
188/188 - 0s - loss: 0.0066
Epoch 42/100
188/188 - 0s - loss: 0.0067
Epoch 43/100
188/188 - 0s - loss: 0.0069
Epoch 44/100
188/188 - 0s - loss: 0.0067
Epoch 45/100
188/188 - 0s - loss: 0.0072
Epoch 46/100
188/188 - 0s - loss: 0.0068
Epoch 47/100
188/188 - 0s - loss: 0.0069
Epoch 48/100
188/188 - 0s - loss: 0.0066
Epoch 49/100
188/188 - 0s - loss: 0.0066
Epoch 50/100
188/188 - 0s - loss: 0.0067
Epoch 51/100
188/188 - 0s - loss: 0.0066
Epoch 52/100
188/188 - 0s - loss: 0.0066
Epoch 53/100
188/188 - 0s - loss: 0.0067
Epoch 54/100
188/188 - 0s - loss: 0.0064
Epoch 55/100
188/188 - 0s - loss: 0.0066
Epoch 56/100
188/188 - 0s - loss: 0.0065
Epoch 57/100
188/188 - 0s - loss: 0.0069
Epoch 58/100
188/188 - 0s - loss: 0.0064
Epoch 59/100
188/188 - 0s - loss: 0.0063
Epoch 60/100
188/188 - 0s - loss: 0.0066
Epoch 61/100
188/188 - 0s - loss: 0.0066
Epoch 62/100
188/188 - 0s - loss: 0.0062
Epoch 63/100
188/188 - 0s - loss: 0.0066
Epoch 64/100
188/188 - 0s - loss: 0.0063
Epoch 65/100
188/188 - 0s - loss: 0.0063
Epoch 66/100
188/188 - 0s - loss: 0.0064
Epoch 67/100
188/188 - 0s - loss: 0.0066
Epoch 68/100
188/188 - 0s - loss: 0.0064
Epoch 69/100
188/188 - 0s - loss: 0.0063
Epoch 70/100
188/188 - 0s - loss: 0.0063
Epoch 71/100
188/188 - 0s - loss: 0.0064
Epoch 72/100
188/188 - 0s - loss: 0.0064
Epoch 73/100
188/188 - 0s - loss: 0.0063
Epoch 74/100
188/188 - 0s - loss: 0.0066
Epoch 75/100
188/188 - 0s - loss: 0.0064
Epoch 76/100
188/188 - 0s - loss: 0.0063
Epoch 77/100
188/188 - 0s - loss: 0.0064
Epoch 78/100
188/188 - 0s - loss: 0.0067
Epoch 79/100
188/188 - 0s - loss: 0.0062
Epoch 80/100
188/188 - 0s - loss: 0.0062
Epoch 81/100
188/188 - 0s - loss: 0.0063
Epoch 82/100
188/188 - 0s - loss: 0.0063
Epoch 83/100
188/188 - 0s - loss: 0.0062
Epoch 84/100
188/188 - 0s - loss: 0.0061
Epoch 85/100
188/188 - 0s - loss: 0.0061
Epoch 86/100
188/188 - 0s - loss: 0.0061
Epoch 87/100
188/188 - 0s - loss: 0.0061
Epoch 88/100
188/188 - 0s - loss: 0.0060
Epoch 89/100
188/188 - 0s - loss: 0.0061
Epoch 90/100
188/188 - 0s - loss: 0.0061
Epoch 91/100
188/188 - 0s - loss: 0.0060
Epoch 92/100
188/188 - 0s - loss: 0.0059
Epoch 93/100
188/188 - 0s - loss: 0.0063
Epoch 94/100
188/188 - 0s - loss: 0.0060
Epoch 95/100
188/188 - 0s - loss: 0.0059
Epoch 96/100
188/188 - 0s - loss: 0.0058
Epoch 97/100
188/188 - 0s - loss: 0.0059
Epoch 98/100
188/188 - 0s - loss: 0.0059
Epoch 99/100
188/188 - 0s - loss: 0.0057
Epoch 100/100
188/188 - 0s - loss: 0.0059

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.077
Train RMSE: 0.174
key_word: stock price
window size: 24
N neurons: 32

 -------------------------------- 
 Training Data 
 -------------------------------- 
 
                 t-0       t-1       t-2  ...      t-22      t-23      t-24
date                                      ...                              
2021-07-11  0.357143  0.142857  0.285714  ...  0.000000  0.214286  1.000000
2021-07-18  0.357143  0.357143  0.142857  ...  0.000000  0.000000  0.214286
2021-07-25  0.285714  0.357143  0.357143  ...  0.500000  0.000000  0.000000
2021-08-01  0.214286  0.285714  0.357143  ...  0.142857  0.500000  0.000000
2021-08-08  0.357143  0.214286  0.285714  ...  0.357143  0.142857  0.500000

[5 rows x 25 columns]

 -------------------------------- 
 Model Summary 
-------------------------------- 
 
Model: "sequential_141"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_141 (LSTM)              (None, 60)                20400     
_________________________________________________________________
dense_139 (Dense)            (None, 1)                 61        
=================================================================
Total params: 20,461
Trainable params: 20,461
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
188/188 - 2s - loss: 0.0107
Epoch 2/100
188/188 - 0s - loss: 0.0087
Epoch 3/100
188/188 - 0s - loss: 0.0081
Epoch 4/100
188/188 - 0s - loss: 0.0080
Epoch 5/100
188/188 - 0s - loss: 0.0079
Epoch 6/100
188/188 - 0s - loss: 0.0079
Epoch 7/100
188/188 - 0s - loss: 0.0073
Epoch 8/100
188/188 - 0s - loss: 0.0077
Epoch 9/100
188/188 - 0s - loss: 0.0081
Epoch 10/100
188/188 - 0s - loss: 0.0076
Epoch 11/100
188/188 - 0s - loss: 0.0073
Epoch 12/100
188/188 - 0s - loss: 0.0075
Epoch 13/100
188/188 - 0s - loss: 0.0073
Epoch 14/100
188/188 - 0s - loss: 0.0075
Epoch 15/100
188/188 - 0s - loss: 0.0070
Epoch 16/100
188/188 - 0s - loss: 0.0069
Epoch 17/100
188/188 - 0s - loss: 0.0070
Epoch 18/100
188/188 - 0s - loss: 0.0070
Epoch 19/100
188/188 - 0s - loss: 0.0071
Epoch 20/100
188/188 - 0s - loss: 0.0073
Epoch 21/100
188/188 - 0s - loss: 0.0072
Epoch 22/100
188/188 - 0s - loss: 0.0068
Epoch 23/100
188/188 - 0s - loss: 0.0077
Epoch 24/100
188/188 - 0s - loss: 0.0069
Epoch 25/100
188/188 - 0s - loss: 0.0070
Epoch 26/100
188/188 - 0s - loss: 0.0073
Epoch 27/100
188/188 - 0s - loss: 0.0067
Epoch 28/100
188/188 - 0s - loss: 0.0071
Epoch 29/100
188/188 - 0s - loss: 0.0069
Epoch 30/100
188/188 - 0s - loss: 0.0070
Epoch 31/100
188/188 - 0s - loss: 0.0071
Epoch 32/100
188/188 - 0s - loss: 0.0067
Epoch 33/100
188/188 - 0s - loss: 0.0068
Epoch 34/100
188/188 - 0s - loss: 0.0067
Epoch 35/100
188/188 - 0s - loss: 0.0068
Epoch 36/100
188/188 - 0s - loss: 0.0069
Epoch 37/100
188/188 - 0s - loss: 0.0069
Epoch 38/100
188/188 - 0s - loss: 0.0067
Epoch 39/100
188/188 - 0s - loss: 0.0070
Epoch 40/100
188/188 - 0s - loss: 0.0068
Epoch 41/100
188/188 - 0s - loss: 0.0068
Epoch 42/100
188/188 - 0s - loss: 0.0068
Epoch 43/100
188/188 - 0s - loss: 0.0068
Epoch 44/100
188/188 - 0s - loss: 0.0064
Epoch 45/100
188/188 - 0s - loss: 0.0070
Epoch 46/100
188/188 - 0s - loss: 0.0067
Epoch 47/100
188/188 - 0s - loss: 0.0067
Epoch 48/100
188/188 - 0s - loss: 0.0067
Epoch 49/100
188/188 - 0s - loss: 0.0066
Epoch 50/100
188/188 - 0s - loss: 0.0069
Epoch 51/100
188/188 - 0s - loss: 0.0068
Epoch 52/100
188/188 - 0s - loss: 0.0066
Epoch 53/100
188/188 - 0s - loss: 0.0068
Epoch 54/100
188/188 - 0s - loss: 0.0066
Epoch 55/100
188/188 - 0s - loss: 0.0065
Epoch 56/100
188/188 - 0s - loss: 0.0067
Epoch 57/100
188/188 - 0s - loss: 0.0066
Epoch 58/100
188/188 - 0s - loss: 0.0066
Epoch 59/100
188/188 - 0s - loss: 0.0068
Epoch 60/100
188/188 - 0s - loss: 0.0064
Epoch 61/100
188/188 - 0s - loss: 0.0065
Epoch 62/100
188/188 - 0s - loss: 0.0065
Epoch 63/100
188/188 - 0s - loss: 0.0064
Epoch 64/100
188/188 - 0s - loss: 0.0066
Epoch 65/100
188/188 - 0s - loss: 0.0063
Epoch 66/100
188/188 - 0s - loss: 0.0064
Epoch 67/100
188/188 - 0s - loss: 0.0064
Epoch 68/100
188/188 - 0s - loss: 0.0067
Epoch 69/100
188/188 - 0s - loss: 0.0066
Epoch 70/100
188/188 - 0s - loss: 0.0064
Epoch 71/100
188/188 - 0s - loss: 0.0062
Epoch 72/100
188/188 - 0s - loss: 0.0063
Epoch 73/100
188/188 - 0s - loss: 0.0063
Epoch 74/100
188/188 - 0s - loss: 0.0065
Epoch 75/100
188/188 - 0s - loss: 0.0068
Epoch 76/100
188/188 - 0s - loss: 0.0061
Epoch 77/100
188/188 - 0s - loss: 0.0062
Epoch 78/100
188/188 - 0s - loss: 0.0064
Epoch 79/100
188/188 - 0s - loss: 0.0063
Epoch 80/100
188/188 - 0s - loss: 0.0061
Epoch 81/100
188/188 - 0s - loss: 0.0063
Epoch 82/100
188/188 - 0s - loss: 0.0066
Epoch 83/100
188/188 - 0s - loss: 0.0063
Epoch 84/100
188/188 - 0s - loss: 0.0064
Epoch 85/100
188/188 - 0s - loss: 0.0062
Epoch 86/100
188/188 - 0s - loss: 0.0064
Epoch 87/100
188/188 - 0s - loss: 0.0061
Epoch 88/100
188/188 - 0s - loss: 0.0062
Epoch 89/100
188/188 - 0s - loss: 0.0061
Epoch 90/100
188/188 - 0s - loss: 0.0061
Epoch 91/100
188/188 - 0s - loss: 0.0063
Epoch 92/100
188/188 - 0s - loss: 0.0060
Epoch 93/100
188/188 - 0s - loss: 0.0062
Epoch 94/100
188/188 - 0s - loss: 0.0060
Epoch 95/100
188/188 - 0s - loss: 0.0063
Epoch 96/100
188/188 - 0s - loss: 0.0060
Epoch 97/100
188/188 - 0s - loss: 0.0061
Epoch 98/100
188/188 - 0s - loss: 0.0059
Epoch 99/100
188/188 - 0s - loss: 0.0061
Epoch 100/100
188/188 - 0s - loss: 0.0061

 -------------------------------- 
 RMSE 
 -------------------------------- 

Train RMSE: 0.077
Train RMSE: 0.171
key_word: stock price
window size: 24
N neurons: 60
